[{"title":"gdb 的常用","url":"/archives/537e6650.html","content":"\n\n看内存\nx&#x2F;&lt;n&#x2F;f&#x2F;u&gt; n 是一个正整数，表示显示内存的长度，也就是说从当前地址向后显示几个地址的内容。f 表示显示的格式，参见上面。如果地址所指的是字符串，那么格式可以是s，如果 地址是指令地址，那么格式可以是i。u 表示从当前地址往后请求的字节数，如果不指定的话，GDB默认是4个bytes。  \n\n\nu 参数可以用下面的字符来代替\n\n   b 表示单字节，   h 表示双字节，   w 表示四字节，   g 表示八字节。\n\n\n\n当我们指定了字节长度后，GDB会从指内存定的内存地址开始，读写指定字节，并把其当作一个值取出来。\n\n\n命令：x&#x2F;3uh 0x54320 表示，从内存地址0x54320读取内容，h表示以双字节为一个单位，3表示三个单位，u表示按十六进制显示。\n\n\nu 可以替换成：\n\n   d 按十进制格式显示变量   x 按十六进制格式显示变量   a 按十六进制格式显示变量   u 按十六进制格式显示无符号整型   o 按八进制格式显示变量   t 按二进制格式显示变量   c 按字符格式显示变量   f 按浮点数格式显示变量\n\n\n\nh 可以替换成：\n\n   b 表示单字节，   h 表示双字节，   w 表示四字节，   g 表示八字节\n\n\n\nvirtual 虚函数表(gdb) set $i = 0(gdb) while $i &lt; 10    print $i    p /a (*(void ***)pSession)[$i]    set $i = $i + 1    end\n\ngdb 系统catch(gdb) catch throw out_of_range","categories":["知识备忘"],"tags":["linux","gdb","C/C++","常用备忘"]},{"title":"linux 调试相关","url":"/archives/559da5ab.html","content":"linux performance tools\n一个很重要的博客http://www.brendangregg.com/linuxperf.html\n查问题：\nperf 查性能消耗在哪里\nstrace 查系统调用\nhtop top升级版\nldd 查依赖\ngperftools 配合google的tcmalloc查内存问题（火焰图）\nlibasan 查内存越界\nsar 查性能瓶颈\ndmesg 查系统抛出的信号\nlsof 查句柄占用\niostat IO消耗\ndstat 定时统计系统占用的\nfree 看内存&#x2F;buffer&#x2F;cache\npmap 查内存\nvmstat 查内存\npidstat/ps 查进程\ndf -h / du -sh * 看磁盘\nip a/ro 查网卡\nethtool -k/g 查网卡配置，主要看offload和ringbuffer相关的\npstack 查热点和死锁\n\n网络\ndig dns解析\nnslookup dns解析\nping 验证IP是否可达（ICMP）\ntcping \ntelnet 验证端口是否可达（TCP）\ntraceroute 探测路由链路（ICMP&#x2F;UDP&#x2F;TCP）\nnetstat 查看网络状态\nss netstat 替代\ncurl 模拟http\nnc 模拟网络（TCP&#x2F;UDP）\ntc 流量控制\ntcpdump 抓包\n\nvim参考\nhttps://zhuanlan.zhihu.com/p/24752590\n\n","categories":["知识备忘"],"tags":["linux","常用备忘"]},{"title":"mysql 数据查询相关","url":"/archives/6d9a8e3e.html","content":"基本规则：struct 表示一张表，  entry 表示表字段必要配置：struct: name; entry: name, type, desctype = string： size必须  &#123; 描述类型，     对应数据库类型，      对应程序类型&#125;  &#123; &#x27;tinyint&#x27;,    &#x27;tinyint&#x27;,           &#x27;int8_t&#x27;&#125;,  &#123; &#x27;utinyint&#x27;,   &#x27;tinyint unsigned&#x27;,  &#x27;uint8_t&#x27;&#125;,  &#123; &#x27;smallint&#x27;,   &#x27;smallint&#x27;,          &#x27;int16_t&#x27;&#125;,  &#123; &#x27;usmallint&#x27;,  &#x27;smallint unsigned&#x27;, &#x27;uint16_t&#x27;&#125;,  &#123; &#x27;int&#x27;,        &#x27;int&#x27;,               &#x27;int32_t&#x27;&#125;,  &#123; &#x27;uint&#x27;,       &#x27;int unsigned&#x27;,      &#x27;uint32_t&#x27;&#125;,  &#123; &#x27;bigint&#x27;,     &#x27;bigint&#x27;,            &#x27;int64_t&#x27;&#125;,  &#123; &#x27;biguint&#x27;,    &#x27;bigint unsigned&#x27;,   &#x27;uint64_t&#x27;&#125;,  &#123; &#x27;float&#x27;,      &#x27;float&#x27;,             &#x27;float&#x27;&#125;,  &#123; &#x27;double&#x27;,     &#x27;double&#x27;,            &#x27;double&#x27;&#125;,  &#123; &#x27;blob&#x27;,       &#x27;blob&#x27;,              &#x27;std::string&#x27;&#125;,  // TODO:sscanf会有问题，暂时不支持  &#123; &#x27;datetime&#x27;,   &#x27;datetime&#x27;,          &#x27;char&#x27;&#125;,  &#123; &#x27;string&#x27;,     &#x27;varchar&#x27;,           &#x27;char&#x27;&#125;,oldname : 修改原有名称index : 索引角色相关日志必填：&lt;entry name=&#x27;event_time&#x27; type=&#x27;datetime&#x27; desc=&#x27;游戏事件的时间&#x27; /&gt;&lt;entry name=&#x27;game_id&#x27; type=&#x27;string&#x27; size=&#x27;128&#x27; desc=&#x27;游戏ID&#x27; /&gt;&lt;entry name=&#x27;area_id&#x27; type=&#x27;uint&#x27; desc=&#x27;区服ID&#x27; /&gt;&lt;entry name=&#x27;group_id&#x27; type=&#x27;uint&#x27; desc=&#x27;服ID&#x27; /&gt;&lt;entry name=&#x27;platform&#x27; type=&#x27;string&#x27; size=&#x27;32&#x27; desc=&#x27;设备类型（android=1，ios=2）&#x27; /&gt;&lt;entry name=&#x27;channel_id&#x27; type=&#x27;string&#x27; size=&#x27;128&#x27; desc=&#x27;渠道ID&#x27; /&gt;&lt;entry name=&#x27;mid&#x27; type=&#x27;string&#x27; size=&#x27;128&#x27; desc=&#x27;玩家用户名&#x27; /&gt;&lt;entry name=&#x27;character_id&#x27; type=&#x27;string&#x27; size=&#x27;128&#x27; desc=&#x27;角色ID&#x27; /&gt;非角色相关日志必填：&lt;entry name=&#x27;event_time&#x27; type=&#x27;datetime&#x27; desc=&#x27;游戏事件的时间&#x27; /&gt;&lt;entry name=&#x27;game_id&#x27; type=&#x27;string&#x27; size=&#x27;128&#x27; desc=&#x27;游戏ID&#x27; /&gt;&lt;entry name=&#x27;area_id&#x27; type=&#x27;uint&#x27; desc=&#x27;区服ID&#x27; /&gt;&lt;entry name=&#x27;group_id&#x27; type=&#x27;uint&#x27; desc=&#x27;服ID&#x27; /&gt;\n\n\nsql 变量应用-- 两行数据时间差，简单版本，注意变量  @i @ii , 两个sql需要不同的名字select x.user_id, x.login_time, y.login_time,TIMESTAMPDIFF(SECOND, x.login_time, y.login_time) sub_sec from(select user_id, login_time, (@i := @i + 1) as rank from user_login_log, (select @i := 1) a where type=11 and app_id=49 and login_time=event_time order by user_id,login_time) as x LEFT JOIN (select user_id, login_time, (@ii := @ii + 1) as rank from user_login_log, (select @ii := 0) a where type=11 and app_id=49 and login_time=event_time order by user_id,login_time)as y on x.user_id = y.user_id and x.rank = y.rank\n\n\nmysql 数据类型\n\n\n列类型\n表达的范围\n存储需求\n\n\n\nTINYINT[(M)] [UNSIGNED] [ZEROFILL]\n-128到127 或 0到255\n1个字节\n\n\nSMALLINT[(M)] [UNSIGNED] [ZEROFILL]\n-32768到32767 或 0到65535\n2个字节\n\n\nINT[(M)] [UNSIGNED] [ZEROFILL]\n-2147483648到2147483647 或 0到4294967295\n4个字节\n\n\nBIGINT[(M)] [UNSIGNED] [ZEROFILL]\n-9223372036854775808到9223372036854775807 或 0到18446744073709551615\n8个字节\n\n\nDECIMAL[(M[,D])] [UNSIGNED] [ZEROFILL]\n整数最大位数（M）为65，小数位数最大（D）为30\n变长\n\n\nDATE\nYYYY-MM-DD\n3个字节\n\n\nDATETIME\nYYYY-MM-DD HH:MM:SS(1001年到9999年的范围)\n8个字节\n\n\nTIMESTAMP\nYYYY-MM-DD HH:MM:SS（1970年到2037年的范围）\n4个字节\n\n\nCHAR(M)\n0&lt;M&lt;&#x3D;255\nM个字符（所占空间跟字符集等有关系）\n\n\nVARCHAR(M)\n0&lt;M&lt;65532&#x2F;N\nM个字符（N由字符集，以及是否为中文还是字母数字等有关系）\n\n\nTEXT\n64K个字符\n所占空间跟字符集等有关系\n\n\n","categories":["数据查询"],"tags":["mysql","数据查询"]},{"title":"redis 常用","url":"/archives/88fcd214.html","content":"Redis Cluster 使用 lua 问题：EVAL 定义是： EVAL script numkeys key [key…] arg [arg…]设计者期望所有操作的KEY 都是用 KEYS传进去的，EVAL执行前会检查一下所有的KEYS，根据这些KEYS找到把指令发送到那个节点上这里的节点对应 Cluster 就是 Slots，一共16384个Slots，规则是 SLOT &#x3D; CRC16(KEY) mod 16384\n&#96;16384 The reason is:    1. Normal heartbeat packets carry the full configuration of a node, that can be replaced in an idempotent way with the old in order to update an old config. This means they contain the slots configuration for a node, in raw form, that uses 2k of space with16k slots, but would use a prohibitive 8k of space using 65k slots.    2. At the same time it is unlikely that Redis Cluster would scale to more than 1000 mater nodes because of other design tradeoffs.So 16k was in the right range to ensure enough slots per master with a max of 1000 maters, but a small enough number to propagate the slot configuration as a raw bitmap easily. Note that in small clusters the bitmap would be hard to compress because when N is small the bitmap would have slots&#x2F;N bits set that is a large percentage of bits set.\nFrom https://github.com/redis/redis/issues/2576&#96;\n根据上面的规则，传入的KEYS如果不是同样的SLOT，就会报错  CROSSSLOT Keys in request don&#39;t hash to the same slot如果不传 KEYS 只使用 ARGV，或者直接lua写死多个KEY的方式，比如:    redis.call(&#39;get&#39;, &#39;123abc&#39;);     redis.call(&#39;get&#39;, &#39;123def&#39;);   -- 这里没有做测试，认为 &#39;123abc&#39; 和 &#39;123def&#39; 是不同的SLOT这时候会报错类似 ERR Error running script (call to f_8ead0f68893988e15c455c0b6c8ab9982e2e707c): @user_script:1: @user_script: 1: Lua script attempted to access a non local key in a cluster node可以用 &#123;&#125; 括起来计算SLOT用的部分，保证 &#123;&#125; 括起来的部分是相同的，Redis 集群的拓扑结构是是一个全连通的网络，每一个节点之间都会建立一个 Cluster Bus，所以集群的任何配置变动都会立即同步到各个节点，也就是说，每一个节点都知道哪些 Slot 对应哪个节点。所以不论客户端连接到哪个节点进行执行指令，服务端都会正确的指示客户端应当重定向到哪一个节点来操作。        redis.call(&#39;get&#39;, &#39;&#123;123&#125;abc&#39;);     redis.call(&#39;get&#39;, &#39;&#123;123&#125;def&#39;);  -- SLOT 计算将会用 123 计算    但是这样 SLOT 所在节点压力就会变大，不均衡原本这两个操作会分布在两个SLOT，但是现在都用一个SLOT执行，而且这样的做法业务不友好\n\nunable to connect to RedisURI 报错:# By default protected mode is enabled. You should disable it only if# you are sure you want clients from other hosts to connect to Redis# even if no authentication is configured, nor a specific set of interfaces# are explicitly listed using the &quot;bind&quot; directive.protected-mode no\n\nRedis Cluster 批量删除（shell）：#!/bin/bashif [ $# != 1 ]; then    echo &quot;Usage: ./del_redis.sh pattern&quot;    exitfi;ips=(192.168.1.1 192.168.1.2)ports=(6379 6380 6381)redis_cluster_ip=192.168.2.1redis_cluster_port=6379for ip in $&#123;ips[@]&#125;; do  for port in $&#123;ports[@]&#125;; do    echo &quot;ip: $&#123;ip&#125; port: $&#123;port&#125;&quot;    redis-cli -h $ip -p $port --scan --pattern &quot;$1&quot; | xargs -i redis-cli -h $ip -p $port del &#123;&#125;  done;done;redis_nodes=`redis-cli -h $redis_cluster_ip -p $redis_cluster_port -c cluster nodes | cut -d &#x27; &#x27; -f 2`for node in $redis_nodes; do    node_redis_ip=`echo &quot;$node&quot; | awk -F &#x27;:&#x27; &#x27;&#123;print $1&#125;&#x27;`    node_redis_port=`echo &quot;$node&quot; | awk -F &#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27;`    echo &quot;------- redis-cluster $&#123;node&#125; $&#123;node_redis_ip&#125; $&#123;node_redis_port&#125; flushall -------&quot;    redis-cli -h $node_redis_ip -p $node_redis_port -c flushalldone\n\n排行榜（c++ &amp; lua）：// redis zset score between -9007199254740992 and 9007199254740992// ( MAX_SCORE &amp; score ) &lt;&lt; 32 | timesecondsint64_t calc_score(int64_t base_value) &#123;    int64_t time_curr = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(std::chrono::system_clock::now().time_since_epoch()).count();    return ((MAX_SCORE &amp; base_value) &lt;&lt; 32) | (time_curr - SUB_TIME);&#125;--  前 count 名&quot;local count = KEYS[1];\\n&quot; +&quot;local revrange = redis.pcall(&#x27;ZREVRANGE&#x27;, &#x27;&quot;+ RANK_REDIS_ZSET_PVP_KEY + &quot;&#x27;, 0, count - 1);\\n&quot; +&quot;local result = &#123;&#125;;\\n&quot; +&quot;for _, v in ipairs(revrange) do\\n&quot; +&quot;  local ones = redis.pcall(&#x27;GET&#x27;, &#x27;&quot;+ RANK_REDIS_ONES_PVP_INFO + &quot;&#x27;..v);\\n&quot; +&quot;  table.insert(result, ones);\\n&quot; +&quot;end\\n&quot; +&quot;return result;\\n&quot;-- 自己的排名&quot;local user = KEYS[1];\\n&quot; +&quot;local revrank = redis.pcall(&#x27;ZREVRANK&#x27;, &#x27;&quot;+ RANK_REDIS_ZSET_PVP_KEY + &quot;&#x27;, user);\\n&quot; +&quot;local result = &#123;&#125;;\\n&quot; +&quot;if (revrank ~= false) then\\n&quot; +&quot;  local ones = redis.pcall(&#x27;GET&#x27;, &#x27;&quot;+ RANK_REDIS_ONES_PVP_INFO + &quot;&#x27;..user);\\n&quot; +&quot;  table.insert(result, tostring(revrank + 1));\\n&quot; +&quot;  table.insert(result, ones);\\n&quot; +&quot;else\\n&quot; +&quot;  table.insert(result, tostring(-1));\\n&quot; +&quot;  table.insert(result, &#x27;&#123;&#125;&#x27;);\\n&quot; +&quot;end\\n&quot; +&quot;return result;\\n&quot;;\n\n定时任务（lua）：key: 任务数据，score：时间戳local taskList = redis.pcall(&#x27;ZRANGEBYSCORE&#x27;, KEYS[1], ARGV[1], ARGV[2], &#x27;limit&#x27;, ARGV[3], ARGV[4]);for _, v in pairs(taskList) do    redis.call(&#x27;ZADD&#x27;,KEYS[1], ARGV[5], v)       -- 更新为下一个触发时间点, 避免任务丢失end;return taskList对于分布式系统，服务器间时间可能有些许差异，只关注超时触发的话可以使用redis拿到的时间- add task:local timestamp = redis.call(&#x27;TIME&#x27;);local timeout_ms = tonumber(timestamp[1]) * 1000 + tonumber(ARGV[2]);if (ARGV[3] == nil) then  return redis.call(&#x27;ZADD&#x27;, KEYS[1], timeout_ms, ARGV[1])else  return redis.call(&#x27;ZADD&#x27;, KEYS[1], ARGV[3], timeout_ms, ARGV[1])end- consume task:local timestamp = redis.call(&#x27;TIME&#x27;);local curr_ms = tonumber(timestamp[1]) * 1000 + tonumber(timestamp[2]) / 1000;local next_ms = curr_ms + tonumber(ARGV[5]);local taskList = redis.pcall(&#x27;ZRANGEBYSCORE&#x27;, KEYS[1], ARGV[1], curr_ms, &#x27;limit&#x27;, ARGV[3], ARGV[4]);for k,v  in pairs( taskList) do  redis.call(&#x27;ZADD&#x27;, KEYS[1], next_ms, v)end;return taskList分布式锁（java）：\n基于redis单线程模型+lua原子的特性\n\n前置条件是redis的lock和unlock是在业务的同一个线程里面的\n\nlock 任何情况下都会释放\n\n线程局部变量\npublic class IdThreadLocalHelper &#123;    private static ThreadLocal&lt;String&gt; idThreadLocal = new ThreadLocal();    IdThreadLocalHelper() &#123;    &#125;    public static void put(final String value) &#123;        idThreadLocal.set(value);    &#125;    public static String get() &#123;        return idThreadLocal.get();    &#125;&#125;\n加锁\npublic boolean lock(String key, long expireSecs) &#123;    final String uuid = IdUtils.getUUid();    IdThreadLocalHelper.put(uuid);    String result = redisStandalone.set(key, uuid, &quot;NX&quot;, &quot;EX&quot;, expireSecs);    return &quot;OK&quot;.equalsIgnoreCase(result);&#125;\n解锁\n@Overridepublic boolean unLock(String key) &#123;    final String requestId = IdThreadLocalHelper.get();    if(requestId == null) &#123;        return false;    &#125;    List&lt;String&gt; listKeys = new ArrayList&lt;&gt;();    listKeys.add(key);    String[] keys = listKeys.toArray(new String[0]);    String script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;;    int result = redisStandalone.eval(script, ScriptOutputType.INTEGER, keys, requestId);    return 1 == result;&#125;\n应用\nfinal String lockKey = &quot;test&quot;;boolean locked = lock(lockKey, 15);if (!locked) &#123;  // TODO: lock error  return;&#125;try &#123;  // TODO: logic&#125; finally &#123;    lobbyServiceRedis.lobbyUnlock(lockKey);&#125;\n\n\n重度redis lua使用的一些基础功能（lua）:\nlocal 前置声明定义local KEY_XXX = &#x27;test.lua.KEY_XXX&#x27;;local KEY_YYY = &#x27;test.lua.KEY_YYY&#x27;;\nfinal atomic 用于lua return 前更新版本号一类的东西\nany : 具体要返回的内容\ninc : 是否操作版本号变更（+1）\n\n\nlocal atomicInc = ARGV;local lua_oper = &#123;&#125;lua_oper.final = function(any, inc)  if inc == true then    if #atomicInc == 1 then      redis.call(&#x27;INCR&#x27;, KEY_ATOMIC_INC..atomicInc[1])    end  end  return any;end\nredis operator 一些常用的操作封装------------------------------------------------ redis operatorlocal redis_oper = &#123;&#125;redis_oper.zset_element = function(key, st, ed)  local elescores = redis.call(&#x27;ZRANGE&#x27;, key, st, ed, &#x27;WITHSCORES&#x27;);  local ele = &#123;&#125;;  local eleKey; local eleScore = 0;  for index, val in pairs(elescores) do    if index % 2 == 1 then eleKey = val;    else eleScore = tonumber(val);    end    ele[eleKey] = eleScore;  end  return ele;endredis_oper.zset_insert = function(key, ele, score)  return redis.call(&#x27;ZADD&#x27;, key, score, ele);endredis_oper.zset_rem = function(key, ele)  return redis.call(&#x27;ZREM&#x27;, key, ele);endredis_oper.zset_card = function(key)  return tonumber(redis.call(&#x27;ZCARD&#x27;, key));endredis_oper.set = function(key, key_plus, data)  return redis.call(&#x27;SET&#x27;, key..key_plus, data);endredis_oper.get = function(key, key_plus)  local res = redis.call(&#x27;GET&#x27;, key..key_plus);  if (res == nil or (type(res) == &#x27;boolean&#x27; and not res)) then    return nil;  end  return res;endredis_oper.del = function(key, key_plus)  return redis.call(&#x27;DEL&#x27;, key..key_plus);endredis_oper.exist = function(key, key_plus)  return tonumber(redis.call(&#x27;EXISTS&#x27;, key..key_plus));end\nlua algorithm 取集合常用的函数------------------------------------------------- lua algorithmlocal lua_res = &#123;&#125;-- 数组转化成键值对tablelua_res.new = function(list)  local tab = &#123;&#125;  for _, v in pairs(list) do    tab[v] = true  end  return tabend-- 并集 a,b为键值对形式的tableres.union = function(a, b)    local tab = &#123;&#125;    for k, _ in pairs(a) do tab[k] = true end    for k, _ in pairs(b) do tab[k] = true end    return res.changeToArr(tab)end-- 交集 a,b为键值对形式的tablelua_res.intersecion = function(a, b)  local tab = &#123;&#125;  for k, v in pairs(a) do    tab[k] = b[k]  end  return lua_res.change2arr(tab)end-- 键值对转换成数组lua_res.change2arr = function(tab)  local list = &#123;&#125;  for k, _ in pairs(tab) do    list[#list + 1] = k  end  return listend\n基于上面一系列的基础内容，剩下的就是写逻辑处理代码了，这样子的逻辑代码看起来更整齐也更干净\n\n备忘：一些 redis lua 需要注意的地方\nnumber 数值范围： range: [-(253)+1, (253)-1] (https://datatracker.ietf.org/doc/html/rfc7159#section-6)\nlua cjson 精度：10进制数字14字符，超过14 encode会以科学计数法表示，以至于丢失精度，这也是lua number2string 的问题。 (https://github.com/mpx/lua-cjson/issues/37)\n\nredis 内存置换策略\nnoeviction内存不足时直接报错 OOM command not allowed when used memory &gt; maxmemory；不会清理数据\nvolatile-ttl清理数据根据 ttl 时间（expire设置了生存时间的）从小到大依次清楚，不会清理 persist 的 key（没有过期时间的）；直到所有 expire 的 key 都清除了，报错 OOM\nvolatile-lru (默认)清理数据根据 expire key 按 lru 算法（最近最少使用）采样清除；直到所有 expire 的 key 都清除了，报错 OOM\nvolatile-random清理数据根据 expire key 随机清除；直到所有 expire 的 key 都清除了，报错 OOM\nallkeys-lru和 volatile-lru 的区别是不判断是否是 expire key；删除一个插入一个，不再报 OOM\nallkeys-random和 volatile-random 的区别是不判断是否是 expire key；删除一个插入一个，不再报 OOM\n\nredis 监控项\naof_enabled, AOF是否处于打开状态\naof_last_write_status, 记录最近一次AOF写的结果是成功还是失败\nblocked_clients, 正在等待阻塞命令（keys*, monitor, blpop, brpop, brpoplpush）的客户端数量\nclient_biggest_input_buf, 当前连接的客户端当中，最大输入缓存\nclient_longest_output_list, 当前连接的客户端当中，最长的输出列表\ncluster_enabled, 集群功能是否已经开启\nconnected_clients, 已连接客户端的数量（不包括通过slave服务器连接的客户端）\nconnected_slaves, 已连接的slave服务器数量\nevicted_keys, 因最大内存容量限制而被LRU算法置换出内存的键数量\nexpired_keys, 因过期而被自动删除的键数量\nkeyspace_hits, 查找键hit次数\nkeyspace_misses, 查找键miss次数\nlru_clock, 以分钟为单位进行自增的时钟，用于LRU管理\nmaster_link_status, slave节点复制连接当前的状态，up表示连接正常，down表示连接断开。\nmaxmemory, redis最大可用内存\nmaxmemory_policy, 内存不足时，数据清除策略，默认为volatile-lru。\n\nvolatile-lru：从已设置过期时间的数据集（server.db[i].expires）使用LRU算法淘汰。\n\n\n\nvolatile-ttl：从已设置过期时间的数据集（server.db[i].expires）采取TTL算法(最小存活时间)，移除即将过期的数据。\n\n\n\nvolatile-random：从已设置过期时间的数据集（server.db[i].expires）采取随机选取算法，并移除选中的K-V，直到”内存足够”为止，如果如果”过期集合”中全部移除全部移除仍不能满足，将OOM\n\n\n\nallkeys-lru：对所有数据（server.db[i].dict），采用LRU算法淘汰。\n\n\n\nallkeys-random：对所有的数据（server.db[i].dict）,采取”随机选取”算法,并移除选中的K-V,直到”内存足够”为止\n\n\n\nnoeviction：禁止驱逐数据，直接返回OOM异常\n\n\n\n\nmem_fragmentation_ratio, 碎片率，计算公式used_memory_rss&#x2F;used_memory\npubsub_channels, 当前被订阅的频道数量\npubsub_patterns, 当前被订阅的模式数量\nrdb_last_bgsave_status, 最近一次创建RDB文件的结果是成功还是失败\nrole, 本机在主从架构中的角色,master和slave两种选择\ntotal_commands_processed, 当前已执行的命令数量\ntotal_connections_received, 当前已接受的连接请求数量\nuptime_in_seconds, Redis服务器启动以来经过的秒数\nused_cpu_sys, Redis服务器耗费的系统CPU\nused_cpu_user, Redis服务器耗费的用户CPU\nused_memory, 由Redis分配器分配的内存总量\nused_memory_rss, 从操作系统的角度，返回Redis已分配的内存总量\ninstantaneous_ops_per_sec, 当前每秒钟执行的命令数量\n\nredis 内存相关\nredis内存相关的\n\nrdb持久化\nAOF重写\n内存剔除策略(高版本redis还存在着内存碎片整理的配置选项),\n其中AOF重写和rdb持久化都属于fork子进程来完成的。本次就以rdb持久化为例，rdb的持久化可以由持久化的配置策略或者命令行bgsave或者主从全同步触发。 redis在做bgsave的时候，fork出子进程来做bgsave。具体的过程如下:\nrdbSaveBackground()中fork子进程 —&gt; rdbSave() —&gt; rdbSaveRio()。\nfork后子进程拥有和父进程一模一样的进程空间，虽然采用了COW机制(父子进程的虚拟内存指向相同的物理page)，但是ps或者top命令中的RSS显示的值都会算成自己进程所占的物理内存，这个可能是很多运维同学&#x2F;DBA同学经常可以眼见的现象，恐怕这个就是潜意识里需要内存预留一半的重要因素。\n\n\nLinux下的进程下的地址都是虚拟地址，CPU使用的也是虚拟地址，Linux将每个进程的地址空间人为地分为用户地址空间和内核地址空间\n\n32位下  0-3G为用户地址空间，3-4G为内核地址空间(每个进程都是这样),\n64位下，0-128T 为用户地址空间，高位-128T为内核地址空间。\n进程中的虚拟地址和内存物理地址存在映射关系，这个映射关系由进程的页表pte来维护。\n虚拟地址和物理地址是多对1或者1对1的关系。Linux默认情况下fork子进程会采用写时复制(Copy On Write)。\n为了解决默认glibc内存分配器的性能和碎片率问题,redis引入了jemalloc,并成为默认配置。\n\n\nLinux的fork COW机制\n\n在内核层面看，fork 创建一个进程的动作:\ndo_fork()\ncopy_process()\ncopy_mm()\ndup_mm()\ndump_nmap()\ncopy_page_range()\ncopyp4d_range()\ncopy_pmd_range()\ncopy_pte_range()\ncopy_one_pte()\nptep_set_wrprotect()\n\n\n大体上的功能就是:复制当前进程的结构，复制当前进程路径，文件句柄，信号，namespace, 虚拟内存(当然包含页目录和页表)，内核栈, CPU体系结构相关信息, 在复制页表的过程中，内核会将物理page权限为设置为只读，一旦父进程\n修改物理page的时候，会触发page fault, 内核在异常处理过程中通过pgd_alloc重新分配物理page,将先前物理page中的数据复制到新分配的物理page,同时修改父进程中页表和物理page的映射关系。(参见ULK 2.4和3.3)\n\n\n从理论上看，redis 在fork bgsave的时候，是不会让内存翻倍的， 那么是不是只要父进程的内存管够，就可以安全地进行bgsave呢？\n\n\n在bgsave期间，业务产生的’update’类数据量(新增&#x2F;修改)。\n\n\n\nredis运行过程中rehash产生的内存消耗。\n\n\n\n\n\n","categories":["知识备忘"],"tags":["常用备忘","redis"]},{"title":"备忘","url":"/archives/30c2270c.html","content":"\n\nnext theme 主题修改部署不同步解决：https://juejin.im/post/6844904106503438343\nHTML 常用颜色表酒紅色紅色橘色金色黃色\t綠色墨綠色\t青色深藍色\t粉紅色紫色\t灰色  \n","categories":["备忘"],"tags":["常用备忘"]},{"title":"mysql sequence 生成 & 遇到的问题","url":"/archives/9e52da14.html","content":"sql语句自动插入有规则的uuid（雪花算法)建议还是给表结构放一个默认的自增_id\ndrop table if EXISTS test01;create table test01 (seq_id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, `index` INT UNSIGNED NOT NULL); drop table if EXISTS new_test01;create table new_test01 (`index` INT UNSIGNED NOT NULL); insert into new_test01 values (0), (1), (2), (3), (4), (5), (6), (7), (8), (9),(10), (11), (12), (13), (14), (15), (16), (17), (18), (19); DROP TRIGGER IF EXISTS `trigger_01`;    CREATE        TRIGGER `trigger_01` BEFORE INSERT        ON `test01`        FOR EACH ROW BEGIN        DECLARE    `seq_id` BIGINT UNSIGNED;        DECLARE    `now_millis` BIGINT UNSIGNED;        DECLARE    `our_epoch` BIGINT UNSIGNED DEFAULT 1446307200000;        SET `now_millis` = (SELECT UNIX_TIMESTAMP(NOW(3)) * 1000);        SET `seq_id` = (SELECT AUTO_INCREMENT FROM information_schema.`TABLES` WHERE table_schema = &#x27;testauto_1&#x27; AND table_name = &#x27;test01&#x27;);        SET NEW.seq_id = (SELECT ((`now_millis` - `our_epoch`) &lt;&lt; 23) | (MOD(2, 256) &lt;&lt; 15) | MOD (`seq_id`, 32768));    END; DROP PROCEDURE IF EXISTS `pro_01`;create PROCEDURE pro_01(in num int unsigned)BEGINDECLARE i int DEFAULT 0;    REPEAT        insert into `testauto_1`.test01 (`index`) ( select `index` from testauto_1.new_test01 );        set i = i+1;    UNTIL i&gt;num    END REPEAT;END; call pro_01(7000); select * from test01 where `index`=1;\n到1638次的时候一定会失败，这个为什么？？\ndrop table if EXISTS test02;create table test02 (seq_id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, `index` INT UNSIGNED NOT NULL);drop table if EXISTS test02_seq;create table test02_seq (seq_id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY); DROP TRIGGER IF EXISTS `trigger_02`;    CREATE        TRIGGER `trigger_02` BEFORE INSERT        ON `test02`        FOR EACH ROW BEGIN        DECLARE    `seq_id` BIGINT UNSIGNED;        DECLARE    `now_millis` BIGINT UNSIGNED;        DECLARE    `our_epoch` BIGINT UNSIGNED DEFAULT 1446307200000;        SET `now_millis` = (SELECT UNIX_TIMESTAMP(NOW(3)) * 1000);        SET `seq_id` = (SELECT AUTO_INCREMENT FROM information_schema.`TABLES` WHERE table_schema = &#x27;testauto_1&#x27; AND table_name = &#x27;test02_seq&#x27;);        SET NEW.seq_id = (SELECT ((`now_millis` - `our_epoch`) &lt;&lt; 23) | (MOD(2, 256) &lt;&lt; 15) | MOD (`seq_id`, 32768));        INSERT into test02_seq values (NULL);    END; DROP PROCEDURE IF EXISTS `pro_02`;create PROCEDURE pro_02(in num int unsigned)BEGINDECLARE i int DEFAULT 0;    REPEAT        insert into `testauto_1`.test02 (`index`) ( select `index` from testauto_1.new_test01 );        set i = i+1;    UNTIL i&gt;num    END REPEAT;END; call pro_02(7000); select * from test02 where `index`=1;\n改成这样就可以解决这个问题，但是没弄明白为什么\ncpp 的方法// 用C++11实现自取seq，有些情况是异步数据库，但是程序需要先知道seq做keyunsigned long long g_seq_id_x = 0; unsigned long long get_seq_id_x()&#123;    unsigned long long _mill_now = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(std::chrono::system_clock::now().time_since_epoch()).count();    unsigned long long _mill_end = _mill_now - 1446307200000;    g_seq_id_x += 1;    return ((_mill_end &lt;&lt; 23) | (1 &lt;&lt; 18) | (2 &lt;&lt; 10) | (g_seq_id_x &amp; 0x3FF));&#125;\n\n备忘存储过程获取sql执行的错误信息\ndrop procedure if exists `procedure_test_01`;create procedure `procedure_test_01` (out xmsg varchar(1024))BEGIN    DECLARE _sql varchar(500);    DECLARE _code char(5) DEFAULT &#x27;00000&#x27;;    DECLARE _msg TEXT;    DECLARE CONTINUE HANDLER FOR SQLEXCEPTION GET DIAGNOSTICS CONDITION 1 _code=RETURNED_SQLSTATE, _msg=MESSAGE_TEXT;    START TRANSACTION;    -- do sql ....    IF _code=&#x27;00000&#x27; THEN        COMMIT;        SET xmsg=&#x27;successed&#x27;;    ELSE        ROLLBACK;        SET xmsg=CONCAT(&#x27;failed,error=&#x27;,_code,&#x27;, message=&#x27;,_msg);    END IF;    SELECT xmsg AS resmsg_out;END\n","categories":["知识积累"],"tags":["mysql"]},{"title":"性能优先的排序双向链表","url":"/archives/a0c5097a.html","content":"说明这是一个表头用网状的排序双向链表结构托管类原本开发的原因是游戏服务器根据玩家战斗力排序的容器更新 &amp; 查找效率不理想，希望有个新的方法替代因为战斗力变化频率比较高，多个用户又可能是相同的战斗力，所以做了这个类似跳跃表的结构对数据分段\nenum EN_GRIDDING_SORT&#123;\ten_grd_sort_up,\ten_grd_sort_down,&#125;; template&lt;class _Ty&gt;struct gridding_node&#123;\t_Ty _value;\tstruct gridding_node* _prev;\tstruct gridding_node* _next; \tstruct gridding_node* _upper;\tstruct gridding_node* _downer; \tgridding_node()\t\t: _prev(NULL)\t\t, _next(NULL)\t\t, _upper(NULL)\t\t, _downer(NULL)\t&#123;\t&#125; \tbool is_header()\t&#123;\t\treturn _upper != NULL || _downer != NULL;\t&#125;&#125;; ////// 网状双向链表托管（类似跳跃表）/// H1 = N11 = N12 = N13..../// ||/// H2 = N21 = N22..../// ||/// H3 = N31 = N32....///template&lt;class _Ty, class _Ty_rule, EN_GRIDDING_SORT en&gt;class gridding_list&#123;\ttypedef _Ty_rule(*FUNC_rule)(const _Ty&amp; value);\ttypedef bool(*FUNC_search_filter)(const _Ty&amp; value);private:\tgridding_node&lt;_Ty&gt;* m_pHeader;\tFUNC_rule m_pFuncRule;private:\tstatic gridding_node&lt;_Ty&gt;* create_header(const _Ty &amp; value)\t&#123;\t\tgridding_node&lt;_Ty&gt;* pNewer = new gridding_node&lt;_Ty&gt;();\t\tpNewer-&gt;_value = value; \t\tgridding_node&lt;_Ty&gt;* pNewerNode = create_node(value);\t\tpNewer-&gt;_next = pNewerNode;\t\tpNewerNode-&gt;_prev = pNewer; \t\treturn pNewer;\t&#125;\tstatic gridding_node&lt;_Ty&gt;* create_node(const _Ty &amp; value)\t&#123;\t\tgridding_node&lt;_Ty&gt;* pNewer = new gridding_node&lt;_Ty&gt;();\t\tpNewer-&gt;_value = value; \t\treturn pNewer;\t&#125; private:\tgridding_list()\t&#123; \t&#125; \tgridding_node&lt;_Ty&gt;* row_head(gridding_node&lt;_Ty&gt;* node)\t&#123;\t\tgridding_node&lt;_Ty&gt;* head = node;\t\tif (node)\t\t&#123;\t\t\twhile (head-&gt;_prev)\t\t\t\thead = head-&gt;_prev;\t\t&#125;\t\treturn head;\t&#125; \tgridding_node&lt;_Ty&gt;* row_end(gridding_node&lt;_Ty&gt;* node)\t&#123;\t\tgridding_node&lt;_Ty&gt;* end = node;\t\tif (node)\t\t&#123;\t\t\twhile (end-&gt;_next)\t\t\t\tend = end-&gt;_next;\t\t&#125;\t\treturn end;\t&#125; public:\tgridding_list(FUNC_rule fnRule)\t\t: m_pHeader(NULL)\t\t, m_pFuncRule(fnRule)\t&#123;\t&#125; \tbool insert(const _Ty &amp; value)\t&#123;\t\tif (m_pFuncRule == NULL)\t\t\treturn false;\t\tif (m_pHeader == NULL)\t\t&#123;\t\t\tm_pHeader = create_header(value);\t\t\treturn true;\t\t&#125; \t\tgridding_node&lt;_Ty&gt;* pRow = NULL; \t\tif (m_pFuncRule(m_pHeader-&gt;_value) == m_pFuncRule(value))\t\t\tpRow = m_pHeader;\t\telse if ((m_pFuncRule(m_pHeader-&gt;_value) &gt; m_pFuncRule(value) &amp;&amp; en == en_grd_sort_up) \t\t\t|| (m_pFuncRule(m_pHeader-&gt;_value) &lt; m_pFuncRule(value) &amp;&amp; en == en_grd_sort_down))\t\t&#123;\t\t\tpRow = create_header(value);\t\t\tpRow-&gt;_downer = m_pHeader;\t\t\tm_pHeader-&gt;_upper = pRow;\t\t\tm_pHeader = pRow;\t\t\treturn true;\t\t&#125;\t\telse\t\t&#123;\t\t\tgridding_node&lt;_Ty&gt;* pCurr = m_pHeader;\t\t\twhile (pCurr-&gt;_downer)\t\t\t&#123;\t\t\t\tif (m_pFuncRule(pCurr-&gt;_downer-&gt;_value) == m_pFuncRule(value))\t\t\t\t&#123;\t\t\t\t\tpRow = pCurr-&gt;_downer;\t\t\t\t\tbreak;\t\t\t\t&#125;\t\t\t\telse if ((m_pFuncRule(pCurr-&gt;_downer-&gt;_value) &gt; m_pFuncRule(value) &amp;&amp; en == en_grd_sort_up) \t\t\t\t\t|| (m_pFuncRule(pCurr-&gt;_downer-&gt;_value) &lt; m_pFuncRule(value) &amp;&amp; en == en_grd_sort_down))\t\t\t\t&#123;\t\t\t\t\tpRow = create_header(value);\t\t\t\t\tpRow-&gt;_downer = pCurr-&gt;_downer;\t\t\t\t\tpRow-&gt;_upper = pCurr;\t\t\t\t\tpCurr-&gt;_downer-&gt;_upper = pRow;\t\t\t\t\tpCurr-&gt;_downer = pRow;\t\t\t\t\treturn true;\t\t\t\t&#125;\t\t\t\telse\t\t\t\t\tpCurr = pCurr-&gt;_downer;\t\t\t&#125;\t\t\tif (pRow == NULL)\t\t\t&#123;\t\t\t\tif (pCurr)\t\t\t\t&#123;\t\t\t\t\tpRow = create_header(value);\t\t\t\t\tpRow-&gt;_upper = pCurr;\t\t\t\t\tpCurr-&gt;_downer = pRow;\t\t\t\t\treturn true;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125; \t\tif (pRow == NULL || pRow-&gt;_next == NULL)\t\t\treturn false; \t\tgridding_node&lt;_Ty&gt;* pCurrNode = pRow-&gt;_next; \t\twhile (pCurrNode)\t\t&#123;\t\t\tif (pCurrNode-&gt;_value == value)\t\t\t&#123;\t\t\t\tpCurrNode-&gt;_value.merge(value);\t\t\t\treturn true;\t\t\t&#125;\t\t\telse if ((pCurrNode-&gt;_value &gt; value &amp;&amp; en == en_grd_sort_up) \t\t\t\t|| (pCurrNode-&gt;_value &lt; value &amp;&amp; en == en_grd_sort_down))\t\t\t&#123;\t\t\t\tgridding_node&lt;_Ty&gt;* pCol = create_node(value); \t\t\t\tpCol-&gt;_next = pCurrNode;\t\t\t\tpCol-&gt;_prev = pCurrNode-&gt;_prev;\t\t\t\tpCurrNode-&gt;_prev-&gt;_next = pCol;\t\t\t\tpCurrNode-&gt;_prev = pCol;\t\t\t\treturn true;\t\t\t&#125;\t\t\telse\t\t\t&#123;\t\t\t\tif (pCurrNode-&gt;_next == NULL)\t\t\t\t&#123;\t\t\t\t\tgridding_node&lt;_Ty&gt;* pCol = create_node(value);\t\t\t\t\tpCurrNode-&gt;_next = pCol;\t\t\t\t\tpCol-&gt;_prev = pCurrNode;\t\t\t\t\treturn true;\t\t\t\t&#125;\t\t\t\telse\t\t\t\t\tpCurrNode = pCurrNode-&gt;_next;\t\t\t&#125;\t\t&#125;\t\treturn false;\t&#125; \t_Ty * search(const _Ty&amp; value)\t&#123;\t\tif (m_pFuncRule == NULL)\t\t\treturn NULL;\t\tgridding_node&lt;_Ty&gt;* pCurr = m_pHeader;\t\twhile (pCurr)\t\t&#123;\t\t\tif (pCurr)\t\t\t&#123;\t\t\t\tif (m_pFuncRule(pCurr-&gt;_value) == m_pFuncRule(value))\t\t\t\t\tbreak;\t\t\t&#125;\t\t\tpCurr = pCurr-&gt;_downer;\t\t&#125; \t\tif (pCurr)\t\t&#123;\t\t\tpCurr = pCurr-&gt;_next;\t\t\twhile (pCurr)\t\t\t&#123;\t\t\t\tif (pCurr-&gt;_value == value)\t\t\t\t\treturn &amp;(pCurr-&gt;_value);\t\t\t\tpCurr = pCurr-&gt;_next;\t\t\t&#125;\t\t&#125; \t\treturn NULL;\t&#125; \t// 按半径搜索\tbool search_radius(const _Ty&amp; center, uint32_t dwRadius, std::vector&lt;_Ty&gt;&amp; vecRes)\t&#123;\t\tif (m_pFuncRule == NULL)\t\t\treturn false; \t\tgridding_node&lt;_Ty&gt;* pCurr = m_pHeader;\t\twhile (pCurr)\t\t&#123;\t\t\tif (m_pFuncRule(pCurr-&gt;_value) == m_pFuncRule(center))\t\t\t\tbreak;\t\t\tpCurr = pCurr-&gt;_downer;\t\t&#125; \t\tif (pCurr)\t\t&#123;\t\t\tpCurr = pCurr-&gt;_next;\t\t\twhile (pCurr)\t\t\t&#123;\t\t\t\tif (pCurr-&gt;_value == center)\t\t\t\t\tbreak;\t\t\t\tpCurr = pCurr-&gt;_next;\t\t\t&#125;\t\t&#125; \t\tif (pCurr == NULL)\t\t\treturn false; \t\tvecRes.push_back(pCurr-&gt;_value); \t\tgridding_node&lt;_Ty&gt;* pCenter = pCurr; \t\t// 向前\t\tfor (uint32_t i = 1; i &lt; dwRadius; ++i)\t\t&#123;\t\t\tif (pCurr-&gt;_prev &amp;&amp; pCurr-&gt;_prev-&gt;is_header() == false)\t\t\t&#123;\t\t\t\tpCurr = pCurr-&gt;_prev;\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t&#125;\t\t\telse\t\t\t&#123;\t\t\t\t// upper row\t\t\t\tgridding_node&lt;_Ty&gt;* pRowHead = row_head(pCurr);\t\t\t\tif (pRowHead &amp;&amp; pRowHead-&gt;_upper)\t\t\t\t&#123;\t\t\t\t\t// 取尾部\t\t\t\t\tpCurr = row_end(pRowHead-&gt;_upper);\t\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t\t&#125;\t\t\t\telse\t\t\t\t\tbreak;\t\t\t&#125;\t\t&#125; \t\tpCurr = pCenter;\t\t// 向后\t\tfor (uint32_t i = 1; i &lt; dwRadius; ++i)\t\t&#123;\t\t\tif (pCurr-&gt;_next)\t\t\t&#123;\t\t\t\tpCurr = pCurr-&gt;_next;\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t&#125;\t\t\telse\t\t\t&#123;\t\t\t\t// downer row\t\t\t\tgridding_node&lt;_Ty&gt;* pRowHead = row_head(pCurr);\t\t\t\tif (pRowHead &amp;&amp; pRowHead-&gt;_downer)\t\t\t\t&#123;\t\t\t\t\tpCurr = pRowHead-&gt;_downer-&gt;_next;\t\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t\t&#125;\t\t\t\telse\t\t\t\t\tbreak;\t\t\t&#125;\t\t&#125;\t\treturn true;\t&#125; \t// 按照自定规则搜索\tbool search_filter(const _Ty&amp; center, FUNC_search_filter fnFilter, std::vector&lt;_Ty&gt;&amp; vecRes)\t&#123;\t\tif (m_pFuncRule == NULL)\t\t\treturn false; \t\tgridding_node&lt;_Ty&gt;* pRow = m_pHeader;\t\twhile (pRow)\t\t&#123;\t\t\tif (m_pFuncRule(pRow-&gt;_value) == m_pFuncRule(center))\t\t\t\tbreak;\t\t\tpRow = pRow-&gt;_downer;\t\t&#125; \t\t// 这里只找行，列就不找了 \t\tif (pRow == NULL)\t\t\treturn false;\t\t\t\tgridding_node&lt;_Ty&gt;* pCurr = pRow-&gt;_next;\t\tif (pCurr == NULL)\t\t\treturn false; \t\tif(fnFilter == NULL || fnFilter(pCurr-&gt;_value))\t\t\tvecRes.push_back(pCurr-&gt;_value); \t\t// 向前\t\twhile(true)\t\t&#123;\t\t\tif (pCurr-&gt;_prev &amp;&amp; pCurr-&gt;_prev-&gt;is_header() == false)\t\t\t&#123;\t\t\t\tpCurr = pCurr-&gt;_prev; \t\t\t\tif (fnFilter == NULL || fnFilter(pCurr-&gt;_value))\t\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t\telse\t\t\t\t\tbreak; // 因为是排序表，fnFilter认为是已知该规则的筛选，如果出现不符的，前面的都不处理了\t\t\t&#125;\t\t\telse\t\t\t&#123;\t\t\t\t// upper row\t\t\t\tgridding_node&lt;_Ty&gt;* pRowHead = row_head(pCurr);\t\t\t\tif (pRowHead &amp;&amp; pRowHead-&gt;_upper)\t\t\t\t&#123;\t\t\t\t\tpCurr = row_end(pRowHead-&gt;_upper); \t\t\t\t\tif (fnFilter == NULL || fnFilter(pCurr-&gt;_value))\t\t\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t\t\telse\t\t\t\t\t\tbreak; // 因为是排序表，fnFilter认为是已知该规则的筛选，如果出现不符的，前面的都不处理了\t\t\t\t&#125;\t\t\t\telse\t\t\t\t\tbreak;\t\t\t&#125;\t\t&#125; \t\tpCurr = pRow-&gt;_next;\t\t// 向后\t\twhile (true)\t\t&#123;\t\t\tif (pCurr-&gt;_next)\t\t\t&#123;\t\t\t\tpCurr = pCurr-&gt;_next; \t\t\t\tif (fnFilter == NULL || fnFilter(pCurr-&gt;_value))\t\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t\telse\t\t\t\t\tbreak; // 因为是排序表，fnFilter认为是已知该规则的筛选，如果出现不符的，后面的都不处理了\t\t\t&#125;\t\t\telse\t\t\t&#123;\t\t\t\t// downer row\t\t\t\tgridding_node&lt;_Ty&gt;* pRowHead = row_head(pCurr);\t\t\t\tif (pRowHead &amp;&amp; pRowHead-&gt;_downer)\t\t\t\t&#123;\t\t\t\t\tpCurr = pRowHead-&gt;_downer-&gt;_next; \t\t\t\t\tif (fnFilter == NULL || fnFilter(pCurr-&gt;_value))\t\t\t\t\t\tvecRes.push_back(pCurr-&gt;_value);\t\t\t\t\telse\t\t\t\t\t\tbreak; // 因为是排序表，fnFilter认为是已知该规则的筛选，如果出现不符的，后面的都不处理了\t\t\t\t&#125;\t\t\t\telse\t\t\t\t\tbreak;\t\t\t&#125;\t\t&#125;\t\treturn true;\t&#125; \tuint32_t rank(const _Ty&amp; value)\t&#123;\t\tuint32_t dwRank = 0;\t\tif (m_pFuncRule == NULL)\t\t\treturn dwRank; \t\tgridding_node&lt;_Ty&gt;* pCurr = m_pHeader;\t\twhile (pCurr)\t\t&#123;\t\t\tpCurr = pCurr-&gt;_next;\t\t\twhile (pCurr)\t\t\t&#123;\t\t\t\tdwRank += pCurr-&gt;_value.size();\t\t\t\tif (pCurr-&gt;_value == center)\t\t\t\t\tbreak;\t\t\t\tpCurr = pCurr-&gt;_next;\t\t\t&#125;\t\t\t\t\t\tif (m_pFuncRule(pCurr-&gt;_value) == m_pFuncRule(center))\t\t\t\tbreak; \t\t\tpCurr = pCurr-&gt;_downer;\t\t&#125; \t\treturn dwRank;\t&#125;&#125;; // 测试用例#include &lt;vector&gt;struct grid_test_data&#123;\tuint32_t _key;\tstd::vector&lt;uint32_t&gt; _value;\tuint32_t _count; \tgrid_test_data()\t\t: _key(0)\t\t, _count(1)\t&#123;\t&#125; \tgrid_test_data(uint32_t a)\t&#123;\t\t_key = a;\t\t_count = 1;\t&#125; \tgrid_test_data&amp; operator = (const grid_test_data&amp; td)\t&#123;\t\t_key = td._key;\t\t_value.clear();\t\t_value = td._value;\t\treturn *this;\t&#125; \tbool operator == (const grid_test_data&amp; td)\t&#123;\t\treturn _key == td._key;\t&#125; \tbool operator &gt; (const grid_test_data&amp; td)\t&#123;\t\treturn _key &gt; td._key;\t&#125; \tbool operator &lt; (const grid_test_data&amp; td)\t&#123;\t\treturn _key &lt; td._key;\t&#125; \tfriend std::ostream&amp; operator &lt;&lt; (std::ostream&amp; out, const grid_test_data&amp; td)\t&#123;\t\tout &lt;&lt; td._key &lt;&lt; &quot;(&quot; &lt;&lt; td._count &lt;&lt; &quot;)&quot;;\t\treturn out;\t&#125; \tvoid merge(const grid_test_data&amp; td)\t&#123;\t\t_value.insert(_value.end(), td._value.begin(), td._value.end());\t\t_count += td._count;\t&#125; \tuint32_t key()\t&#123;\t\treturn _key;\t&#125;\tuint32_t key() const\t&#123;\t\treturn _key;\t&#125;\tuint32_t count()\t&#123;\t\treturn _count;\t&#125;\tuint32_t count() const\t&#123;\t\treturn _count;\t&#125; \tstd::vector&lt;uint32_t&gt;&amp; value()\t&#123;\t\treturn _value;\t&#125;&#125;;\n\n测试代码template&lt;class _T&gt;  uint32_t rule_calc_row(const _T&amp; value)  &#123;      return value.key() / 100;  &#125;    random_help rh;  gridding_list&lt;grid_test_data, uint32_t, en_grd_sort_up&gt; g_list(rule_calc_row&lt;grid_test_data&gt;);  for (int i = 0; i &lt; 1024 * 1024; ++i)  &#123;      grid_test_data td01(rh(1, 10240));      if (g_list.insert(td01) == false)      &#123;          std::cout &lt;&lt; __FUNCTION__ &lt;&lt; &quot;,&quot; &lt;&lt; __LINE__ &lt;&lt; td01.key() &lt;&lt; std::endl;          break;      &#125;  &#125;  \n\n测试结果上面是测试用的规则、测试代码，random_help是之前写的一个随机函数类 centos开发环境 1024 * 1024 分散量级 10240的数据实际插入耗时是4.6s 单条查找耗时 &lt; 1ms\n","categories":["代码"],"tags":["C++"]},{"title":"游戏小地图的组装","url":"/archives/ed0f38cf.html","content":"说明游戏里随机地图的需求地图内容不是完全随机的，而是由多张小地图组合而成的多个小地图的组合规则由点的连接来做法是先把两张地图逻辑上放到一个超大地图里，再根据需要合并的两个点移动两块合并\n地图组装代码int array_1[][4] = &#123;    &#123;1, 1, 1, 1&#125;,    &#123;3, 3, 3, 3&#125;,    &#123;5, 5, 5, 7&#125;,&#125;;int array_2[][5] = &#123;    &#123;2, 2, 2, 2, 2&#125;,    &#123;4, 4, 4, 4, 4&#125;,    &#123;6, 6, 6, 6, 6&#125;,    &#123;8, 8, 8, 8, 8&#125;,&#125;;enum array_dir&#123;    en_left,    en_right,    en_top,    en_down,&#125;;vector&lt;vector&lt;int&gt; &gt; new_array;void init_new_array()&#123;    int _1_x = sizeof(array_1) / sizeof(array_1[0]);    int _1_y = sizeof(array_1[0]) / sizeof(array_1[0][0]);    int _2_x = sizeof(array_2) / sizeof(array_2[0]);    int _2_y = sizeof(array_2[0]) / sizeof(array_2[0][0]);    int max_x = _1_x + _2_x + 1;    int max_y = _1_y + _2_y + 1;    for (x..)    &#123;        vector&lt;int&gt; line;        for (y..)        &#123;            line.push_back(0);        &#125;        new_array.push_back(line);    &#125;&#125;void insert_top_left(vector&lt;vector&lt;int&gt; &gt;&amp; _array, int _x, int _y)&#123;    for (x = 0; x &lt; _x; ++x)    &#123;        for (y = 0; y &lt; _y; ++y)        &#123;            new_array[x][y] = _array[x][y];        &#125;    &#125;&#125;void insert_down_right(vector&lt;vector&lt;int&gt; &gt;&amp; _array, int _x, int _y, int _pos_x, int _pos_y)&#123;    for (x = _pos_x; x &lt; _x + _pos_x; ++x)    &#123;        for (y = _pos_y; y &lt; _y + _pos_y; ++y)        &#123;            new_array[x][y] = _array[x - _pos_x][y - _pos_y];        &#125;    &#125;&#125;void mv_top_down(int _x, int _y)&#123;    for (int x = _x - 1; x &gt;= 0; --x)    &#123;        for (int y = 0; y &lt; _y; ++y)        &#123;            new_array[x + 1][y] = new_array[x][y];        &#125;    &#125;    for (int y = 0; y &lt; _y; ++y)        new_array[0][y] = 0;&#125;void mv_top_right(int _x, int _y)&#123;    for (int x = 0; x &lt; _x; ++x)    &#123;        for (int y = _y - 1; y &gt;= 0; --y)        &#123;            new_array[x][y + 1] = new_array[x][y];        &#125;    &#125;    for (int x = 0; x &lt; _x; ++x)    &#123;        new_array[x][0] = 0;    &#125;&#125;void mv_down_top(int _x, int _y, int _max_x, int _max_y)&#123;    for (int x = _x; x &lt; _max_x; ++x)    &#123;        for (int y = _y; y &lt; _max_y; ++y)        &#123;            new_array[x - 1][y] = new_array[x][y];        &#125;    &#125;    for (int y = _y; y &lt; _max_y; ++y)        new_array[_max_x - 1][y] = 0;&#125;void mv_down_left(int _x, int _y, int _max_x, int _max_y)&#123;    for (int x = _x; x &lt; _max_x; ++x)    &#123;        for (int y = _y; y &lt; _max_y; ++y)        &#123;            new_array[x][y - 1] = new_array[x][y];        &#125;    &#125;    for (int x = _x; x &lt; _max_x; ++x)        new_array[x][_max_y - 1] = 0;&#125;\n\n生成地图的测试代码方式1\nint _1_check_x = 2;int _1_check_y = 3;int _2_check_x = 3;int _2_check_y = 0;int _1_curr_check_x = _1_check_x;int _2_curr_check_x = _2_check_x + _1_x + 1;bool suit = false;int mv_top_count = 0;for (; mv_top_count &lt; _1_x _ 1;)&#123;    mv_down_top(_1_x + 1 - mv_top_count, _1_y + 1, max_x, max_y);    ++mv_top_count;    --_2_curr_check_x;    if(_1_curr_check_x == _2_curr_check_x)    &#123;        suit = true;        break;    &#125;&#125;if (suit == false)&#123;    int mv_down_count = 0;    for (; mv_down_count &lt; _2_x + 1;)    &#123;        mv_top_down(_1_x, _1_y);        ++mv_down_count;        ++_1_curr_check_x;        if (_1_curr_check_x == _2_curr_check_x)        &#123;            suit = true;            break;        &#125;    &#125;&#125;\n方式2\nint _1_check_x = 2;int _1_check_y = 0;int _2_check_x = 0;int _2_check_y = 4;int _1_curr_check_y = _1_check_y;int _2_curr_check_y = _2_check_y + _1_y + 1;int mv_left_count = 0;for (; mv_left_count &lt; _1_y + 1;)&#123;    mv_down_left(_1_x + 1， _1_y + 1 - mv_left_count, max_x, max_y);    ++mv_left_count;    --_2_curr_check_y;    if (_1_curr_check_y == _2_curr_check_y)    &#123;        suit = true;        break;    &#125;&#125;if (suit == false)&#123;    int mv_right_count = 0;    for (; mv_right_count &lt; _2_y + 1;)    &#123;        mv_top_right(_1_x, _1_y + mv_right_count);        ++mv_right_count;        ++_1_curr_check_y;        if (_1_curr_check_y == _2_curr_check_y)        &#123;            suit = true;            break;        &#125;    &#125;&#125;\n\n补充该方法可以根据逻辑增加合适的策略规则  譬如统计链接方向选择下一个链接的方向，尽量让地图生成为方形而不是长条  如果chunk定义了链接方向，可以加入chunk的旋转和镜像，用于地图链接，避免出现因为定义了方向地图拼接失败的情况….\n","categories":["代码"],"tags":["C++"]},{"title":"腾讯tlog模拟实现","url":"/archives/2c8da671.html","content":"说明基于腾讯tlog接口实现具体代码接入腾讯的项目都要接入tlog事件日志收集系统，但是很多项目后期才会接入做了这个符合tlog接口的功能，这样游戏前期就可以有自己的event-log用了数据配置规则参考\n接入层代码（伪）// tlog_interface.hnamespace tlog&#123;\tclass tlog_category_interface;\tclass tlog_ctx_interface;&#125;; typedef tlog::tlog_ctx_interface* LPTLOGCTX;typedef tlog::tlog_category_interface* LPLOGCATEGORYINST; LPTLOGCTX tlog_init_from_file(const char*);LPLOGCATEGORYINST tlog_get_category(LPTLOGCTX, const char*); void tlog_info(LPLOGCATEGORYINST, size_t, size_t, const char*); int tlog_fini_ctx(LPTLOGCTX*); // tlog_base.hnamespace tlog&#123;class tlog_category_interface&#123;\tpublic:\t\t~tlog_category_interface()&#123;&#125;\t\tvirtual void exec(const char*) = 0;\t\tvirtual int release() = 0;&#125;; class tlog_ctx_interface&#123;\tpublic:\t\t~tlog_ctx_interface()&#123;&#125;\t\tvirtual tlog_category_interface* get_category(const char*) = 0;\t\tvirtual int release();&#125;; enum EN_DRVICE_TYPE&#123;\ten_device_file,\ten_device_net,&#125;; struct stDevice&#123;\tEN_DRVICE_TYPE _enType;\tstDevice(EN_DRVICE_TYPE enType)\t\t:_enType(enType)\t&#123;&#125;\tvirtual EN_DRVICE_TYPE get_type() &#123; return _enType; &#125;\t\tvirtual bool init(pugi::xml_node node) = 0;\tvirtual int release() = 0;\tvirtual void exec(const char* pszData) = 0;&#125;; struct stDeviceFile : public stDevice&#123;\tstd::string _pattern; // 路径\tuint32_t _bufferSize; // 大小\tstd::string _data;    // 内容\tstd::ofstream _out;   // 句柄\t\tstDeviceFile()\t\t: stDevice(en_device_file)\t&#123;&#125;\t\tvirtual bool init(pugi::xml_node node)\t&#123;\t\t// 初始化数据成员\t\t// 打开要写的文件\t&#125;\tvirtual int release()\t&#123;\t\t// 如果 _data 里面还有内容，写入到文件\t\t// 关闭文件\t&#125;\tvirtual void exec(const char* pStr)\t&#123;\t\t_data.append(pStr);\t\t_data.append(&quot;\\n&quot;);\t\tif (_data.size() &gt;= _bufferSize)\t\t&#123;\t\t\t_out &lt;&lt; _data;\t\t\t_data.clear();\t\t&#125;\t&#125;&#125;;struct stDeviceNet : public stDevice&#123;\tchar _protocol[32];\tchar _ip[64];\tchar _port[8];\tint _sock_c;\t\tstDeviceNet()\t\t: stDevice(en_device_net)\t&#123;&#125;\t\tvirtual bool init(pugi::xml_node node)\t&#123;\t\t// 初始化数据成员\t\t// 链接到UDPServer\t&#125;\tvirtual int release()\t&#123; \t&#125;\tvirtual void exec(const char* pStr)\t&#123;\t\tsockaddr_in ser;\t\tbzero(&amp;ser, sizeof(ser));\t\tser.sin_family = AF_INET;\t\tser.sin_port = htons(atoi(_port));\t\tser.sin_addr.s_addr = inet_addr(_ip);\t\tint nlen = sizeof(ser);\t\t\t\tsendto(_sock_c, pStr, strlen(pStr) + 1, 0, (sockaddr*)&amp;ser, nlen);\t&#125;&#125;; class tlog_category : public tlog_category_interface&#123;private:\tstd::string _name;\tstd::vector&lt;stDevice*&gt; _vecDevice;public:\tbool init(pugi::xml_node node)\t&#123;\t\t// 解析配置，初始化数据成员\t&#125;\t\tvirtual int release()\t&#123;\t\t// vec data release;\t\t// destroy vec;\t&#125;\t\tvirtual void exec(const char* pstr)\t&#123;\t\t// for (auto&amp; itr : _vec)\t\t// if (itr) itr-&gt;exec(pstr);\t&#125;&#125;; class tlog_ctx : public tlog_ctx_interface&#123;private:\tstd::unordered_map&lt;std::string, tlog_category*&gt; _mapCate;public:\tbool init(const char* pszPath)\t&#123;\t\t// 初始化 _mapCate\t&#125;\t\tvirtual int release()\t&#123;\t\t// _mapCate data release\t\t// destroy _mapCate\t&#125;\t\tvirtual tlog_category_interface* get_category(const char* name)\t&#123;\t\treturn _mapCate[name];\t&#125;&#125;; &#125;; // tlog_base.cpp LPTLOGCTX tlog_init_from_file(const char* pszPath)&#123;\ttlog_ctx* pCtx = new tlog_ctx;\tpCtx-&gt;init(pszPath);\treturn pCtx;&#125; LPLOGCATEGORYINST tlog_get_category(LPTLOGCTX pstCtx, const char* pszName)&#123;\tif (pstCtx)\t&#123;\t\treturn pstCtx-&gt;get_category(pszName);\t&#125;\treturn NULL;&#125; void tlog_info(LPLOGCATEGORYINST pCat, size_t id, size_t, cls, const char* pszFmt, ...)&#123;\tif (!pCat) return;\tva_list vArg;\tva_start(vArg, pszFmt);\tchar buffer[MAX_SIZE] = &#123;0&#125;;\t// char* pbuffer = buffer;\t// int len = _vsnprintf(pszFmt, vArg);\t// if (len &lt; 0)\t// &#123;\t// \tva_end(vArg);\t// \treturn;\t// &#125;\t// if (len &gt;= MAX_SIZE)\t// \tpbuffer = (char*)malloc(len + 1);\tvsnprintf(buffer, MAX_SIZE, pszFmt, vArg);\t\tpCat-&gt;exec(buffer);\t\tva_end(vArg);&#125; int tlog_fini_ctx(LPTLOGCTX* ppstCtx)&#123;\tif (ppstCtx &amp;&amp; *ppstCtx)\t&#123;\t\t(*ppstCtx)-&gt;release();\t\t*ppstCtx = NULL;\t\treturn 0;\t&#125;\treturn -1;&#125;\n\n解析xml工具代码// tlog_sql.h struct stEntry&#123;\tstd::string _name;\tstd::string _oldname;\tstd::string _type;\tuint32_t _size;\tstd::string _desc;\tbool _index;&#125;; struct stStruct&#123;\tstd::string _name;\tstd::string _oldname;\tstd::string _desc;\tstd::unordered_map&lt;std::string, stEntry&gt; _mapEntry;&#125;; /*解析xml到三个文件：.sql .h .cpp.sql\tprocedure \t\t-- alter table name \t\tIF EXIST (select * from information_schema.TABLES) WHERE table_name=&#x27;...&#x27;) THEN ALTER TABLE ... RENAME TO ... END IF;\t\t-- new table\t\tIF NOT EXIST (select * from information_schema.TABLES) WHERE table_name=&#x27;...&#x27;) THEN CREATE TABLE .... END IF;\t\t-- alter column name\t\tIF EXIST (select * from information_schema.COLUMNS) WHERE table_name=&#x27;...&#x27; and column_name=&#x27;...&#x27;) THEN ALTER TABLE ... END IF;\t\t-- add column\t\tIF NOT EXIST (select * from information_schema.COLUMNS) WHERE table_name=&#x27;...&#x27; and column_name=&#x27;...&#x27;) THEN ALTER TABLE ... END IF;所有字段都这么组织一下sql语句，没有oldname的话就没有相关sql语句.h interface\tclass data_basic\t&#123;\tpublic:\t\tvirtual bool ss_split(const char* str) = 0;\t\tvirtual const char* get_sql() = 0;\t&#125;;\t\ttemplate&lt;class data_basic&gt;\tdata_basic* getTlogData()\t&#123;\t\tstatic data_base Inst;\t\treturn &amp;Inst;\t&#125;每一个struct都继承data_basic， name作为类名，entry内容作为数据成员ss_split: 解析传入的 name|...|...|... 格式字符串到数据成员，组织DB INSERT语句get_sql: 返回DB INSERT语句.cpp \tdata_base* getTLogData(const char* name)\t&#123;\t\tif (strcmp(name, &quot;...&quot;) == 0)\t\t\treturn getTLogData&lt;...&gt;();\t\t// .... else if () ....\t\treturn NULL;\t&#125;... 是struct的名字，*/\n\n接收端接收端大概是收到udp消息，用xml解析工具生成的 .h .cpp函数，插入到数据库当然也可以基于es + kafka做一个更简单的服务器\n备忘** MySQL 的”utf8mb4”才是真正的”UTF-8” **\n","categories":["代码"],"tags":["C++"]},{"title":"记录：线上内存问题处理","url":"/archives/62116300.html","content":"说明线上环境配置：Centos 7.5 3.10.0 2核 4G游戏上线，其中2组服务器遇到了内存增长异常的问题\n\n程序内存泄漏？程序内部对象都是以对象池方式分配的, 唯一malloc的地方是网络buffer缓冲\n\ngrep -rn ‘chunk’ .&#x2F;*     log 目录, 查对象池分配日志对象池没有新分配的内容 这些都是原始的分配，分别是 gate 管理的 user 对象 &amp; timer 定时器对象（1个chunk 1024 个对象）\n涉及malloc free的内存，跟随net session的accept &amp; bedelete上图指令分别是: accept次数, bedelete次数, 当前连接数 socket-session 对象建立，每个session 1M (send-buffer) + 1M (recv-buffer)，不是session没有释放导致的\npmap 看具体占用大量没有释放出来的内存  64M程序是不会分配这么大的内存的，内存分配器是glibc，glibc官方说明Starting with glibc 2.11 (for example, customers upgrading from RHEL 5 to RHEL 6), by default, when glibc malloc detects mutex contention (i.e. concurrent mallocs), then the native malloc heap is broken up into sub-pools called arenas. This is achieved by assigning threads their own memory pools and by avoiding locking in some situations. The amount of additional memory used for the memory pools (if any) can be controlled using the environment variables MALLOC_ARENA_TEST and MALLOC_ARENA_MAX. MALLOC_ARENA_TEST specifies that a test for the number of cores is performed once the number of memory pools reaches this value. MALLOC_ARENA_MAX sets the maximum number of memory pools used, regardless of the number of cores. The default maximum arena size is 1MB on 32-bit and 64MB on 64-bit. The default maximum number of arenas is the number of cores multiplied by 2 for 32-bit and 8 for 64-bit. This can increase fragmentation because the free trees are separate. In principle, the net performance impact should be positive of per thread arenas, but testing different arena numbers and sizes may result in performance improvements depending on your workload. You can revert the arena behavior with the environment variable MALLOC_ARENA_MAX=1解释: glibc 在多线程竞争malloc时候，会创建新的arena块，一个arena是64M（64位系统上） 截图里面 64516 + 1020 &#x3D; 65536 64Mldd gate  # 查libc.so所在目录 (libc)/lib64/libc.so.6  # 查版本\n\n\n线上只有两组服务器有内存增长过快的问题，是否和系统版本、环境变量有关？\nkernel 确认相同\n程序使用的环境变量 cat /proc/2948/environ | tr &#39;\\000&#39; &#39;\\n&#39;  基本相同（相差的对内存问题没有关系）\nSA 帮忙确认宿主机内核、glibc版本对内存没有影响\n\nglibc的内存管理\n内存布局\nmalloc 内存分配的系统调用\nbrk() sbrk()    申请heap(移动最高地址指针，性能损耗小)  内存碎片的产生：先申请了10 指针移动到curr +&#x3D; 10, 然后申请20 指针移动到curr +&#x3D; 20; 释放10 当前指针在20位置，20还在使用，无法释放。只有高地址内存释放了，低地址才会释放  为了避免这种内存空洞的产生，在分配&gt;&#x3D;128K内存的时候glibc使用的是 mmap； 由M_MMAP_THRESHOLD调节；M_TRIM_THRESHOLD调节空闲归还\nmmap() munmap()    申请memory mapping segment(在虚拟地址空间找空闲的内存，性能损耗稍大)  整页分配，整页释放  但是如果程序使用的都是大内存(&gt;128K)，为了避免mmap/munmap带来的性能消耗，常见的设置是  mallopt(M_MMAP_MAX, 0); mallopt(M_TRIM_THRESHOLD, -1); 显然这样会带来更大的内存消耗（brk造成的内存空洞）  可用 for ((i = 1; i &lt;100; i++)); do ps -o majflt,minflt -C npl-gate; sleep 1; done 监测某个程序是否需要这种设置\nlinux内存管理的基本思想: 内存延迟分配，分配的是虚拟内存，只有真正访问的时候才建立虚拟内存和物理内存的映射\n\n\nglibc的mallocsize &lt; M_MMAP_THRESHOLD 先尝试从brk已经释放的内存中获取，获取不到，调用sbrksize &gt;&#x3D; M_MMAP_THRESHOLD 调用mmapM_MMAP_THRESHOLD default:(128 * 1024) min:(0) max(512 * 1024 or 4 * 1024 * 1024)M_TRIM_THRESHOLD default:(128 * 1024) -1 disables trimming completelymallopt文档\nglibc 内存分配算法\nArena: 管理堆内存链表的; 每个线程有自己的arena区域，arena有上限 32-bit: 2 * cores; 64-bit: 8 * cores  当线程数量超过arena上限的时候，多个线程会共享一个arena区域，多线程竞争时加锁处理\nChunk: 每次分配的堆内存，会根据需要被分割成&gt;&#x3D;1的chunk\nBins: 管理已经被释放的chunk链表\nfastbin\nunsorted bin [free’d]\nsmall bin (2-63) [&lt; 512 bytes]\nlarge bin (64-126) [&gt;&#x3D; 512 bytes]\n\n\n分配策略: fastbin -&gt; unsortedbin -&gt; smallbin -&gt; largebin -&gt; top chunk -&gt; 系统分配，并把多余的内存放回到bins里面\n释放策略：在释放某个时检查附近的块是不是free的，如果是，那么合并添加到unsortedbin里面\n\n\n\n写测试程序测试验证内存分配问题\n测试代码：\n#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;malloc.h&gt;#include &lt;string.h&gt;#define K (1024)#define M (1024 * 1024)#define K_NUM 500000#define M_NUM  500int main() &#123;    int block_size = K;    int block_num = K_NUM;    #ifdef BLOCK_M    block_size = M;    block_num = M_NUM;    printf(&quot;%s\\n&quot;, &quot;----- block M&quot;);    #endif    #ifdef M_MMAP    mallopt(M_MMAP_THRESHOLD, M * 2);    printf(&quot;%s\\n&quot;, &quot;----- glibc mmap threshold&quot;);    #endif    char *ptrs[K_NUM];    for (int i = 0; i &lt; block_num; ++i)    &#123;        ptrs[i] = (char *)malloc(1 * block_size);        memset(ptrs[i], 0, 1 * block_size);    &#125;    #ifdef ONE_MORE    char *tmp1 = (char *)malloc(1);    memset(tmp1, 0, 1);    printf(&quot;%s\\n&quot;, &quot;----- one more 1 malloc&quot;);    #endif    //malloc_info(0, stdout);    printf(&quot;%s\\n&quot;, &quot;##### malloc done&quot;);    getchar();    printf(&quot;%s\\n&quot;, &quot;##### start free memory&quot;);    for(int i = 0; i &lt; block_num; ++i) &#123;        free(ptrs[i]);    &#125;    printf(&quot;%s\\n&quot;, &quot;##### free done&quot;);    //malloc_info(0, stdout);    getchar();    return 0;&#125;\n\ng++ -g -o memory_test01 -std=c++11 memory_test01.cpp -lpthread -DBLOCK_M\n这次编译结果 .&#x2F;strace -f .&#x2F;memory_test 可以看到调用都是mmap\ng++ -g -o memory_test01 -std=c++11 memory_test01.cpp -lpthread -DBLOCK_M -DM_MMAP\n这次编译结果 .&#x2F;strace -f .&#x2F;memory_test 可以看到调用都是brk\n\n测试2：线程内存分配\n#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;mutex&gt;#define K (1024)#define MAX_NUM 500000#define MAX_THREAD 10int main() &#123;    std::mutex lock_;    std::vector&lt;char*&gt; ptrs;    std::function&lt;void()&gt; func_create = [&amp;]() &#123;        for (int i = 0; i &lt; MAX_NUM / MAX_THREAD; ++i)        &#123;                std::lock_guard&lt;std::mutex&gt; _lock(lock_);                ptrs.emplace_back((char *)malloc(1 * K));                memset(ptrs.back(), 0, 1 * K);        &#125;        char *tmp1 = (char *)malloc(1);        memset(tmp1, 0, 1);    &#125;;    std::vector&lt;std::thread&gt; tasks;    for (int i = 0; i &lt; MAX_THREAD; ++i) &#123;        tasks.push_back(std::thread(func_create));    &#125;    std::for_each(tasks.begin(), tasks.end(), [](std::thread&amp; t)&#123;t.join();&#125;);    char *tmp1 = (char *)malloc(1);    memset(tmp1, 0, 1);    printf(&quot;%s\\n&quot;, &quot;malloc done&quot;);    getchar();    printf(&quot;%s\\n&quot;, &quot;start free memory&quot;);    for(int i = 0; i &lt; MAX_NUM; ++i) &#123;        free(ptrs[i]);    &#125;    printf(&quot;%s\\n&quot;, &quot;free done&quot;);    getchar();    return 0;&#125;\n用测试1类似的办法，可以看到多线程内存的分配和释放\n\n测试3：内存一边分配一边释放，监控内存占用\n#include&lt;iostream&gt;#include &lt;iostream&gt;#include &lt;utility&gt;#include &lt;thread&gt;#include &lt;chrono&gt;#include &lt;functional&gt;#include &lt;atomic&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;memory&gt;#include &lt;string.h&gt;#include &lt;mutex&gt;#include &lt;queue&gt;#include &quot;google/malloc_extension.h&quot;#include &quot;malloc.h&quot;typedef void*                           pvoid_t;typedef const void*                     cvoid_t;class asio_NetBuffer&#123;    // .... 一个简单的内存管理器&#125;;struct session&#123;    asio_NetBuffer _send_buffer;    asio_NetBuffer _recv_buffer;&#125;;struct NetEvent&#123;    pvoid_t session;    uint32_t handle;    uint32_t event;&#125;;struct NetData&#123;    int32_t length;&#125;;#define NET_PACKET_SIZE( Length ) (sizeof(NetEvent) + sizeof(NetData) + Length)std::queue&lt; std::tuple&lt; pvoid_t, size_t &gt; &gt; event_queue_;std::mutex lock_queue_;char* _1Mdata;void Push( pvoid_t data, size_t size )&#123;    std::lock_guard&lt; std::mutex &gt; _lock( lock_queue_ );    event_queue_.push( std::make_tuple( data, size ) );&#125;bool Kick( pvoid_t &amp;data, size_t &amp;size )&#123;    std::lock_guard&lt; std::mutex &gt; _lock( lock_queue_ );    if( event_queue_.empty() )    return false;    auto pkg = event_queue_.front();    data = std::get&lt;0&gt;( pkg );    size = std::get&lt;1&gt;( pkg );    event_queue_.pop();    return true;&#125;#define MAX_THREAD 10std::atomic&lt;int&gt; _index;#include &lt;random&gt;std::mt19937&amp; get_random_driver()&#123;    static std::mt19937 mt( (int32_t) time( nullptr ) );    return mt;&#125;template &lt; class T1, class T2, typename std::enable_if&lt; !std::is_floating_point&lt; T1 &gt;::value &amp;&amp; !std::is_floating_point&lt;T2&gt;::value, bool &gt;::type = true &gt;auto random_range( T1 Min, T2 Max )-&gt;decltype( Min + Max )&#123;    if( Min == Max )    return Min;    using NewT = decltype( Min + Max );    if( Min &gt; Max )    return std::uniform_int_distribution&lt;NewT&gt;( Max, Min )( get_random_driver() );    else    return std::uniform_int_distribution&lt;NewT&gt;( Min, Max )( get_random_driver() );&#125;int main()&#123;    _1Mdata = (char*)malloc(80 * 1024 * 1024);    memset(_1Mdata, &#x27;a&#x27;, 80 * 1024 * 1024);    std::function&lt;void()&gt; func_create = [_index]()&#123;    std::cout &lt;&lt; &quot;thread : &quot;&lt;&lt;std::this_thread::get_id() &lt;&lt; std::endl;    session* _ss = new session();    _ss-&gt;_send_buffer.open(10 * 10024 * 1024);    _ss-&gt;_recv_buffer.open(10 * 10024 * 1024);    int event_id = _index.load();    _index += 1000;    while (true)    &#123;        int packet_length = random_range(10, 80 * 1024 * 1024);        NetEvent evt;        evt.session = nullptr;        evt.handle = 1;        evt.event = event_id++;        NetData dat;        dat.length = packet_length;        asio_NetBuffer packet(NET_PACKET_SIZE(packet_length));        packet.put(&amp;evt, sizeof(evt));        packet.put(&amp;dat, sizeof(dat));        packet.put(_1Mdata, packet_length);        Push(packet.release(), NET_PACKET_SIZE(packet_length));        std::this_thread::sleep_for(std::chrono::milliseconds(1));    &#125;    delete _ss;    std::cout &lt;&lt; &quot;thread end : &quot; &lt;&lt;std::this_thread::get_id() &lt;&lt; std::endl;    std::this_thread::sleep_for(std::chrono::seconds(30));    &#125;;    std::vector&lt;std::thread&gt; tasks;    for (int i = 0; i &lt; MAX_THREAD; ++i) &#123;    tasks.push_back(std::thread(func_create));    &#125;    while (true)    &#123;    pvoid_t data = nullptr;    size_t size = 0;    while (Kick(data, size))    &#123;        NetEvent* pHeader = (NetEvent*)data;        // std::cout &lt;&lt; &quot;event:&quot; &lt;&lt; pHeader-&gt;event &lt;&lt; std::endl;        free(data);        std::this_thread::sleep_for(std::chrono::milliseconds(1));    &#125;    &#125;    std::for_each(tasks.begin(), tasks.end(), [](std::thread&amp; t)&#123;t.join();&#125;);    free(_1Mdata);    MallocExtension::instance()-&gt;ReleaseFreeMemory();    std::cout &lt;&lt; &quot;threads joined ... &quot; &lt;&lt; std::endl;    std::this_thread::sleep_for(std::chrono::seconds(30));    return 0;&#125;\nShell:\nfor ((i=1; i&lt;100; i++)); do pmap -x 4454 | grep total; sleep 1; done\nRSS在3.5G左右会有一次比较大的空间释放\n\n\n暂时的结果和线上临时处理暂时的结果根据上面问题的筛查和测试程序，基本可以确认不是程序内存泄漏由于程序net代码用的package和event内存都是是每次单独malloc出来的，分配大小比较乱，基本定位大概率是由于这里的使用方式加上内存分配器机制导致的也在线上没有人的时候gdb attach到进程 dump memory看了其中一块64M的内存，strings结果基本都是网络收发包的文本理论上这些内存是可以归还给系统的，但是由于增长速度过快，而且还只有2组服务器有这种情况，不敢任由服务器有OOM的风险\n线上临时处理由于开发过程中使用过 tcmalloc + gperftools 查内存问题，稍微看过api，知道有ReleaseFreeMemory的操作，就临时把一台服务器换成了tcmalloc的内存分配器程序链接 google tcmalloc（介绍） 重新编译程序新增信号执行 MallocExtension::instance()-&gt;ReleaseFreeMemory()，以防万一\n\n记录线上环境不比测试环境，很多操作都要很小心，特别是长连接的服务器，不敢有过多和长时间的操作\n一些内存指令\nfree              total        used        free      shared  buff/cache   availableMem:        4046216     2444056      238012      194580     1364148     1117984Swap:       4193276      706248     3487028\ntotal: 物理内存总量used: 使用中的内存总量free: 空闲内存总量Buffers/cached: 磁盘缓存的内存量SWAP: 虚拟内存\n/proc/meminfo\n/proc/pid/maps同 pmap -x pid\nsar -r\nsar -B\n\n后续：关于tcmalloc, ptmalloc, jmalloc参考\n\n目前：\n\ntcmalloc 分配内存更快，因为用的大都是sbrk？ptmalloc大内存会用mmap&#x2F;munmap\ntcmalloc 应该是更占内存的？因为sbrk回收的问题\ntcmalloc 像系统要的内存维护在PageHeap，8K&#x3D;1page，释放的内存都在FreeList，线程有自己的ThreadCache，但是内存都是从同一地方拿，归还同一地方；内存利用率相对更高？\njmalloc facebook推出的， 最早的时候是freebsd的libc malloc实现。 目前在firefox、facebook服务器各种组件中大量使用。\n\n\n汇总：  - ptmalloc  - ptmalloc 有一个主分配区(main arena)， 有多个非主分配区。非主分配区只能使用mmap向操作系统批发申请HEAP_MAX_SIZE（64位系统为64MB）大小的虚拟内存。当某个线程调用malloc的时候，会先查看线程私有变量中是否已经存在一个分配区，如果存在则尝试加锁，如果加锁失败则遍历arena链表试图获取一个没加锁的arena， 如果依然获取不到则创建一个新的非主分配区。free()的时候也要获取锁。分配小块内存容易产生碎片，ptmalloc在整理合并的时候也要对arena做加锁操作。在线程多的时候，锁的开销就会增大。  - ptmalloc 用户请求分配的内存使用chunk表示， 每个chunk至少需要8个字节额外的开销。用户free掉的内存不会马上归还操作系统，ptmalloc会统一管理heap和mmap区域的空闲chunk，避免了频繁的系统调用。  - ptmalloc 将相似大小的 chunk 用双向链表链接起来, 这样的一个链表被称为一个 bin。 Ptmalloc 一共 维护了 128 个 bin,并使用一个数组来存储这些 bin  - ptmalloc 数组中的第一个为 unsorted bin, 数组中从 2 开始编号的前 64 个 bin 称为 small bins, 同一个small bin中的chunk具有相同的大小。 small bins后面的bin被称作large bins  - ptmalloc 当free一个chunk并放入bin的时候， 还会检查它前后的chunk 是否也是空闲的, 如果是的话, 会首先把它们合并为一个大的chunk, 然后将合并后的chunk 放到unstored bin中。另外为了提高分配的速度,会把一些小的(不大于64B) chunk先放到一个叫做 fast bins 的容器内。  - ptmalloc 在fast bins和bins都不能满足需求后，会设法在一个叫做top chunk的空间分配内存。对于非主分配区会预先通过mmap分配一大块内存作为top chunk， 当bins和fast bins都不能满足分配需要的时候, c会设法在top chunk中分出一块内存给用户, 如果top chunk本身不够大, 分配程序会重新mmap分配一块内存chunk, 并将top chunk 迁移到新的chunk上，并用单链表链接起来。如果free()的chunk恰好 与 top chunk 相邻,那么这两个 chunk 就会合并成新的 top chunk，如果top chunk大小大于某个阈值才还给操作系统。主分配区类似，不过通过sbrk()分配和调整top chunk的大小，只有heap顶部连续内存空闲超过阈值的时候才能回收内存  - ptmalloc 需要分配的 chunk 足够大,而且 fast bins 和 bins 都不能满足要求,甚至 top chunk 本身也不能满足分配需求时, 会使用 mmap 来直接使用内存映射来将页映射到进程空间  - ptmalloc缺陷 后分配的内存先释放,因为 ptmalloc 收缩内存是从 top chunk 开始,如果与 top chunk 相邻的 chunk 不能释放, top chunk 以下的 chunk 都无法释放。  - ptmalloc缺陷 多线程锁开销大， 需要避免多线程频繁分配释放。  - ptmalloc缺陷 内存从thread的areana中分配， 内存不能从一个arena移动到另一个arena， 就是说如果多线程使用内存不均衡，容易导致内存的浪费。比如说线程1使用了300M内存，完成任务后glibc没有释放给操作系统，线程2开始创建了一个新的arena， 但是线程1的300M却不能用了。  - ptmalloc缺陷 每个chunk至少8字节的开销很大  - ptmalloc缺陷 不定期分配长生命周期的内存容易造成内存碎片，不利于回收。 64位系统最好分配32M以上内存，这是使用mmap的阈值  - ptmalloc使用经验 避免多线程频繁分配和释放内存，会造成频繁加解锁。  - ptmalloc使用经验 不要分配长生命周期的内存块，容易造成内碎片，影响内存回收。  - ptmalloc使用经验 对于动态增长STL容器，要注意它维护的队列却是分配在heap上的。也就是说一个这样的临时对象所操作过的内存，依然可能产生碎片。如果这样的函数被频繁调用，碎片就会非常多。尽量成批reserve一块内存使用。减少在容器已满的情况下仍然push_back单个元素的操作，这样非常容易产生碎片。  - ptmalloc使用经验 即便我们做过shrink_to_fit的工作（std::vector&lt;t*&gt;(v).swap(v)），如果里面是碎片，那也会被驻留在brk维护的free_list中，不会被释放。  - ptmalloc使用经验 长时间的线上服务更应该注重编码习惯，尽量减少内存碎片。  - ptmalloc使用经验 每个线程至少有一个，至多有cores_num*8个自己的arena（看成by线程的内存池），减少锁的使用。不同arena之间不能交替使用。多尝试arena数目的设置，对虚拟内存的消耗有挺大的影响。\ntcmalloc\ntcmalloc 为每个线程分配了一个线程本地ThreadCache，小内存从ThreadCache分配，此外还有个中央堆（CentralCache），ThreadCache不够用的时候，会从CentralCache中获取空间放到ThreadCache中。\ntcmalloc 小对象（&lt;&#x3D;32K）从ThreadCache分配，大对象从CentralCache分配。大对象分配的空间都是4k页面对齐的，多个pages也能切割成多个小对象划分到ThreadCache中\ntcmalloc 小对象有将近170个不同的大小分类(class)，每个class有个该大小内存块的FreeList单链表，分配的时候先找到best fit的class，然后无锁的获取该链表首元素返回。如果链表中无空间了，则到CentralCache中划分几个页面并切割成该class的大小，放入链表中\ntcmalloc 大对象(&gt;32K)先4k对齐后，从CentralCache中分配。 CentralCache维护的PageHeap数组中第256个元素是所有大于255个页面都挂到该链表中\ntcmalloc 当best fit的页面链表中没有空闲空间时，则一直往更大的页面空间则，如果所有256个链表遍历后依然没有成功分配。则使用sbrk, mmap, &#x2F;dev&#x2F;mem从系统中分配。\ntcmalloc PageHeap管理的连续的页面被称为span. 如果span未分配， 则span是PageHeap中的一个链表元素. 如果span已经分配，​​它可能是返回给应用程序的大对象， 或者已经被切割成多小对象，该小对象的size-class会被记录在span中\ntcmalloc 在32位系统中，使用一个中央数组(central array)映射了页面和span对应关系， 数组索引号是页面号，数组元素是页面所在的span。在64位系统中，使用一个3-level radix tree记录了该映射关系\ntcmalloc 当一个object free的时候，会根据地址对齐计算所在的页面号，然后通过central array找到对应的span。\ntcmalloc 如果是小对象，span会告诉我们他的size class，然后把该对象插入当前线程的ThreadCache中。如果此时ThreadCache超过一个预算的值（默认2MB），则会使用垃圾回收机制把未使用的object从ThreadCache移动到CentralCache的central free lists中。\ntcmalloc 如果是大对象，span会告诉我们对象锁在的页面号范围。假设这个范围是[p,q]， 先查找页面p-1和q+1所在的span，如果这些临近的span也是free的，则合并到[p,q]所在的span， 然后把这个span回收到PageHeap中。\ntcmalloc CentralCache的central free lists类似ThreadCache的FreeList，不过它增加了一级结构，先根据size-class关联到spans的集合， 然后是对应span的object链表。如果span的链表中所有object已经free， 则span回收到PageHeap中\ntcmalloc相比ptmalloc ThreadCache会阶段性的回收内存到CentralCache里。解决了ptmalloc2中arena之间不能迁移的问题。\ntcmalloc相比ptmalloc tcmalloc占用更少的额外空间。例如，分配N个8字节对象可能要使用大约8N * 1.01字节的空间。即，多用百分之一的空间。 ptmalloc2使用最少8字节描述一个chunk。\ntcmalloc相比ptmalloc 更快。小对象几乎无锁， &gt;32KB的对象从CentralCache中分配使用自旋锁。并且&gt;32KB对象都是页面对齐分配，多线程的时候应尽量避免频繁分配，否则也会造成自旋锁的竞争和页面对齐造成的浪费\n\n\n\njmalloc\njmalloc 与tcmalloc类似，每个线程同样在&lt;32KB的时候无锁使用线程本地cache。\njmalloc 在64bits系统上使用下面的size-class分类：  Small: [8], [16, 32, 48, …, 128], [192, 256, 320, …, 512], [768, 1024, 1280, …, 3840]  Large: [4 KiB, 8 KiB, 12 KiB, …, 4072 KiB]  Huge: [4 MiB, 8 MiB, 12 MiB, …]\njmalloc small&#x2F;large对象查找metadata需要常量时间， huge对象通过全局红黑树在对数时间内查找。\njmalloc 虚拟内存被逻辑上分割成chunks（默认是4MB，1024个4k页），应用线程通过round-robin算法在第一次malloc的时候分配arena， 每个arena都是相互独立的，维护自己的chunks， chunk切割pages到small&#x2F;large对象。free()的内存总是返回到所属的arena中，而不管是哪个线程调用free()。\njmalloc 小对象也根据size-class，但是它使用了低地址优先的策略，来降低内存碎片化。\njmalloc 大概需要2%的额外开销。（tcmalloc 1%， ptmalloc最少8B）\njmalloc 和tcmalloc类似的线程本地缓存，避免锁的竞争\njmalloc 相对未使用的页面，优先使用dirty page，提升缓存命中。\n\n\n\n参考\n深入理解glibc malloc (https://wooyun.js.org/drops/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20glibc%20malloc.html)\nLinux内存点滴 用户进程内存空间 (https://www.cnblogs.com/muahao/p/5974594.html)\nLinux下/proc目录简介 (https://blog.spoock.com/2019/10/08/proc/)\nmallopt(3) - Linux man page (https://linux.die.net/man/3/mallopt)\nglibc wiki (https://sourceware.org/glibc/wiki/MallocInternals)\n禁用 mmap 和 memory trip 来加速 MPI RMA (https://enigmahuang.me/2018/09/05/MPI_mmap_trim/)\nkernel-memory (https://hhb584520.github.io/kvm_blog/2017/03/06/kernel-memory.html)\nTCMalloc : Thread-Caching Malloc (https://github.com/google/tcmalloc/blob/master/docs/design.md)\n3-level radix tree 基数树 (https://zh.wikipedia.org/wiki/%E5%9F%BA%E6%95%B0%E6%A0%91)\nunderstanding-glibc-malloc (https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/)\nSyscalls used by malloc (https://sploitfun.wordpress.com/2015/02/11/syscalls-used-by-malloc/)\n几种malloc实现原理 ptmalloc(glibc) &amp;&amp; tcmalloc(google) &amp;&amp; jemalloc(facebook) (https://msd.misuland.com/pd/300184051069751296)\nptmalloc、tcmalloc与jemalloc对比分析 (https://www.cyningsun.com/07-07-2018/memory-allocator-contrasts.html#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D)\n内存优化总结:ptmalloc、tcmalloc和jemalloc (http://www.cnhalo.net/2016/06/13/memory-optimize/)\n\n","categories":["内存"],"tags":["linux","内存"]},{"title":"asan 内存越界检查","url":"/archives/571a5caf.html","content":"介绍AddressSanitizer (or ASan) is an open source programming tool by Google that detects memory corruption bugs such as buffer overflows or accesses to a dangling pointer (use-after-free). AddressSanitizer is based on compiler instrumentation and directly-mapped shadow memory. AddressSanitizer is currently implemented in Clang (starting from version 3.1) , GCC (starting from version 4.8) and Xcode (starting from version 7.0) . On average, the instrumentation increases processing time by about 73% and memory usage by 240%. – 摘自 wiki\nwiki 里面讲的很详细，还包括了 example下面主要是尝试使用的记录\n安装centos: sudo yum install libasan 或者 sudo yum install  devtoolset-3-libasan-devel或者: https://github.com/google/sanitizers 编译安装\n使用\n编译参数: -fsanitize&#x3D;address -fno-omit-frame-pointer -g\n连接参数：-lasan\n环境变量：export ASAN_OPTIONS&#x3D;log_path&#x3D;&#x2F;home&#x2F;jianglei&#x2F;asan.log 指定输出错误日志文件路径\n测试代码：#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;int main() &#123;  char* ptr = new char[10];  memset(ptr, 0, 11);  while (true) &#123;    sleep(1);  &#125;  return 0;&#125;\n\n\n结果\nlibasan 会把程序在哪一行访问越界多少字节，越界的内存地址清楚的标记出来\nlibasan 会立即终止程序（不过一般内存都踩坏了，程序继续运行也可能会有更大的事故）\n开发期间尽量包在编译选项，并且指向到日志\n如果 gcc -O 的关系无法看到具体出错的地方，可以用 addr2line -e ./asan -f 0x4007d7 | c++filt 定位,具体参考 addr2line\n\n","categories":["知识备忘"],"tags":["linux","C/C++"]},{"title":"记录：日常","url":"/archives/e5b83726.html","content":"计划要做的事情network基于asio，期望接口类似netty；多io_service，send、recv、close等都绑定strandTCP &amp; UDP, server &amp; client\nmongodbfriend\nid: 10088 &amp; id: 10089 互为好友db.friend.insert(&#123;&quot;_id&quot;:10088,&quot;friends&quot;:[&#123;&quot;pid&quot;:10089,&quot;name&quot;:&quot;10089&quot;,&quot;iclass&quot;:1,&quot;trophy&quot;:0&#125;,&#123;&quot;pid&quot;:11089,&quot;name&quot;:&quot;11089&quot;,&quot;iclass&quot;:1,&quot;trophy&quot;:0&#125;]&#125;);db.friend.insert(&#123;&quot;_id&quot;:10089,&quot;friends&quot;:[&#123;&quot;pid&quot;:10088,&quot;name&quot;:&quot;10088&quot;,&quot;iclass&quot;:1,&quot;trophy&quot;:0&#125;,&#123;&quot;pid&quot;:11088,&quot;name&quot;:&quot;11088&quot;,&quot;iclass&quot;:1,&quot;trophy&quot;:0&#125;]&#125;);\n\n添加好友关系：(如何一条语句完成？)db.friend.update(&#123;_id:10088&#125;, &#123;$push: &#123;friends: &#123;pid:10089, name:&quot;10089&quot;, iclass:1, trophy:0&#125;&#125; &#125;);db.friend.update(&#123;_id:10089&#125;, &#123;$push: &#123;friends: &#123;pid:10088, name:&quot;10088&quot;, iclass:1, trophy:0&#125;&#125; &#125;);\n\n解除好友关系：db.friend.updateMany(&#123;$or:[&#123;&quot;_id&quot;:10088&#125;, &#123;&quot;_id&quot;:10089&#125;]&#125;, &#123;$pull: &#123;friends: &#123;pid: &#123;$in:[10088, 10089]&#125;&#125;&#125;&#125;);ordb.friend.update(&#123;_id:10088&#125;, &#123;$pull: &#123;&#39;friends&#39;:&#123;pid: 10089&#125;&#125;&#125;);db.friend.update(&#123;_id:10089&#125;, &#123;$pull: &#123;&#39;friends&#39;:&#123;pid: 10088&#125;&#125;&#125;);\n\n\n一些记录\n如果是 std::unrodered_map O(1) 的时间复杂度，和 std::vector 下标访问 O(1) 的时间复杂度，如何选择\n额… 忘记hash是耗cpu的了\n\n\n\n现状关于自己\n2010年入行游戏行业做平台服务端开发，语言主要用C++一个小心翼翼，容易紧张的职场新人；朝九晚五，薪水够用，前辈悉心教导，看着他们觉得这就是自己以后的样子，是满足的。12年公司裁员，自己在列表里面，慌张的找工作，同事大都建议离开游戏行业….\n传统行业做了2个月，不适应那样的环境，刚好有老同事创业招人的机会，回到游戏行业开始做游戏服务端开发从业务功能开始做，学习游戏相关系统；作为游戏开发者真是件辛苦又好玩的事情\n大概6个月时间，创业公司解散，还好摸了游戏一些东西，大致知道了游戏是什么样子的一个新公司，一个MMORPG的游戏项目；虽是维护老的项目，也激动于能看到MMO游戏怎么做，当时认知里最复杂的游戏类型做游戏的同学简单直接，换了公司像一切都没什么改变；也没有很多适应新环境的时间就开始做相对复杂的系统\n开了新的MMORPG项目，服务端重写，主要负责战斗、角色相关的内容，当时的游戏团队都很小，服务器最多时候7个人基本是每个人负责一个系统的做，那段时间看了很多东西，做了很多东西；一段快速成长的经历\nMMO的项目没有赚到钱，行业大部分钱也都去了手游那边团队合并，开始做手游服务端，是比MMO简单的架构，也简单的逻辑\n经历两个项目的完整开发、上线，游戏常规的模块基本都做了一遍，也有一些自己的想法急切着想有机会实现然而又是项目组合并，面对一个过百人的研发团队做一个小兵，觉得当下不是适合自己的机会\n目前2018：老领导带我换到了一家做发行的平台，服务端、客户端用的SDK、客户端的工具支持东西很杂，内容很多，但又觉得没有做什么，以至于整理简历发现近两年只有两三行内容\n目前2020：手游服务端开发的机会，语言换成了JAVA，依葫芦画瓢着写，暂时还是看不到未来做游戏是需要热情的，对行业的热情，对自己产品的热情，大概理解了以前面试会被问自己最近在玩的游戏这类问题\n2022：前面做了2款休闲游戏，都没有很好的收益，部门解散，开始重新找工作，原本想休息一段时间，看下C++相关的东西做回C++相关，但实际是被赶着往前走，迅速开始了面试，一家公司HR联系的时候由特意问到有没有接触其他公司，可能是不喜欢临时抱佛脚刷面试题的同学把，复习了自己blog上记录的东西，就这样继续面试继续往前走吧。很久没有面试的感觉了，一次面试在白板上一直画架构，早先MMO的架构已经记忆的不是很细节了，这边漏一个那边漏一个，现场尴尬….虽然早先看这是个很老的架构，但是里面还是由很多细节和做的不是那么好的地方，近些年不少游戏已经在尝试和产出了更好的方案，可是我离这些好像有点远了；我不追求做大世界的项目，小而美反而更心动，可两者技术上都有被动的地方在了，大世界的架构没有很好的想法，小而美的架构上调整成更适合快速开发的样子，在这些面前，我像个待在传统老项目里的老年人，没有什么吸引力在了。\n\n","categories":["记录"],"tags":["日常"]},{"title":"std::shared_ptr 线程安全？","url":"/archives/ec0ed877.html","content":"std::shared_ptrcppreference.com: (https://en.cppreference.com/w/cpp/memory/shared_ptr)原本知道 shared_ptr refcount 是原子的，也就是线程安全的，但是并没有细究过内部在多线程下操作会有怎样的问题，是否是安全的直到遇到一次因为 shared_ptr 的崩溃网上关于std::shared_ptr线程安全的文章已经很多了，这里主要是记录和模拟崩溃\n崩溃的地方的大致堆栈（这是测试模拟出的）\n讲的很明白的文章https://cloud.tencent.com/developer/article/1654442https://www.cnblogs.com/Solstice/archive/2013/01/28/2879366.htmlhttps://www.modernescpp.com/index.php/atomic-smart-pointershttps://www.justsoftwaresolutions.co.uk/threading/why-do-we-need-atomic_shared_ptr.html\n源码最常用的 operator =调用的 swap\n陈硕老师的文章讲的很清楚陈硕（giantchen_AT_gmail_DOT_com）\n2012-01-28\n我在《Linux 多线程服务端编程：使用 muduo C++ 网络库》第 1.9 节“再论 shared_ptr 的线程安全”中写道：\n（shared_ptr）的引用计数本身是安全且无锁的，但对象的读写则不是，因为 shared_ptr 有两个数据成员，读写操作不能原子化。根据文档（http://www.boost.org/doc/libs/release/libs/smart_ptr/shared_ptr.htm#ThreadSafety）， shared_ptr 的线程安全级别和内建类型、标准库容器、std::string 一样，即：\n• 一个 shared_ptr 对象实体可被多个线程同时读取（文档例1）；\n• 两个 shared_ptr 对象实体可以被两个线程同时写入（例2），“析构”算写操作；\n• 如果要从多个线程读写同一个 shared_ptr 对象，那么需要加锁（例3~5）。\n请注意，以上是 shared_ptr 对象本身的线程安全级别，不是它管理的对象的线程安全级别。\n后文（p.18）则介绍如何高效地加锁解锁。本文则具体分析一下为什么“因为 shared_ptr 有两个数据成员，读写操作不能原子化”使得多线程读写同一个 shared_ptr 对象需要加锁。这个在我看来显而易见的结论似乎也有人抱有疑问，那将导致灾难性的后果，值得我写这篇文章。本文以 boost::shared_ptr 为例，与 std::shared_ptr 可能略有区别。\nshared_ptr 的数据结构shared_ptr 是引用计数型（reference counting）智能指针，几乎所有的实现都采用在堆（heap）上放个计数值（count）的办法（除此之外理论上还有用循环链表的办法，不过没有实例）。具体来说，shared_ptr 包含两个成员，一个是指向 Foo 的指针 ptr，另一个是 ref_count 指针（其类型不一定是原始指针，有可能是 class 类型，但不影响这里的讨论），指向堆上的 ref_count 对象。ref_count 对象有多个成员，具体的数据结构如图 1 所示，其中 deleter 和 allocator 是可选的。\n\n图 1：shared_ptr 的数据结构。\n为了简化并突出重点，后文只画出 use_count 的值：\n\n以上是 shared_ptr x(new Foo); 对应的内存数据结构。\n如果再执行 shared_ptr y &#x3D; x; 那么对应的数据结构如下。\n\n但是 y&#x3D;x 涉及两个成员的复制，这两步拷贝不会同时（原子）发生。\n中间步骤 1，复制 ptr 指针：\n\n中间步骤 2，复制 ref_count 指针，导致引用计数加 1：\n\n步骤1和步骤2的先后顺序跟实现相关（因此步骤 2 里没有画出 y.ptr 的指向），我见过的都是先1后2。\n既然 y&#x3D;x 有两个步骤，如果没有 mutex 保护，那么在多线程里就有 race condition。\n多线程无保护读写 shared_ptr 可能出现的 race condition考虑一个简单的场景，有 3 个 shared_ptr 对象 x、g、n：\nshared_ptr g(new Foo); &#x2F;&#x2F; 线程之间共享的 shared_ptrshared_ptr x; &#x2F;&#x2F; 线程 A 的局部变量shared_ptr n(new Foo); &#x2F;&#x2F; 线程 B 的局部变量一开始，各安其事。\n\n线程 A 执行 x &#x3D; g; （即 read g），以下完成了步骤 1，还没来及执行步骤 2。这时切换到了 B 线程。\n\n同时编程 B 执行 g &#x3D; n; （即 write g），两个步骤一起完成了。\n先是步骤 1：\n\n再是步骤 2：\n\n这是 Foo1 对象已经销毁，x.ptr 成了空悬指针！\n最后回到线程 A，完成步骤 2：\n\n多线程无保护地读写 g，造成了“x 是空悬指针”的后果。这正是多线程读写同一个 shared_ptr 必须加锁的原因。\n当然，race condition 远不止这一种，其他线程交织（interweaving）有可能会造成其他错误。\n思考，假如 shared_ptr 的 operator&#x3D; 实现是先复制 ref_count（步骤 2）再复制 ptr（步骤 1），会有哪些 race condition？\n杂项shared_ptr 作为 unordered_map 的 key如果把 boost::shared_ptr 放到 unordered_set 中，或者用于 unordered_map 的 key，那么要小心 hash table 退化为链表。http://stackoverflow.com/questions/6404765/c-shared-ptr-as-unordered-sets-key/12122314#12122314\n直到 Boost 1.47.0 发布之前，unordered_set&lt;std::shared_ptr &gt; 虽然可以编译通过，但是其 hash_value 是 shared_ptr 隐式转换为 bool 的结果。也就是说，如果不自定义hash函数，那么 unordered_{set&#x2F;map} 会退化为链表。https://svn.boost.org/trac/boost/ticket/5216\nBoost 1.51 在 boost&#x2F;functional&#x2F;hash&#x2F;extensions.hpp 中增加了有关重载，现在只要包含这个头文件就能安全高效地使用 unordered_setstd::shared_ptr 了。\n这也是 muduo 的 examples&#x2F;idleconnection 示例要自己定义 hash_value(const boost::shared_ptr&amp; x) 函数的原因（书第 7.10.2 节，p.255）。因为 Debian 6 Squeeze、Ubuntu 10.04 LTS 里的 boost 版本都有这个 bug。\n为什么图 1 中的 ref_count 也有指向 Foo 的指针？shared_ptr sp(new Foo) 在构造 sp 的时候捕获了 Foo 的析构行为。实际上 shared_ptr.ptr 和 ref_count.ptr 可以是不同的类型（只要它们之间存在隐式转换），这是 shared_ptr 的一大功能。分 3 点来说：\n\n无需虚析构；假设 Bar 是 Foo 的基类，但是 Bar 和 Foo 都没有虚析构。\n\nshared_ptr sp1(new Foo); &#x2F;&#x2F; ref_count.ptr 的类型是 Foo*\nshared_ptr sp2 &#x3D; sp1; &#x2F;&#x2F; 可以赋值，自动向上转型（up-cast）\nsp1.reset(); &#x2F;&#x2F; 这时 Foo 对象的引用计数降为 1\n此后 sp2 仍然能安全地管理 Foo 对象的生命期，并安全完整地释放 Foo，因为其 ref_count 记住了 Foo 的实际类型。\n\nshared_ptr 可以指向并安全地管理（析构或防止析构）任何对象；muduo::net::Channel class 的 tie() 函数就使用了这一特性，防止对象过早析构，见书 7.15.3 节。\n\nshared_ptr sp1(new Foo); &#x2F;&#x2F; ref_count.ptr 的类型是 Foo*\nshared_ptr sp2 &#x3D; sp1; &#x2F;&#x2F; 可以赋值，Foo* 向 void* 自动转型\nsp1.reset(); &#x2F;&#x2F; 这时 Foo 对象的引用计数降为 1\n此后 sp2 仍然能安全地管理 Foo 对象的生命期，并安全完整地释放 Foo，不会出现 delete void* 的情况，因为 delete 的是 ref_count.ptr，不是 sp2.ptr。\n\n多继承。假设 Bar 是 Foo 的多个基类之一，那么：\n\nshared_ptr sp1(new Foo);\nshared_ptr sp2 &#x3D; sp1; &#x2F;&#x2F; 这时 sp1.ptr 和 sp2.ptr 可能指向不同的地址，因为 Bar subobject 在 Foo object 中的 offset 可能不为0。\nsp1.reset(); &#x2F;&#x2F; 此时 Foo 对象的引用计数降为 1\n但是 sp2 仍然能安全地管理 Foo 对象的生命期，并安全完整地释放 Foo，因为 delete 的不是 Bar，而是原来的 Foo。换句话说，sp2.ptr 和 ref_count.ptr 可能具有不同的值（当然它们的类型也不同）。\n为什么要尽量使用 make_shared()？为了节省一次内存分配，原来 shared_ptr x(new Foo); 需要为 Foo 和 ref_count 各分配一次内存，现在用 make_shared() 的话，可以一次分配一块足够大的内存，供 Foo 和 ref_count 对象容身。数据结构是：\n\n不过 Foo 的构造函数参数要传给 make_shared()，后者再传给 Foo::Foo()，这只有在 C++11 里通过 perfect forwarding 才能完美解决。\n(.完.)\n测试代码#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;memory&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;chrono&gt;#include &lt;atomic&gt;#include &lt;string&gt;struct abc : public std::enable_shared_from_this&lt;abc&gt; &#123;  std::string _str;  int a = 0;  abc() &#123;    std::cout &lt;&lt; &quot;create...&quot; &lt;&lt; std::endl;  &#125;  ~abc() &#123;    std::cout &lt;&lt; &quot;destory...&quot; &lt;&lt; std::endl;  &#125;  std::shared_ptr&lt;abc&gt; sthis() &#123;    return shared_from_this();  &#125;&#125;;long long g_i = 0;int main() &#123;  std::mutex mut;  std::vector&lt;std::shared_ptr&lt;abc&gt;&gt; _handles;  _handles.push_back(nullptr);  std::function&lt;void()&gt; func1 = [&amp;]()&#123;    while (true) &#123;      std::cout &lt;&lt; &quot;call func1...&quot; &lt;&lt; std::endl;      std::shared_ptr&lt;abc&gt; ptr;      &#123;        std::lock_guard&lt;std::mutex&gt; _lock(mut);          // ！！！！必要        ptr = _handles[0];      &#125;      std::cout &lt;&lt; &quot;call func1.1...&quot; &lt;&lt; std::endl;      if (ptr) &#123;        ptr-&gt;_str = &quot; test: &quot; + std::to_string(g_i++);        std::cout &lt;&lt; &quot;use count: &quot; &lt;&lt; ptr.use_count() &lt;&lt; &quot; &quot; &lt;&lt; ptr-&gt;_str &lt;&lt; &quot;:&quot; &lt;&lt; g_i++ &lt;&lt; std::endl;      &#125;      else        std::cout &lt;&lt; &quot;nullptr&quot; &lt;&lt; std::endl;      std::this_thread::sleep_for(std::chrono::microseconds(1));    &#125;  &#125;;  std::thread t1(func1);  std::function&lt;void()&gt; func2 = [&amp;]()&#123;    while (true) &#123;      std::cout &lt;&lt; &quot;call func2...&quot; &lt;&lt; std::endl;      std::function&lt;void(const std::shared_ptr&lt;abc&gt;&amp; ptr)&gt; linkup = [&amp;_handles, &amp;mut](const std::shared_ptr&lt;abc&gt;&amp; ptr)&#123;        std::lock_guard&lt;std::mutex&gt; _lock(mut);              // ！！！！必要        _handles[0] = ptr-&gt;shared_from_this();        std::cout &lt;&lt; &quot;linkup...&quot; &lt;&lt; std::endl;      &#125;;      std::function&lt;void()&gt; linkdown = [&amp;_handles, &amp;mut]()&#123;        // if (ptr == _handles[0])        std::lock_guard&lt;std::mutex&gt; _lock(mut);              // ！！！！必要        _handles[0] = nullptr;        std::cout &lt;&lt; &quot;linkdown...&quot; &lt;&lt; std::endl;      &#125;;      std::shared_ptr&lt;abc&gt; abcptr(std::make_shared&lt;abc&gt;());      linkup(abcptr);      abcptr = nullptr;      std::this_thread::sleep_for(std::chrono::microseconds(1));      linkdown();    &#125;  &#125;;  std::thread t2(func2);  while (true) &#123;    std::this_thread::sleep_for(std::chrono::seconds(1));  &#125;  t1.join();  t2.join();  return 0;&#125;\n\n代码注释 ！！！！必要 的地方从上往下分别是：\n\nstd::shared_ptr读，引用计数+1\nstd::shared_ptr写，传值为引用，但是原_handles[0]内容被覆盖，保护原对象，加锁\nstd::shared_ptr置空，nullptr 也看做是std::shared_ptr，就可以明白，这里也是要加锁的\n\n更好的解决办法std::atomic_compare_exchange_weakstd::atomic_store但是\n","categories":["知识积累"],"tags":["linux","C/C++"]},{"title":"cmake 常用备忘","url":"/archives/136816a5.html","content":"# cmake 版本号cmake_minimum_required(VERSION 3.19)# project nameproject(service)\n","categories":["备忘"],"tags":["常用备忘"]},{"title":"如何设计分布式的\"小\"游戏","url":"/archives/9177ae4e.html","content":"前言\n从前….做的游戏基本都是小区概念的，区和区之间数据在物理上是隔离的，网络一般也都是隔离开的（除了少数游戏会有一个注册发现discover的单点服务器统一管理服务器之间的链接）\n是否开区从服务端开发的角度，一般是单区（一组服务器）ACU（最高同时在线）服务端是否撑的住（主要是内存、磁盘IO、带宽、cpu）\n当然很多服务端设计里也会把单区做成进程可扩展的方式，比如MMO游戏根据场景分不同的GameService（逻辑服务器进程）、开房间玩法的游戏会有多组BattleService（战斗服务器）分摊压力，也避免在某个进程出问题的时候不至于整区不能游戏\n绝大部分小区的游戏服务端数据存储（DB）是个单点进程，或者有些不用单独的DBService，直接由GameService操作数据库的读写，数据库可能是Mysql、MongoDB（落盘的物理存储）+ redis、memcache（高速内存存储）\n玩家玩游戏需要选择他自己游戏角色所在的区，然后进入这个区开始游戏\n\n常见的游戏常见的MMO游戏服务端架构\n\n玩家通过服务端区列表选择所在的区（拿到LoginService的IP:Port）\n链接LoginService认证账号，获得这次登陆的凭证(token、signature) 和 GateService的IP:Port，同时LoginService把凭证存储到Redis或者通过消息同步给GateService\n链接GateService（长连接），进行游戏\n客户端的交互操作经由GateService转发到GameService，GameService的回执和通知消息经由GateService发送给玩家客户端\nGameService 通过 DBService 从数据库（DataBase）拿到玩家的游戏数据，数据变更后发送到DBService，DBService负责在合适的时间写入数据库（这里一般认为GameService的存储请求到达DBService，DBService将新的数据覆盖到内存就算成功，DBService会在一定的时间后将数据写入数据库（磁盘写入操作）；因为一般情况磁盘读写是最耗时的操作）。\n图中黄色较粗的链接线表示内网的数据传输，一般内网的带宽是1G，服务端一般认为这里是不会有带宽资源不够的情况\n图中没有单独的BattleService，因为对于MMO游戏来说，场景同步一般才是最影响服务端性能部分，游戏服务器的架构也更倾向处理场景同步的问题\n而对于没有场景同步需求的游戏，或者一场战斗只是几个人的游戏，比如1V1的2人游戏，MOBA类型的10人游戏；更在意的是战斗事件处理的速度和到客户端的网络延迟，大多这样的游戏是把战斗从GameService单独拆分出来，或许还会把Matchmaking（匹配）服务单独拆分出来\n\n也许你的游戏也有遇到过\n游戏开服的时候，运营厂商疯狂的开区，甚至你想和朋友在一起玩的时候还需要排队进入\n游戏运营到中期，不用排队进服了，但是好友列表、公会成员列表里面的头像灰态的越来越多\n游戏运营到后期，运营商开始公告合服相关的信息，2+ 个区合并到一起，期望回到游戏前中期的盛世，也节省部分运营成本\n\n倾向的需求\n在游戏里的任何人都可以在一起玩（开房间的玩法）\n不再有或者减轻服务端崩溃（重启）对玩家造成的影响\n服务端还是需要更新的，但是这种更新维护对玩家尽量是透明的\n没有合服的动作，或者合服对玩家是透明的\n\n这些都指向了 大区概念（分布式）的游戏服务器架构\n大区概念的数据\n数据集中：数据集中存放，数据后挂slaver节点备份数据，当master数据服宕机，使用slaver的数据\nmaster 和 slaver 数据同步是一个异步的过程，如果使用数据集群的处理方式  （1 * master + N * slaver，每次更新必须保证 1 * master + M * slaver 更新成功返回成功（M &lt; N）），  master 宕机后只是有更大可能选择到了一个数据最新的 slaver 节点，这是可以被接受的么？ CAP 布鲁尔定理\n假如是一个全球大区（全球通服）的游戏，数据节点部署到那个位置才是合适的？  （相对中心位置并且有不错网络环境支持的新加坡还是重点运营的大洲？）\n在倾向分布式的系统架构里，单点服务的存在一定是最容易被拿出来说道的话题\n\n\n\n\n\n数据分区：战斗只关心拿到正确的数据，不在意数据从哪里来的\n只有一个数据节点不仅会加大资源竞争，而且一但这个数据节点崩溃或者停机，所有玩家都不能玩了，数据分区减少了资源压力，如果有某几个数据节点出问题，也只影响部分玩家\n玩家战斗需要的数据量理论上是小于完整数据量的，如果创建数据时选区规则是就近数据区路由的方式，也可以保证在大部分时候，玩家是从较近的数据节点，经过较少的路由，较快的拿到了角色的全量数据\n当然，如果玩家在亚洲建的账号（数据区在亚洲），但是后来玩游戏是在欧洲，他需要经过跨州的网络拿到自己的数据（一般数据区只有数据存储的逻辑，这种情况可以迁移数据到欧洲的数据区）\n如果常规做法是匹配到战斗是客户端从服务端拿到加密的战斗相关的角色数据包，直接发送到战斗服务器，战斗服务器解出数据并校验的方式（没有战斗服务器和数据区的直接交互），也存在另外的问题：在遇到跨数据区交互的内容，比如排行榜、好友、公会的功能，即使这些功能里只有玩家角色少量的信息，也会存在跨区数据查找的过程，这个过程是不可靠和难控的\n这种数据交互一些的做法参考：玩家ID自带可解出数据分区的信息（或者数据分区和ID绑定（避免数据区迁移需要变更ID的情况）），好友服务器向数据区服务请求数据内容（主动要），一定时间内没有返回（超时时间）再要，直到 要 到数据。\n这样做法的问题显而易见，每次查看好友列表都需要向N组数据服务器请求角色数据。所以一般好友服务器会缓存好友列表界面需要的数据，比如角色名（name）、角色等级（level），这些数据发生变更的时候，数据服务器主动推送变更通知到好友服务器，好友服务器更新自己的缓存。\n作为推送的消息，数据服务器是不能确定推送内容一定被好友服务器接收并处理了，特别是全球服跨物理大洲的推送\n一般情况，好友里数据的更新延迟是可以被接受的，我们这里也假设好友列表刷新的数据可以接受一定程度的延迟和不正确\n这种情况下我的建议是：数据服应尽量保证数据推送到了好友服务器（至少在出现网络问题的时候有重复推送的机制）；对于重传N次后依然没有到达好友服务器或者好友服务器没有正确处理掉的数据，用版本号确认的方式做补偿更新\n补偿更新具体操作是：好友的详细信息里有一个Version标记（这个标记由获得好友详细信息的数据一起带过来，如果只是用作后面建议的数据同步方式，建议这个Version（Friend.Version） &#x3D;&#x3D; 数据服务器用户数据的Version（User.Version）），假设Version是自增的，理论上 Friend.Version &lt;= User.Version；客户端的一些行为：比如打开好友详情面板（展示单个好友更多信息）时，带着Friend.Version 到 数据服务器请求 单个用户详情信息，Friend.Version != User.Version 的时候，数据服务器检查到Friend.Version != User.Version，主动补偿推送最新的数据到好友服务器。（当然这种补偿的做法可以是双向的，某些时候好友服务器发现自己数据错误的时候，也可以主动向数据服务器要数据（主动要））\n\n\n\n\n\nCAP wiki (https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86)\n在理论计算机科学中，CAP定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），它指出对于一个分布式计算系统来说，不可能同时满足以下三点：[1][2]\n一致性（Consistency） （等同于所有节点访问同一份最新的数据副本）\n可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）\n分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择[3]。）\n根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项[4]。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。\n\n\n\n\n\n简易的消息流程\n其中 Operator Change Avatar 标识一次 Package for battle 内部数据修改应重传一次 Package for battle encode 数据\n加密方式有很多种，简单的如图示，数据服务器持公钥编码，战斗服务器持私钥解码\n\n大区概念的网络\n跨大洲的网络通讯：物理距离在我的理解里是无法避免的\n一条消息从亚洲到欧洲，平均需要200ms，这只是平均值（https://wondernetwork.com/pings/），在极端情况这个值会很大，大到玩家觉得游戏很卡\n传说一些有钱的游戏购买了运营商的专线网络做加速，但是那个成本实在太高了\n考虑如何减轻网络延迟的影响，或者想办法把玩家尽量放到离他很近的游戏服务器（需要基于游戏玩法本身考虑）\n确保在跨区交互上也是符合CP（参考CAP）\n下面的一些描述基于游戏是一个开房间的方式，战斗服务器需要在战斗开始拿且仅拿一次数据，结算返回到逻辑服务器（离数据近的服务器）做数据更新\n战斗开始，战斗服务器拿到的数据是否可以相信客户端发送到服务器的数据（客户端从数据服务器拿到战斗需要的加密数据包，并在战斗开始的时候发送到战斗服务器，战斗服务器解密并验证数据合法性），这样做可以避免跨大洲的数据交互\n战斗结算，以类似战斗开始的方式由客户端转发结算数据到逻辑服务器\n理论上，上面描述的方式是可行的\n如果战斗服务器的算力很强大，延迟只考虑网络的情况，给玩家选择战斗服务器的时候需要就近选择（ping值较优的那台）\n玩家登录后获取所有（尽可能多的）战斗服务器的列表，并做ICMP的网络探测并上报数据给到匹配服务器（匹配战斗服务器用的一组服务器Matchmaking）\n匹配服务器基于一定的规则，尽量把玩家分配到网络较优的战斗服务器上\n\n\n\n帧同步的数据校验\n帧同步的游戏，这里一般是在战中有玩家操作的游戏（如果只是战前策略的游戏，用服务器比客户端帧数快的方式先跑完战斗结果再同步给客户端播放更合适）\n服务端在游戏里更多是做消息转发(广播)的内容，伤害等都在客户端做，如何避免客户端作弊呢？\n分两种最常见的帧同步游戏讨论\n#1. 1V1的\n假设客户端是A、B，A计算自己的战场数据伤害等，也模拟计算B的战场数据（不然A看到B的更新会比B自己看到的慢至少1帧）\n客户端需要同步的消息分两种：玩家操作类的和当前战场快照\nA把自己的战场快照同步给B，B根据自己的模拟数据需要做一次战场同步\n如果让B在这个过程做一个快照间的差值计算  \n这里存在一个所有权的问题：\n如果把A作为完全的控制方，那相当于把A的机器当作传统CS架构的S端，一切以A为准，B的一些操作内容会先发到A执行具体结果，再回传给B做结果播放；这样子逻辑看起来很清楚，结构也简单，但是做为B会感受到延迟带来的不好的体验（操作手感和表现延迟）\n如果AB各控制一部分内容，比如主动操作的执行结果，而其他比如场景内的内容由A控制；那AB在客户端感受上都可以得到一个较好的手感和表现，但是控制权的问题也稍复杂点\n\n\n\n\n#2. 断线重连的问题\n\n（待续….）\nhttps://gist.github.com/jboner/2841832https://colin-scott.github.io/personal_website/research/interactive_latency.html\n","categories":["游戏开发"],"tags":["游戏开发"]},{"title":"分享：音乐","url":"/archives/d610ad0a.html","content":"置顶\n\n\n\n2022-11-06\n常态\n\n2020-12\n平安喜乐\n\n\n\n\n诱惑本质喜欢的很多，这首可以一直循环\n\n\n\n\n12月第一天，陈绮贞甜度热爱\n\n\n\n\n2020-11\n偶尔听下花粥，觉得生活都变可爱了\n\n","categories":["音乐"],"tags":["音乐","分享"]},{"title":"字符编码","url":"/archives/e057aac0.html","content":"这些是什么？\nASCII (https://zh.wikipedia.org/wiki/ASCII) 字符编码\nUnicode (https://zh.wikipedia.org/wiki/Unicode) 通用字符集编码\nUTF8 (https://zh.wikipedia.org/wiki/UTF-8) 针对Unicode的可变长度字符编码\nGB2312、GBK、GB18030 (https://zh.wikipedia.org/wiki/GB_18030) 中文编码字符集编码\nBig5 (https://zh.wikipedia.org/wiki/%E5%A4%A7%E4%BA%94%E7%A2%BC) 繁体中文 汉字字符集标准\n附: CRLF 回车 (CR, ASCII 13, \\r)  换行 (LF, ASCII 10, \\n) 换行符方式\n\n基础概念\n字符: (https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AC%A6_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6)) \n字符集：由字符组成的合集，覆盖世界上各个语言的文字，规定了每种文字由那些字符以什么顺序组合出来，并规定了这些字符显示的字形\n字符编码: (https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81)\n\n字符集和字符编码\nASCII: 这是最基础的字符编码，简单理解可以认为是包含了键盘上的所有字符\nGB_XXXX: 单就我们熟悉的中文，ASCII字符编码一定是不够的，由此GB定义了字符集以及编码方式覆盖了中文文字（也有日韩、emoji等）\nUnicode: 国际通用的字符集编码，覆盖了世界上大部分的文字系统\nUTF-8: 看起来Unicode是最好的解决方式了，那么UTF-8出现和很广泛的使用又是为了什么呢？\nUnicode：是一个符号集，规定了各种文字符号的代码，为了覆盖这么多文字，Unicode的占用字节数很大，比如ASCII的任意字符，在ASCII里面表示只需要1字节，但是一些中文在Unicode里面需要4字节；Unicode为了统一就把只需要1字节的前面3个字节补0存放；结果就是在计算机资源(存储、带宽)匮乏的年代，Unicode是一种很奢侈的编码方式\n而UTF-8基于一定的规则，把Unicode从定长编码成变长的，可以使用1-4字节表示一个符号，根据不同的符号变化字节的长度，这样就节省很多的资源占用\nUTF-8的规则\n在ASCII码的范围，用一个字节表示，超出ASCII码的范围就用字节表示，这就形成了我们上面看到的UTF-8的表示方法，这様的好处是当UNICODE文件中只有ASCII码时，存储的文件都为一个字节，所以就是普通的ASCII文件无异，读取的时候也是如此，所以能与以前的ASCII文件兼容。\n大于ASCII码的，就会由上面的第一字节的前几位表示该unicode字符的长度，比如110xxxxx前三位的二进制表示告诉我们这是个2BYTE的UNICODE字符；1110xxxx是个三位的UNICODE字符，依此类推；xxx的位置由字符编码数的二进制表示的位填入。越靠右的x具有越少的特殊意义。只用最短的那个足够表达一个字符编码数的多字节串。注意在多字节串中，第一个字节的开头”1”的数目就是整个串中字节的数目。\n\n\n\n\nGB_XXXX 和 UTF-8: 这里其实更合适的讨论是GB_XXXX 和 Unicode：一个汉字在GB_XXXX编码的值和Unicode里的值是不一样的，而UTF-8只是把Unicode用变长的方式编码出来；所以如果需要从GB_XXXX编码转换到UTF-8是2步操作：1-通过映射表转换到Unicode，2-Unicode用UTF-8做编码\n\n如何区分编码\n我们写入一个文件 这是一段中文\n\nhex 值可以看出，UTF 相关的编码前N个字节，是有一定的规则的  (https://unicode.org/faq/utf_bom.html)\n\n\n\nBytes\nEncoding Form\n\n\n\n00 00 FE FF\nUTF-32, big-endian\n\n\nFF FE 00 00\nUTF-32, little-endian\n\n\nFE FF\nUTF-16, big-endian\n\n\nFF FE\nUTF-16, little-endian\n\n\nEF BB BF\nUTF-8\n\n\n\n既然 UTF 编码可以通过前面的字节判断的，那么其他就是GBK编码了（这只是一个简单的编码猜测方式）\n\n做文件GBK-UTF8转换的脚本（自行判断文件编码，并做转换，基于iconv）\n\n\n#!/bin/bashif [ ! $# == 2 ]; then    echo &quot;usage: $0 path suffix filter....&quot;;    exit;fifunction isGbk() &#123;    local temp=`iconv -f gbk $1 1&gt;/dev/null 2&gt;/dev/null &amp;&amp; echo &#x27;true&#x27;`;    if [ &quot;$temp&quot; == &#x27;true&#x27; ]; then        return 0;    fi;    return -1;&#125;echo &quot;find $1 -type f -name \\&quot;$2\\&quot; ....&quot;;find $1 -type f -name &quot;*$2&quot;|while read line;do$(isGbk $line) if [ $? = &#x27;0&#x27; ]; then    echo $line;    iconv -f gbk -t UTF-8 $line &gt; $&#123;line&#125;.utf8;    mv $&#123;line&#125;.utf8 $line;fi;done\n\n附\nBE: big endian 低地址端存放高位字节\nLE: little endian 低地址端存放低位字节\n\n常用编码检查\nshell: file aaa.txt\nIDE: txt、vscode （上图用的就是vscode）\n\n默认编码\nwindows: GBK （中文）\nlinux: UTF-8\nIDE: VSCode: UTF-8\n语言： C&#x2F;C++ 处理的是二进制数据，所以本身是没有默认编码，而编码是跟源文件（代码文件、读取的磁盘文件）\n\n区域设置\n既然语言如 C&#x2F;C++ 处理的是二进制数据（字符集本身是二进制数据的拼合），又有那么多编码并且各个编码所占字节又不同的情况下，我们需要告知程序在做字符转换的时候用那种拆分方式拆分一个字符串数据.setlocale告知程序在做多字符-宽字符 mbstowcs, wcstombs 互相转换的时候如何解码字符 (需要注意的是这里linux、windows设置是不一样的)linux: (https://man7.org/linux/man-pages/man7/locale.7.html)windows: (https://docs.microsoft.com/en-us/cpp/c-runtime-library/country-region-strings?view=msvc-160)\n\n如果你不需要做字符转换（UTF-8 是用途最广的编码方式），只需要保证程序读取的文件都是相同编码（UTF-8）的，如果你的程序里有（比如：中文这种），也需要保证你的源文件是（UTF-8）编码的\n\n\n未完\nC++11\nC++11 新增了字符串的字面量种类(https://en.cppreference.com/w/cpp/language/string_literal)(https://en.cppreference.com/w/cpp/language/user_literal)\n\n备忘** MySQL 的”utf8mb4”才是真正的”UTF-8” **https://zhuanlan.zhihu.com/p/63360270\ndrop table if exists unioncode_test;create table unioncode_test(\t`id` int primary key auto_increment,\t`name` varchar(100) default null) default charset=utf8;insert into unioncode_test (`name`) values(&#x27;𠖲&#x27;);select * from unioncode_test;ALTER TABLE unioncode_test CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;insert into unioncode_test (`name`) values(&#x27;𠖲&#x27;);select * from unioncode_test;\n\n","categories":["知识备忘"],"tags":["知识备忘"]},{"title":"网络：基础","url":"/archives/3388bb24.html","content":"前言\n计算机网络是程序员，特别是服务端程序员必须要掌握的技能\n服务端的工作主要是完成数据存储、请求验证、交互通讯\n数据存储：业务服务器和数据服务器通讯大都在内网环境，更多关注的是数据安全、容灾、效率这些问题\n请求验证：客户端和服务端的通讯内容，通过服务端的配置数据、规则计算、安全认证等验证数据即可，基本都是业务服务器进程内的工作，关注处理的并发量、处理的效率、处理的安全性\n交互通讯：包括客户端和服务端的通讯、客户端和客户端通讯但是需要服务端中介转发，关注通讯的稳定、可靠，通讯的安全，这里涉及的内容很杂，因为客户端本身需要经过一个复杂的公网环境才能和服务端交互，交互的链路是无法预知和预估的，也就更容易出现奇奇怪怪的问题\n\n\n关于服务端程序本身，关注的问题也基本是围绕内存、网络相关的问题\n希望逐步整理网上不错的内容和自己的理解、实验，整理网络相关的知识\n几种常用的协议：ICMP、UDP、TCP、HTTP\n一些常见的概念：\n物理设备：路由、NAT、网卡、虚拟网卡\n判定参考：ICMP、ping、traceroute\n行为状态：三次握手、四次挥手、半连接队列、全连接队列、SYN重传、FIN、close_wait、time_wait\n数据控制：滑动窗口、拥塞控制、MTU、MSS、SACK、DSACK、RTO、keepalive\n\n\n\n网络各层职责和协议\n\n上面图包含了7层模型，标准的OSI模型\n\n这其中 表示层、会话层已被弃用，我们现在听到的主要是5层模型\n\n作为使用者，主要关心的是网络通信（TCP/IP）相关的内容，把数据链路层和物理层合并命名为网络接口层，就是常说的4层模型了\n\n几乎所有的网络上来就是分层概念，对于应用者，可能只是用到ICMP、TCP、UDP\n\n之所以要关心分层概念，主要是在网络出问题的时候，可以定位出是那一层出的问题，并依此考虑应该如何解决\n\n如果不了解分层，假设客户端和服务端通讯TCP异常丢包，而且是那种看似随机的丢包，甚至一端被RST强行关闭了，这种就无法快速响应到说重点从那些方面查这种问题。\n\n\n参考\n5G时代已经到来，TCP&#x2F;IP老矣，尚能饭否？(https://zhuanlan.zhihu.com/p/129910367)\nTCP&#x2F;IP网络模型 (https://tonydeng.github.io/sdn-handbook/basic/tcpip.html)\n常用网络协议神图 (https://www.yuque.com/bwlab/design/1124531?language=zh-cn)\nwiki (https://zh.wikipedia.org/wiki/OSI%E6%A8%A1%E5%9E%8B)\n\n","categories":["网络"],"tags":["网络"]},{"title":"网络：TCP","url":"/archives/3b5f401c.html","content":"过程状态TCP 包传输过程\n\nstack\n\n主过程是接收过程\n\n下面两个黄色的GSO/LSO -&gt; 替换 GRO/LRO/RFS/RPS ， qdisc队列 -&gt; 替换 Soft data 队列 就是大概的发送过程了\n\n图示主要是应用层使用者常见的一些内容，实际网络上的设备、处理要更多\n\n一些说明\n\nDMA: 数据从网卡硬件拷贝到内存\nGRO/LRO: 数据在网络上是按照mtu值拆分的，如果一个数据包超过了mtu值，那么会被GSO/TSO(也就是下面发送过程替换的块)拆分成多个数据包，接收层GRO/LRO就是讲多个数据包聚合成一个大的数据包的过程\n网卡配置：ethtool -k eth0Features for eth0:rx-checksumming: ontx-checksumming: on        tx-checksum-ipv4: off [fixed]        tx-checksum-ip-generic: on        tx-checksum-ipv6: off [fixed]        tx-checksum-fcoe-crc: off [fixed]        tx-checksum-sctp: off [fixed]scatter-gather: on        tx-scatter-gather: on        tx-scatter-gather-fraglist: off [fixed]tcp-segmentation-offload: on        tx-tcp-segmentation: on        tx-tcp-ecn-segmentation: off [fixed]        tx-tcp6-segmentation: on        tx-tcp-mangleid-segmentation: offudp-fragmentation-offload: off [fixed]generic-segmentation-offload: ongeneric-receive-offload: onlarge-receive-offload: onrx-vlan-offload: ontx-vlan-offload: onntuple-filters: off [fixed]receive-hashing: onhighdma: onrx-vlan-filter: on [fixed]vlan-challenged: off [fixed]tx-lockless: off [fixed]netns-local: off [fixed]tx-gso-robust: off [fixed]tx-fcoe-segmentation: off [fixed]tx-gre-segmentation: off [fixed]tx-ipip-segmentation: off [fixed]tx-sit-segmentation: off [fixed]tx-udp_tnl-segmentation: off [fixed]fcoe-mtu: off [fixed]tx-nocache-copy: offloopback: off [fixed]rx-fcs: off [fixed]rx-all: off [fixed]tx-vlan-stag-hw-insert: off [fixed]rx-vlan-stag-hw-parse: off [fixed]rx-vlan-stag-filter: off [fixed]busy-poll: off [fixed]tx-gre-csum-segmentation: off [fixed]tx-udp_tnl-csum-segmentation: off [fixed]tx-gso-partial: off [fixed]tx-sctp-segmentation: off [fixed]l2-fwd-offload: off [fixed]hw-tc-offload: off [fixed]rx-udp_tunnel-port-offload: off [fixed]\n这里面主要关注的一些offload参数: 是一种TCP加速技术，使用于网卡（NIC），将TCP/IP堆疉工作的负载移转到网卡上，用硬件来完成。这个功能常见于高速以太网接口上，如吉比特以太网（GbE）或10吉比特以太网（10GbE），在这些接口上，处理TCP/IP数据包表头的工作变得较为沉重，由网卡硬件进行可以减轻CPU的负担。 (https://en.wikipedia.org/wiki/TCP_offload_engine)\n网卡 ring buffer: ethtool -g eth0\n\n\nRFS/RPS: 简单理解为多核时代，均衡CPU负载\nARP: 地址解析协议\nqdisc队列（发包过程）: 缓存数据包的地方，可以看到这里是可以做流量控制的，收包是没有这一块的，所以说流量控制控制的是发送而不是接收，而网络上有很多网络设备，比如A-&gt;B-&gt;C，前一个设备是后一个设备的发送方，限速在任意中间设备上做就可以影响最后的下载速度\n\n\n再下面就是最常接触到的过程了\n\nTC 工具常用\n\ntc qdisc show dev eth0 查看当前策略\ntc qdisc add dev eth0 root netem delay 100ms 这个是对网卡eth0 添加策略， 发送的数据包 延时100ms\ntc qdisc add dev eth0 root netem delay 120ms 10ms 该命令将 eth0 网卡的传输设置为延迟 120ms ± 10ms (90 ~ 130 ms 之间的任意值)发送。\ntc qdisc add dev eth0 root netem loss 20% 40% 该命令将 eth0 网卡的传输设置为随机丢掉 20% 的数据包,成功率为 40%\ntc qdisc del dev eth0 root 删除所有策略\n\n\n其他工具：google tcp packet drill (https://github.com/google/packetdrill)https://cloud.tencent.com/developer/article/1745583\n\n\nTCP&#x2F;IP 封装\n\nAppl: 我常用的方式是 message_length(4-byte) + message_id(4-byte)\n为什么包大小是46-1500\n1500： 经常见到，mtu值\n46：涉及一个概念，以太网时隙 (wiki) 看到这个值最小是512-bit，也就是64-bytes，64-14-4=46\n\n\nMTU：IP层的控制，其实这个值可以很大了，但是路径上的最小值才是决定因素，所以一般还是认为这个值是1500\nMSS: TCP层的控制，这个值应 小于等于 MTU，试想一下，如果MSS大于MTU，IP层因MTU拆了包分别是[1,2]，这时候IP层会给这两个包都加上IP-header，但是2这时候就没有TCP报文头了\n\nTCP 状态行为-&gt;状态wiki: https://en.wikipedia.org/wiki/File:Tcp_state_diagram_fixed_new.svg\n握手-&gt;挥手\n从状态讲起\nCLOSE: TCP 未打开或者是关闭的\nLISTEN: 监听端口打开\nSYN_SENT: 三次握手，发送SYN报文，然后状态进入SYN_SENT，等待 SYN_ACK，如果请求链接的一方有防火墙限制，会看到这个状态\n如果一定时间没有收到SYN_ACK，会重发SYN包，重发次数由 /proc/sys/net/ipv4/tcp_syn_retries 控制（默认5）\n重传的时间间隔：1s，2s，4s，8s，16s；然后等32s，总时长约1分钟\n\n\nSYN_RCVD: 对应 SYN_SENT， 收到SYN报文进入这个状态，等待第三次握手报文\n这里的链接被存储在半连接队列，常见的SYN攻击就是攻击的这个队列，如果这个队列满了，就不能再进来新的连接请求了\nnetstat -s | grep &#39;SYNs to LISTEN dropped&#39; 查看因半连接队列满造成的丢弃次数；累积值，需要定时轮询统计分析\n/proc/sys/net/ipv4/tcp_max_syn_backlog\n一定时间没有收到最后一次握手ACK报文，也会重发SYN_ACK，次数由/proc/sys/net/ipv4/tcp_syn_retries 控制（默认5）\n重传时间间隔同上\n收到ACK，进到全连接队列并通知到应用的accept，如果应用处理的慢，也会造成全连接队列满\n全连接队列：min(/proc/sys/net/core/somaxconn, backlog); 这里的backlog是程序listen的入参\n如果队列因为一些原因满了，为了更快响应 可以设置 /proc/sys/net/ipv4/tcp_abort_on_overflow &#x3D; 1，这样就会直接回个RST，避免客户端一直等待；这个值默认是0，因为如果是瞬间上来的量，服务端很有可能再SYN重试的时间内就腾出了accept队列空间，这时候客户端表现是连接时间比较长而已，但是收到RST就要重建连接了\nnetstat -s | grep &#39;socket overflowed&#39;  查看因accept队列满造成的丢弃次数；累计值，需要定时轮询统计分析\n\n\nESTABLISHED：连接成功的状态，可用来过滤统计有效连接数\n到达这个状态就可以互发消息了\n打开时间戳功能，/proc/sys/net/ipv4/tcp_timestamps在TCP报文传输的时候会带上发送报文的时间戳，解决序列号绕回造成的关闭一定需要等待的问题\nnetstat -s | grep &#39;timestamp&#39; 统计因timestamp校验错误导致包被拒绝的数量\n窗口扩大因子 /proc/sys/net/ipv4/tcp_window_scaling，窗口内的数据可以并行发送，窗口可扩大也就意味着两端传输可以提升发送速度\n发送缓冲区范围  /proc/sys/net/ipv4/tcp_wmem  一共三个值，分别是最小值，默认值，最大值 byte\n接收缓冲区范围  /proc/sys/net/ipv4/tcp_rmem  一共三个值，分别是最小值，默认值，最大值 byte\n内存范围  /proc/sys/net/ipv4/tcp_mem  一共三个值，分别是最小值，默认值，最大值 !! 单位是页（4K一页) !!\n！！这里遗漏了一些东西（超时重传、快速重传、滑动窗口、MSS），太多了而且机制很有意思，在下面说明\n\n\nFIN_WAIT_1: ESTABLISHED 状态，发送FIN报文请求关闭连接，并进入这个状态，一般很难见到\n这里一样有重传次数控制: /proc/sys/net/ipv4/tcp_orphan_retries 默认是0（特指8次）；可以看出，挥手要求比握手高，超过这个次数，就直接RST了\n这里也有一个FIN状态连接上限控制: /proc/sys/net/ipv4/tcp_max_orphans；超过这个上限的，就直接RST了\n还有一个超时控制:  /proc/sys/net/ipv4/tcp_fin_timeout；默认60s，同样超过了就直接RST\n\n\nFIN_WAIT_2: FIN_WAIT_1 后收到 ACK 报文，进入这个状态，一般也很难见到\n相关详细内容参考FIN_WAIT_1\n\n\nCLOSING: 如果是两端同时关闭，都发送了FIN，也收到了对方的FIN，但是还没有收到FIN的ACK，就会到这个状态，一般很难见到\nTIME_WAIT: 主动关闭的一方才有的状态，连接经历2个MSL(wiki)，关闭这个链接，一般会设置成60s*2\n避免延迟的数据段被相同的4元组连接收到\n等待被动关闭的那边收到完整的关闭消息\n调整数量限制：/proc/sys/net/ipv4/tcp_max_tw_buckets\n复用TIME_WAIT状态资源：/proc/sys/net/ipv4/tcp_tw_reuse， 注意SocketOptions.ReuseAddress是针对绑定端口的，可以绑定TIME_WAIT的端口\n快速回收TIME_WAIT状态socket： /proc/sys/net/ipv4/tcp_tw_recycle 但是不推荐启用：https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux -&gt; 中文： https://www.cnblogs.com/sunsky303/p/12818009.html\n2022-06-27 关于 tcp_tw_recycle 补充：linux kernel 4.12 (centos 8+ kernel 一般是 4.18), linux 移除了 tcp_tw_recycle 选项 commit -&gt; 实际代码注释掉了tcp_tw_recycle == 1的处理逻辑，每个新链接都在原基础上增加了 tcp timestamp 的 offsets 值 commit，在这个更新里面看到的是把原来的 tcp_time_stamp 换成了 tcp_time_stamp + tcp_rsk(req)-&gt;ts_off; ts_off 的初始化在 af_ops-&gt;init_seq(skb, &amp;tcp_rsk(req)-&gt;ts_off); 对于IPV4，对应的是 static u32 tcp_v4_init_sequence(const struct sk_buff *skb, u32 *tsoff)；而这个函数里面的写法是 hash[1] &#x3D; (__force u32)daddr; *tsoff &#x3D; hash[1]; 增加了偏移避免timestamp的单调递增\n\n\nCLOSE_WAIT: SOCKET 等待应用层主动调用close关闭SOCKET，因为网络层关闭了，上层应用需要处理自己的东西，比如缓冲区、句柄等等，如果netstat看到大量这种状态，基本确定是程序出问题了\nLAST_ACK：等待挥手最后一个ACK\n上面这些状态（除了CLOSE）都是占用着系统资源句柄的!!\nRST: 特殊的响应，暴力关闭、拒绝(不必挥手了，直接释放资源)\n未监听的端口访问\n不请自来的SYN&#x2F;ACK&#x2F;FIN\n处于 orphan 的socket\nclose() SO_LINGER\nl_onoff非0，l_linger为0，close()强制关闭(RST,ACK)\nl_onoff非0，l_linger非0，close() 优雅关闭(FIN)\n\n\ntcp_abort_on_overflow\nconnect_timeout\nkeepalive 超时\n\n\n\nTCP 可靠传输TCP 数据包结构wiki: https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AEwiki: https://en.wikipedia.org/wiki/Transmission_Control_Protocol\n超时重传\n保证可靠传输中最重要的机制，发送一条消息的时候设置一个定时器，定时器时间内如果没有收到对方的ACK确认包，就重发这条消息\n超时重传RTO: 超时重传的时间（上面那个定时器用的时间）\n这个时间多少是最合适的？ (https://www.ietf.org/rfc/rfc6298.txt)\nRTT: round-trip time. 往返时间:同一个包来回的时间（以毫秒为单位）\nSRTT: smoothed round-trip time. 平滑的RTT，在数学上使用之前的RTT时间计算出来的时间\nRTTVAR: round-trip time variation\n首次计算RTO: （这里的R是第一次测量的RTT，没有RTT的时候 RTO &lt;- TCP_TIMEOUT_INIT 1s）  SRTT &lt;- R  RTTVAR &lt;- R/2  RTO &lt;- SRTT + max (G, K*RTTVAR)where K = 4. G是clock granularity 时钟粒度，避免K*RTTVAR=0 (一般是100ms) https://stackoverflow.com/questions/12480486/how-to-check-hz-in-the-terminal\n后续  RTTVAR &lt;- (1 - beta) * RTTVAR + beta * |SRTT - R&#x27;|  SRTT &lt;- (1 - alpha) * SRTT + alpha * R&#x27;The value of SRTT used in the update to RTTVAR is its valuebefore updating SRTT itself using the second assignment.  Thatis, updating RTTVAR and SRTT MUST be computed in the aboveorder.The above SHOULD be computed using alpha=1/8 and beta=1/4 (assuggested in [JK88]).After the computation, a host MUST updateRTO &lt;- SRTT + max (G, K*RTTVAR)\nWhenever RTO is computed, if it is less than 1 second, then the RTO SHOULD be rounded up to 1 second.\nA maximum value MAY be placed on RTO provided it is at least 60 seconds.\nrfc6298 5. Managing the RTO Timer\n5.1. 发送一个带有数据的包后（包括重传），如果RTO定时器未启动，启动RTO定时器\n5.2. 在确认所有未完成的数据后，关闭RTO定时器\n5.3. 当收到确认新数据的ACK时，重新设置RTO时间为当前RTO值，然后重启定时器如果RTO超时了\n5.4. 接收器尚未确认的最早段\n5.5. RTO &lt;- RTO * 2 (“back off the timer”，指数回避策略)\n5.6. 重现设定RTO时间为当前RTO值\n5.7. 如果握手超时，并且RTO小于3s，连接后初始RTO使用3s （TCP_TIMEOUT_INIT， TCP_TIMEOUT_FALLBACK）\n\n\n\n\n超时重传次数：/proc/sys/net/ipv4/tcp_retries1 &amp; /proc/sys/net/ipv4/tcp_retries2 两个值控制，其中1之后会做一次路由更新\n额外：KCP(https://github.com/skywind3000/kcp) 里面提到的和TCP重要的区别，RTO只是1.5，这是一种UDP常用的超发策略，TCP认为超时的情况是网络拥堵了，发的越多会导致网络越来越差（堵）\n\n快速重传\n另外的重传机制，前面RTO是定时器，这个是依照数据\n首先，发送数据不可能是发送一次等一个ACK，这样太慢了，是发送N个包，有N个RTO定时器，这N个包在IP层很可能不是有序到达对端的，特别是ECMP的等价多路径连路上https://www.ietf.org/rfc/rfc3782.txtNewReno算法处理步骤：1) 三个重复的ACK确认  第3个重复的ACK确认到达而且发送方未进入快速恢复处理时，检查累计的确认值是否大于recover变量， 是则转步骤1A，否则转1B：1A) 调用快速重传：　　设置慢启动阈值(slow start threshold, ssthresh)为：　　ssthresh = max (FlightSize / 2, 2*smss)　　其中FlightSize表示已经发送但还没有被确认的数据量　　然后将发送在最大序列号值保存在recover变量中，转步骤2；1B) 不调用快速重传：　　不进入快速重传和快速恢复处理，不改变ssthresh，不用执行步骤2，32) 进入快速重传　　重传丢失的包然后设置拥塞窗口CWnd=ssthresh + 3*SMSS，扩大拥塞窗口；3) 快速恢复　　在快速恢复阶段，对于所接收到的每个重复的ACK包，拥塞窗口递增SMSS，扩大拥塞窗口；4) 快速恢复继续　　发送一个数据段，如果新的cwnd和接收端的通知窗口的值允许的话5) 当一个确认新数据的ACK到达时，此ACK可能是由步骤2中的重传引发的确认，或者是由稍后的一次重传引起的，分完整确认和部分确认两种情况：　　完整确认：　　此ACK确认了所有数据的序列号括了recover记录的序列号，则此ACK确认了所有中间丢失的数据包，此时调整cwnd或者为(1) min(ssthresh, FlightSize + SMSS)；或者(2) ssthresh 来缩小cwnd，结束快速恢复。　　部分确认：　　如果这个ACK不确认所有并包含到“recover”的数据的话，就产生一个部分ACK。在此种情况下，重传第一个没有确认的数据段。按确认的新数据量来减小拥塞窗口，如果这个部分确认确认了至少一个MSS的新数据，则加回一个MSS。如果cwnd的新值允许的话，发送一个新数据段。这个“部分窗口缩减”试图确定当快速恢复最终结束时，大约ssthresh数量的数据还在向网络中传送。此情况下不退出快速恢复过程。对在快速恢复期间第一个到达的部分ACK，也要重设重传定时器。6) 重传超时　　重传超时后，将发送的最大序列号保存在recover变量中，结束快速恢复过程。\n\n这张图上\n假设接收方收到包的顺序&#x3D;发送方发送的顺序\n假设发送方发送了第2个包 2: 500-999 在 第4个包到达之后才到达\n假设开启了SACK功能\n发送方收到R3回执的时候，ACK 500 这个信息收到了3次，触发快速重传，发送第5步\n这时候接收方收到了前面第2步的包，回执R4: ACK 2000 （没有了SACK信息，因为没有空洞数据了）\n然后又收到了第5步的数据，说明但是数据重复了，就回了一个R5: 带D-SACK信息的包告诉发送方重复发送了\n\n\nSACK: /proc/sys/net/ipv4/tcp_sack\nD-SACK: /proc/sys/net/ipv4/tcp_dsack\n\n流量控制-滑动窗口\nwiki: https://en.wikipedia.org/wiki/Sliding_window_protocol\n控制发送者的发送速度，让接收者来得及接收数据，避免接收不过来导致数据丢失\n前面说到 首先，发送数据不可能是发送一次等一个ACK，这样太慢了，是发送N个包，有N个RTO定时器，这N个包在IP层很可能不是有序到达对端的，特别是ECMP的等价多路径连路上\n这个N个包也是有限制的，这个限制就是滑动窗口\n滑动窗口大小是以字节为单位的，TCP报文里面的WIN就是窗口大小（16位&#x3D;2字节&#x3D;65535），TCP作为双工模式，这个窗口大小也是两种，接收窗口大小、发送窗口大小\n双方相互告知自己的接收窗口大小，\n接收窗口大小意义：发送数据的时候不能超过另一方的接收窗口大小，不然接收的那一方就无法正常接收到数据了\n发送窗口大小意义：发送N多的数据，没有及时拿到ACK的话就会导致可用窗口越来越小，到0的时候就不再发送数据了\n\n\n可以看出来，窗口大小是会影响发送速度的\n只有2字节表示窗口大小显然不够，TCP报文的选项里定义了窗口扩大因子WINDOW SCALINGFor more efficient use of high-bandwidth networks, a larger TCP window size may be used. The TCP window size field controls the flow of data and its value is limited to between 2 and 65,535 bytes.Since the size field cannot be expanded, a scaling factor is used. The TCP window scale option, as defined in RFC 1323, is an option used to increase the maximum window size from 65,535 bytes to 1 gigabyte. Scaling up to larger window sizes is a part of what is necessary for TCP tuning.The window scale option is used only during the TCP 3-way handshake. The window scale value represents the number of bits to left-shift the 16-bit window size field. The window scale value can be set from 0 (no shift) to 14 for each direction independently. Both sides must send the option in their SYN segments to enable window scaling in either direction.Some routers and packet firewalls rewrite the window scaling factor during a transmission. This causes sending and receiving sides to assume different TCP window sizes. The result is non-stable traffic that may be very slow. The problem is visible on some sites behind a defective router.[24]\n滑动窗口分为4部分：图片来自（https://www.cnblogs.com/xiaolincoding/p/12732052.html）\n#1. 已经收到ACK确认的数据\n#2. 已经发送但是还没有收到ACK确认的数据\n#3. 在窗口大小内，还没有发送的数据\n#4. 窗口外的数据\n\n\n额外：前面快速重传+SACK图，发送0-499，ACK: 500，这个500就是告知对方发送的窗口指针可以移到那个位置了\n发送窗口发送数据的策略：Nagle 延时发送策略 （https://en.wikipedia.org/wiki/Nagle%27s_algorithm）\n#1. 待发送数据大小 &gt;&#x3D; MSS\n#2. 对方窗口大小 &gt;&#x3D; MSS\n#3. FIN 包\n#4. TCP_NODELAY\n#5. 收到了之前发送数据的确认包\n#6. 200ms timeout\n\n\n延迟确认 （delayed ACKs）\n确认包很小，默认准备好确认包40ms timeout 发送，如果这期间有其他包需要发送，就把确认包一起带上发送出去\n\n\n\n拥塞控制\nwiki (https://en.wikipedia.org/wiki/TCP_congestion_control)\n流量控制是一个socket通道上的，拥塞控制属于链路上的网络环境，在较差的网络环境上TCP的重传机制会使网络负担越来越重，因此就有了拥塞控制的内容，避免雪崩式拥塞，若出现拥塞而不进行控制，整个网络的负担会随着输入的负荷增大而增大，恶性循环，因此加入拥塞控制机制避免这种情况\n概念：拥塞窗口: cwnd 是确定可以随时发送的字节数的因素之一。拥塞窗口由发送方维护，是一种阻止发送方和接收方之间的链接因流量过多而过载的方法。这不应与接收器保持的滑动窗口混淆，该滑动窗口存在以防止接收器过载。通过估算链路上有多少拥塞来计算拥塞窗口。\n建立连接后，拥塞窗口（在每个主机上独立维护的值）将设置为该连接所允许的MSS的很小的倍数。拥塞窗口的进一步变化由加性增加&#x2F;乘性减少（AIMD）方法决定。这意味着，如果所有段均已接收并且确认已按时到达发送方，则将某些常量添加到窗口大小中。当窗口达到ssthresh时，在收到的每个新确认中，拥塞窗口以1 &#x2F;（拥塞窗口）段的速率线性增加。窗口不断增长，直到发生超时。超时时：\n#1. 拥塞窗口重设为1 MSS。\n#2. ssthresh设置为超时前拥塞窗口大小的一半。\n#3. 启动慢速启动。\n\n\n\n下面将围绕拥塞控制的内容具体说下TCP拥塞控制的算法\n\n#1. 慢启动\n#2. 拥塞避免\n#3. 拥塞发生（快重传）\n#4. 快恢复\n\n慢启动\n慢启动简单的说就是刚建立网络连接的时候，一点点的提速，而不是一上来就把通道占满\n具体的过程：\n#1. 连接建立之初，cwnd = 1，此时可以传 1*MSS 大小的数据\n#2. 收到一个确认包ack，cwnd += 1\n#3. 这时候就可以发送 2*MSS 的数据了，接收方会回复 2*ack，for(2次) cwnd += 1\n#4. cwnd 的增长呈指数增加 1, 2, 4, 8….\n#5. cwnd 的增长也是有上限的，cwnd &lt; ssthresh (NewReno算法处理步骤)\n\n\n\n拥塞避免\n上面慢启动的过程是cwnd &lt; ssthresh，当cwnd &gt;= ssthresh时候，就到了拥塞避免阶段\n上面慢启动是一个指数增长，而拥塞避免是线性增长的过程，假设 ssthresh == 8图片来自（https://www.cnblogs.com/xiaolincoding/p/12732052.html）\n\n拥塞发生（快重传）\n拥塞线性增长到达一定值的时候，网络负担会越来越重，这时候就会有包开始因为网络拥塞而重传了\n这里有两种情况：\n#1. 超时重传（RTO超时没有收到确认包）\n\nssthresh = cwnd / 2; cwnd = 1;此时大部分情况cwnd &lt; ssthresh，回到慢启动状态\n\n#2. 快速重传（接收方发现中间少了包，重复发了三次前一个包的ack，触发快速重传）\n\ncwnd = cwnd / 2; ssthresh = cwnd;此时大部分情况cwnd == ssthresh，回到拥塞避免状态\n\n\n快速恢复\n拥塞发生时候，当是快速重传的情况\n#1. 收到了3个重复的ack\n#2. cwnd = cwnd / 2; ssthresh = cwnd;\n#3. cwnd += 3;\n#4. 发送中间丢的数据包\n#5. 收到确认ack，cwnd += 1;\n#6. 基本回到之前的状态了\n\n\n\n汇总图\n错误控制\nTCP 最常见的错误：(wireshark 经常看到的标记黑色的那些)\nTCP Retransmission (tcp重传：发送端发送的数据接收端一定时间RTO没有收到，就会触发这个错误，发送端将触发重传)\nTCP Fast Retransmission (tcp快速重传：上面是RTO时间，这个是收到了3个重复的ACK确认序号触发的快速重传)\nTCP Dup ACK 数字A#数字B (tcp重复ACK：数字A是重复的序列号，数字B是重复的次数)\nTCP Out-of-order (接收到的顺序错乱：一般是发送端到接收端链路上有多个路径，一条长路径上的晚到了，TCP会做一些工作保证顺序重组)\nTCP window update (窗口更新)\nTCP zerowindow (包种的“win”代表接收窗口的大小，当Wireshark在一个包中发现“win&#x3D;0”时，就会发提示。)\nTCP window Full (窗口被填满了)\n\n\n\nsysctl.conf 调优kernel.sysrq = 0kernel.core_uses_pid = 1kernel.msgmnb = 131070kernel.msgmax = 131070kernel.shmmax = 68719476736kernel.shmall = 4294967296kernel.pid_max = 65536fs.file-max = 1000000vm.swappiness = 0vm.overcommit_memory = 1vm.vfs_cache_pressure = 50vm.min_free_kbytes = 65536net.ipv4.ip_forward=0net.ipv4.tcp_retries1 = 3net.ipv4.tcp_retries2 = 2net.ipv4.tcp_keepalive_intvl = 30net.ipv4.tcp_keepalive_probes = 4net.ipv4.tcp_keepalive_time = 1200net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_fin_timeout = 30# tcp TLP kernel &lt; 4.0 设置，避免错误的retransmissionnet.ipv4.tcp_early_retrans = 0# tcp closed cache，影响慢启动net.ipv4.tcp_no_metrics_save = 1net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 0net.ipv4.tcp_max_syn_backlog = 524288net.ipv4.tcp_syncookies = 0net.core.netdev_max_backlog = 524288net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.core.somaxconn = 524288net.ipv4.tcp_rmem = 8192 87320 16777216net.ipv4.tcp_wmem = 8192 87320 16777216net.ipv4.tcp_mem = 87320 1310720 10485760net.ipv4.ip_local_port_range = 1024 65535net.ipv4.tcp_window_scaling = 1# 这里的调整可能不太合适，上面开启了tcp_tw_reuse# 这里如果过大，会减轻reuse的触发# 但是也会造成TIME_WAIT端口量很大（特别是短连接服务），理论上会导致 cpu sy 部分占用较高，实际调整要根据具体应用分析，当然这个值也不能太小，参考值 500000net.ipv4.tcp_max_tw_buckets = 1440000net.ipv4.neigh.default.gc_stale_time = 60net.ipv4.neigh.default.gc_thresh1 = 1024net.ipv4.neigh.default.gc_thresh2 = 4096net.ipv4.neigh.default.gc_thresh3 = 8192net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0net.ipv6.conf.all.disable_ipv6=1net.netfilter.nf_conntrack_max = 16777216net.netfilter.nf_conntrack_tcp_timeout_established = 1200net.netfilter.nf_conntrack_tcp_timeout_time_wait = 60net.netfilter.nf_conntrack_tcp_timeout_last_ack = 30net.netfilter.nf_conntrack_tcp_timeout_close_wait = 30net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 30net.netfilter.nf_conntrack_tcp_timeout_syn_recv = 30net.netfilter.nf_conntrack_tcp_timeout_syn_sent = 30\n\n参考\nhttps://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6\nhttps://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE\nhttps://www.cnblogs.com/xiaolincoding/p/12732052.html\nhttps://en.wikipedia.org/wiki/Transmission_Control_Protocol\nhttp://www.medianet.kent.edu/techreports/TR2005-07-22-tcp-EFSM.pdf\nhttps://tonydeng.github.io/sdn-handbook/linux/tc.html\nhttp://blog.hyfather.com/blog/2013/03/04/ifconfig/\nhttps://tonydeng.github.io/sdn-handbook/linux/kernel-network-params.html\nhttps://plantegg.github.io/2019/05/08/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C--%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%B5%81%E8%BD%AC/\nhttps://access.redhat.com/sites/default/files/attachments/20150325_network_performance_tuning.pdf\nhttps://blog.csdn.net/dog250/article/details/51439747\nhttps://www.cnblogs.com/yulia/p/10346339.html\nhttps://beta.computer-networking.info/syllabus/default/exercises/tcp.html\nhttps://beta.computer-networking.info/syllabus/default/exercises/tcp-2.html\n\n2022-06-27 更新参考\nhttps://www.cnblogs.com/brucemengbm/p/7028969.html - tcp_tw_recycle检查tcp_timestamps的内核代码\nhttps://blog.51cto.com/professor/1909022 - TCP timestamp 相关知识\nhttps://juejin.cn/post/7094826862970404895 - 我们为什么关掉了 TCP Timestamp\n\n","categories":["网络"],"tags":["网络"]},{"title":"网络：ICMP","url":"/archives/f04c5e28.html","content":"当我们判断网络是否可用的时候感谢baidu.com\n\nping 命令是使用ICMP报文\n\nICMP 报文具体是什么呢？\n\nfrom 互联网控制消息协议:  https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E6%8E%A7%E5%88%B6%E6%B6%88%E6%81%AF%E5%8D%8F%E8%AE%AE  \n\nType - ICMP的类型,标识生成的错误报文；\n\nCode - 进一步划分ICMP的类型,该字段用来查找产生错误的原因.；例如，ICMP的目标不可达类型可以把这个位设为1至15等来表示不同的意思。\n\nChecksum - Internet校验和（RFC 1071），用于进行错误检查，该校验和是从ICMP头和以该字段替换为0的数据计算得出的。\n\nRest of Header - 报头的其余部分，四字节字段，内容根据ICMP类型和代码而有所不同。\n\nIdentification： 标识符：linux-进程PID，windows-固定值1\nSequence number: 序列号\n\n\n!! 注意：这里多了Timestamp 8字节，这里测试时用的MacOS（参考：hping）\n\nICMP数据 - 48字节\n\n总共是：src-mac(6字节) + dst-mac(6字节) + 类型(2字节) + IP报文(20字节) + ICMP报文(8字节) + ICMP数据(48字节) + Timestamp(8字节)\n\n\n\n\nICMP 作用概念\nICMP: Internet Control Message Protocol 控制报文协议\nICMP 和 IP 处于同一层，但是ICMP是配合IP协议一起使用的，补充IP协议的差错控制和辅助机制\n分为差错报告和查询两种报文类型\n差错：目的主机或者网络路由处理IP数据报文的时候出问题了就报告\n查询：最常见的应用就是ping、traceroute这样的使用了，发送请求，并要求回执\n\n\n\n差错报文\n那些情况会有差错报告：\n目的站不可达，很多可能都会造成这种情况：没有网络，主机找不到，协议，端口找不到，路由失败\n源站抑制，机器本身或者网络上的其他设备网络拥塞导致数据丢了\n超时：假设一个数据报被分片发送了，一定时间内没有收到全部的分片，已经收到的就会被丢弃掉，并且产生一个这样的报文告知\n参数问题：协议数据校验发现错误了，就会丢掉这个数据报，并且报告\n改变路由：A点到B点需要经过很多的路由设备，如果其中一个路由设备不可用或者发现了更优路径了，需要切换路由设备了，会产生这样一个报文，让上一层知道下一次路由用已经切换过的节点吧\n\n\n那些情况及时出问题也不会报告差错：\n本身ICMP就是差错报告的包出错了，不会报告，不然就是递归了\n分片的数据报，不会报告(IP分片的第一片会报，其他片不会)\n多播的数据报，不会报告\nlocalhost地址，不会报告\n\n\n上面这些差错报告，是可能由路由层发出的，而路由层解包的是IP层的协议，ICMP可以看做是IP协议的子类\n\nICMP 报文类型\nICMP 工具1. ping\n最常用的工具了，上面介绍ICMP也用的这个\n\n2. why dose ping need setuid permissionhttps://unix.stackexchange.com/questions/382771/why-does-ping-need-setuid-permission; 这个问题包含的知识挺多的\n\nsuid : https://www.cnblogs.com/sparkdev/p/9651622.html\nraw network socket : https://stackoverflow.com/questions/14774668/what-is-raw-socket-in-socket-programming\nraw network socket wiki: https://en.wikipedia.org/wiki/Network_socket\ngetcap: https://www.man7.org/linux/man-pages/man8/getcap.8.html\ntraceroute -T 需要root也是因为socket_raw的关系\nwindows 的 tracert 没有 tcp 的选项，但是可以自己写程序模拟，但是自己的程序需要administrator权限\nwindows 的 ping 没有特别的要求administrator权限，是win有个特殊的icmp.dll 不需要管理员权限就可以用，而ping是基于这个实现的 (https://www.thoughtco.com/implementing-ping-without-using-raw-sockets-4068869)\n有时候icmp的路径探测是不准确的，(不同协议路由的路径很可能不同); 这时候我们需要个tcp的路径探测包在自己的程序里，(TTL递增)代码很简单，只是需要记得需要管理员权限\nttl(Time To Live):代表是报文的存活时间，存活时间以秒为单位，但小于一秒的时间均向上取整到一秒。在现实中，这实际上成了一个跳数计数器：报文经过的每个路由器都将此字段减1，当此字段等于0时，报文不再向下一跳传送并被丢弃，最大值是255（8bit）图片来源：https://www.cloudflare.com/zh-cn/learning/cdn/glossary/time-to-live-ttl/\n\n3. traceroute 路径探测wiki: (https://en.wikipedia.org/wiki/Traceroute)man page: (https://linux.die.net/man/8/traceroute)\n\n默认是UDP探测，利用IP协议TTL字段，第一次TTL&#x3D;1探测一个路由节点，收到ICMP Type&#x3D;11, Code&#x3D;0的Time Exceeded\n\n做下一次，TTL递增，直到探测到目标节点，到达目标接地那会收到ICMP Type&#x3D;3 Code&#x3D;3之前的路径太长了，这次探测换了路径中一个近的路由点\n\ntraceroute 可以选择ICMP、UDP、TCP模式，并可以选择最多探测多少（也就是TTL最大多少）\n\n指定–mtu也可以探测路径上的mtu，但是下一次发消息不一定是探测的路径，所以这个值只能用作参考\n\n行程中的一些附加注释：这些都对应了ICMP的Type&amp;Code，具体抓包可以看到\n\n!H 主机不可达\n!N 网络不可达\n!P 协议不可访问\n!S 源路由失败\n!F 需要分段\n!X（管理性通信）禁止\n!V 违反主机优先级\n!C 有效优先级截止\n!(num)（ICMP无法访问代码(num)）\n\n\n如果几乎所有的探测导致某种无法到达的情况，traceroute将放弃并退出。\n\ntraceroute * * * Qos&#x2F;ACL\n\n根据差错报文的规则，我们用TCP+TTL访问一个不存在的端口，就可以探测出TCP的路由路径，TTL超时（type=11 code=0)表示没有到达目标点，RST（type=3 code=3 也有可能是其他）、connected表示到达了目标点\n\n\nECMP 等价多路径wiki: (https://en.wikipedia.org/wiki/Equal-cost_multi-path_routing)\n\n消息报从A点发送到B点，链路上会有很多路由节点，但是有一些路由节点是是核心的路由节点，图示的线路\n如果traceroute遇到ECMP（等价路径点A&amp;B)，也就是这次经过等价路径的A，但是下次很可能经过的B\n\n说明\n由于现在网络环境大都有NAT、防火墙等设备、策略，ICMP的检测只能作为参考，甚至ICMP拿不到结果\n指定目标IP:Port，指定协议，这样检测出来的结果相对价值更大\nICMP的差错报文可以帮助我们考虑网络问题可能出现在哪个方面\n日常多抓包，多看\n\n","categories":["网络"],"tags":["网络"]},{"title":"网络：NAT STUN","url":"/archives/1fb5c021.html","content":"前言之前工作中有机会接触到p2p相关内容，目标是实现一个p2p下载器，基本可以算是从0开始，看了NAT、torrent、KCP等相关内容。\n\ntorrent 相对成熟，做上层开发也很简单，但是并不适合我们需求的场景; 不过自己下载器实现的时候也参考了libtorrent源码上的一些设计。\nKCP 传输上的设计也给了不少启发。\nNAT 这里我认为最完整也最棒的文档来自华为\n\nNAT 简介\nnetwork address translation. 将IP数据报文头中的IP地址转换为另一个IP地址的过程\n目的: 简单点说是IPV4地址（公网）不够大家用了，NAT设备通过IP层地址替换的方式让多个人使用一个IP地址（公网）\n问题: NAT也带来最直接的问题就是大家基于N个IP地址被划分成了N个块，而由于NAT类型的限制，我们不容易直接暴露自己的网络到公网了，而P2P网络要求通信双方都可以主动发起访问，NAT也就阻碍了P2P网络应用的使用\n\nNAT STUN\n简要：STUN协议（Simple Traversal of UDP Through NAT），基于UDP的NAT打洞技术，为了解决NAT给P2P网络带来的问题\n定义：NAT会话穿越应用程序STUN（Session Traversal Utilities for NAT）是一种由RFC定义的网络协议，作为其他协议（例如SIP、FTP、DNS）处理NAT穿越问题的一个工具。其可以用于检查网络中NAT设备的存在，并确定两个通信端点被NAT设备分配的IP地址和端口号。然后，通过ICE（Interactive Connectivity Establishment），自动创建一条能够进行NAT穿越的数据通道。\n\nNAT 类型（STUN标准）华为官方文档https://support.huawei.com/enterprise/zh/doc/EDOC1100112409/fd829977\n\nFull Cone NAT（完全锥型NAT）所有从同一个私网IP地址和端口（IP1:Port1）发送过来的请求都会被映射成同一个公网IP地址和端口（IP:Port）。并且，任何外部主机通过向映射的公网IP地址和端口发送报文，都可以实现和内部主机进行通信。这是一种比较宽松的策略，只要建立了私网IP地址和端口与公网IP地址和端口的映射关系，所有的Internet上的主机都可以访问该NAT之后的主机。\nRestricted Cone NAT（限制锥型NAT）所有从同一个私网IP地址和端口（IP1:Port1）发送过来的请求都会被映射成同一个公网IP和端口号（IP:Port）。与完全锥型NAT不同的是，当且仅当内部主机之前已经向公网主机发送过报文，此时公网主机才能向私网主机发送报文。\nPort Restricted Cone NAT（端口限制锥型NAT）与限制锥型NAT很相似，只不过它包括端口号。也就是说，一台公网主机（IP2:Port2）想给私网主机发送报文，必须是这台私网主机先前已经给这个IP地址和端口发送过报文。\nSymmetric NAT（对称NAT）所有从同一个私网IP地址和端口发送到一个特定的目的IP地址和端口的请求，都会被映射到同一个IP地址和端口。如果同一台主机使用相同的源地址和端口号发送报文，但是发往不同的目的地，NAT将会使用不同的映射。此外，只有收到数据的公网主机才可以反过来向私网主机发送报文。这和端口限制锥型NAT不同，端口限制锥型NAT是所有请求映射到相同的公网IP地址和端口，而对称NAT是不同的请求有不同的映射。\n\nNAT能访问的时候是怎么样的呢？\nFull Cone NAT（完全锥型NAT）\n首先192.168.0.11:1024端口请求了102.101.10.1的任意端口\nNAT设备做了地址映射，把192.168.0.11:1024映射到456端口上\n这样任意访问NAT设备上456端口的数据都会被映射到192.168.0.11:1024上\n也就是说203.201.20.2发送到NAT:456的数据会被转到192.168.0.11:1024上\n\n\nRestricted Cone NAT（限制锥型NAT）（其实这里我更喜欢叫做address-restricted-cone，对应下面的port-restricted-cone）\n同上 192.168.0.11:1024端口请求了102.101.10.1的任意端口\nNAT设备做了地址映射，把192.168.0.11:1024+102.101.10.1映射到456端口上\n这时候203.201.20.2发送到NAT:456的数据会因为找不到映射被丢弃掉\n如果 192.168.0.11:1024端口请求了203.201.20.2的任意端口\nNAT设备做了地址映射，把192.168.0.11:1024+203.201.20.2映射到456端口上（这里映射一样是456，因为源都是192.168.0.11:1024）\n然后203.201.20.2发送到NAT:456的数据就可以找到正确的私网二元组了\n\n\nPort Restricted Cone NAT（端口限制锥型NAT）\n同上 192.168.0.11:1024端口请求了102.101.10.1的2048端口\nNAT设备做了地址映射，把192.168.0.11:1024+102.101.10.1:2048映射到456端口上\n这时候不仅其他IP发送到NAT:456的数据会找不到映射被丢掉，102.101.10.1非2048端口的数据发送到NAT:456的数据会因为找不到映射被丢弃掉\n如果 192.168.0.11:1024端口请求了203.201.20.2的2048端口\nNAT设备做了地址映射，把192.168.0.11:1024+203.201.20.2:2048映射到456端口上（这里映射一样是456，因为源都是192.168.0.11:1024）\n然后203.201.20.2:2048发送到NAT:456的数据就可以找到正确的私网二元组了\n\n\nSymmetric NAT（对称NAT）\n流程和Port Restricted Cone NAT一样\n只是NAT上的映射不一样了，我们这里假设192.168.0.11:1024+102.101.10.1:2048被映射到了456端口，把192.168.0.11:1024+203.201.20.2:2048被映射到其他端口比如789上\n\n\n\nNAT 侦测这部分华为是个主文字的文档，也建议先看一遍文字版本\nSTUN 报文https://tools.ietf.org/html/rfc3489\nAll STUN messages consist of a 20 byte header:0                   1                   2                   30 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|      STUN Message Type        |         Message Length        |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                        Transaction ID+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                                                                |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+The Message Types can take on the following values:    0x0001  :  Binding Request    0x0101  :  Binding Response    0x0111  :  Binding Error Response    0x0002  :  Shared Secret Request    0x0102  :  Shared Secret Response    0x0112  :  Shared Secret Error Response\n\nSTUN 侦测流程图\n\n图里有2处虚线的部分，是当时因为bug看到的异常情况，当时发现如果Test II加上一步Test III，会大概率导致结果变成Full Cone，暂时没有找到相关文档说明，大家可以多试试（这也帮助我修改了后面穿透的流程，使得port-restricted-cone和symmetric有更大机会直接穿透）\n\n穿透穿透的难度\n根据上面NAT类型映射的方式，我们可以看到非对称类型的NAT设备，如果102.101.10.1是个我们自建的服务器，就可以拿到给203.201.20.2用的二元组，让它可以正常发送消息给192.168.0.11机器\n对称NAT设备，除了暴力遍历或者一定算法下的遍历试出来789这个端口，基本没有其他办法穿透NAT设备了\n\n原因不明的投机取巧\n\n也就是基于上面探测流程里虚线部分的逻辑\n假设192.168.0.11对应NAT设备10.227.90.131是个symmetric类型，映射的NAT端口是未知的X\n假设192.168.1.22对应NAT设备201.127.10.1是个port-restricted-cone类型，映射的NAT端口是已知的1000\nstep 1. symmetric 给 cone 类型已知端口发送N次消息(这里N次只是尽可能让udp消息到达)，消息会被NAT丢掉\nstep 2. cone 再给 symmetric 发送N次消息\n大概率是可以发送成功的，试了很多次，觉得反正这两种类型本就不好穿透，既然这样可行就先备在代码里了\n\n参考\n华为：https://support.huawei.com/enterprise/zh/doc/EDOC1100112409/fd829977 \nRFC: https://tools.ietf.org/html/rfc3489\nSTUN: http://www.networksorcery.com/enp/protocol/stun.htm\nhttps://www.cnblogs.com/my_life/articles/1908552.html\nhttps://dearmiku.github.io/2017/11/17/NTA%E6%89%93%E6%B4%9E/\n\n","categories":["网络"],"tags":["网络"]},{"title":"网络：P2P下载器","url":"/archives/c0cdd768.html","content":"前言\n#1. 假设N个人同时从一个地方A下载东西，A的发送流量会暴涨\n#2. 假设A从N处下载一个东西，A的接收流量会暴涨\n这两种情况都是运营商不愿意看到的，运营商更希望上下行带宽都尽量平稳均匀分配下去\nNAT越来越多主要是Symmetric类型了\nNAT篇 介绍已知Symmetric类型对Port-Restricted-Cone类型很难做到穿透，这造成现在的P2P下载相关越来越少\n\n目标\n在CDN下载基础上，增加P2P辅助下载，节省CDN成本，也尽量为下载加速\n基于CDN的下载保持下载压缩文件的方式\n\n相关知识\nCDN服务器已经很便宜了，而且大厂的节点覆盖很广，速度也有保障，但是我们游戏包体超过70G（压缩后40G），即使选择类似带宽峰值的付费方案成本还是很大的\n最直接的就是加上P2P的下载方式\n基于google webRTC 音频视频行业的兴起，初看好像这是个做下载器很不错的东西（只是我自己没做过JS开发，提前就选择放弃了\ntorrent已经是很成熟的技术了，在备选列表\nSTUN、TURN、ICE 我们只需要P2P的下载，如果NAT无法穿透，走HTTP下载压缩内容就好，TURN、ICE就被排除了，只需要一个侦测IP地址和NAT类型的STUN服务\n\ntorrent是否可行？\ntorrent 基于一定格式的种子文件，不断请求tracker服务对端列表，尝试穿透下载开始下载\n对于纯torrent下载的方式是很合适的，想在里面加入混合cdn下载的方式，就比较麻烦了\n我们自己部署peer也是不可行的，\n普通服务器的流量、带宽成本是比cdn贵很多的\n如果不能在网络边缘节点部署torrent-peer，也会导致部分玩家下载速度不稳定或者很慢\ncdn服务器一般都只会开放80的http端口\n\n\n\n方向\n基于上面的目标：\n玩家机器上是解压过的文件，P2P也就需要传输原始文件（或者分享一方读取原始文件，压缩后传输，接收一方接到压缩内容，解压后写入）\n为了保证CDN和P2P同时进行，CDN下载压缩内容，写入玩家磁盘需要是已经解压过的内容（在内存解压）\n下载内容需要以文件为单位了，无论是CDN的HTTP还是P2P\nCDN传输压缩数据，但是写入磁盘需要是以文件为单位的解压后数据，需要研究下怎么能边下载边解压\nP2P是基于UDP的，不可靠的传输需要在接收一方增加验证机制，一次传输的限制（MTU）需要一定的验证传输内容和是否接收完成的规则\n有些游戏单个文件可能会很大，不能是整个文件接收完了再验证，这样很可能导致很大的进度回滚\n\n问题很多，一个个解决吧HTTP 边下载边解压\n压缩文件格式 zip-format///////////////////////////////////////////////////////////////////////////*// https://users.cs.jmu.edu/buchhofp/forensics/formats/pkzip.html        0x0 0x1 0x2 0x3 0x4 0x5 0x6 0x7 0x8 0x9 0xa 0xb 0xc 0xd 0xe 0xf0x0000 |signature     |ver    |flag   |comp   |time   |data   |crc    |0x0010 |crc   |z-size         |unz-size       |f-n-l  |e-f-l  |filename0x0020                      (variable size)                           |0x0030 |extra field         (variable size)                           |*///////////////////////////////////////////////////////////////////////////#pragma pack(push, 1)struct local_file_header&#123;    static constexpr uint32_t _signature = 0x04034b50;  // https://stackoverflow.com/questions/50332569/why-i-am-getting-this-error-constexpr-is-not-valid-here    uint16_t                  _version   = 0;    uint16_t                  _flag      = 0;    uint16_t                  _compression_mod = 0;    uint16_t                  _mod_time = 0;    uint16_t                  _mod_date = 0;    uint32_t                  _crc = 0;    uint32_t                  _compressed_size = 0;    uint32_t                  _uncompressed_size = 0;    uint16_t                  _file_name_len = 0;    uint16_t                  _extra_field_len = 0;    // variable size (filename)    // variable size (extra field)&#125;;struct central_directory_header&#123;    static constexpr uint32_t _signature = 0x02014b50;  // https://stackoverflow.com/questions/50332569/why-i-am-getting-this-error-constexpr-is-not-valid-here    // 不处理了，直接返回&#125;;#pragma pack(pop)\n简单点看，zip结构分为3块\n#1.local_file_header\n#2.data\n#3.central_directory_header\n\n\n其中[#1.local_file_header][#2.data]紧邻，以一个个文件划分\nlocal_file_header里面也包含file_name、crc、uncompressed_size等信息\n从上面看问题简单了，只需要参考miniunzip代码，把从磁盘读数据解压换成从网络读数据解压就好了\n理论上磁盘写入速度是比网络传输快的，所以网络读取开一个socket就好\n实际操作中遇到的问题：\n#1. miniunzip 代码是依赖central_directory_header解析下载的，但是因为现在读取文件是从网络，不好做到偏移到最后读完central_directory再解析；还好local_file_header里的内容是够用的\n#2. 虽然有zip crc的校验，但是是否真正下载完成还是需要一个文件md5更准确的校验\n#3. 遇到游戏文件更新那种很可能是只下载zip-file某几个文件段，也就是需要提前知道下载那些文件，这些文件在那些zip-file range 段\n#4. 需要标记某个文件正在被HTTP还是P2P下载，并且避免两者重复下载\n\n\n处理 #1. 按照zip格式和miniunzip代码参考，实现基于local_file_header信息的文件解压\n处理 #2. 每个文件的文件名和md5单独记录成一个信息文件 .filelist\n处理 #3. .filelist 文件增加zip_startpos, zip_endpos值标记所在zip文件的绝对位置（包含local_file_header）, .filelist文件结构如下  +,(md5),(filename),(zip_pos-start),(zip_pos-end),(zip-size),(unzip-size)eg. +,fcf36e5c7b0e345c24539f8dfe5357cb,file_test1.txt,0,108592,108544,648704+,3b18132de2b0d07cd8d0193cb449e68b,file_test2.txt,0,108592,108544,648704\n处理 #3.1. http请求分段range的内容，回执会有多余的内容如下，需要单独解析ignore掉  /*&gt;&gt; curl http://xxxxx.zip  -H &quot;Range: bytes=443079-443083, 11883693-11883697&quot;--Cdn Cache Server V2.0:0787E385DC32A96203E8A7DCD10E5D99Content-Type: application/octet-streamContent-Range: bytes 443079-443083/18670564PK--Cdn Cache Server V2.0:0787E385DC32A96203E8A7DCD10E5D99Content-Type: application/octet-streamContent-Range: bytes 11883693-11883697/18670564PK--Cdn Cache Server V2.0:0787E385DC32A96203E8A7DCD10E5D99--*/\n处理 #4. 文件列表顺序是一定的，规定zip从第一个需要下载文件的顺序向后下载，p2p从最后一个需要下载的文件向前下载，并增加内存里文件下载状态的标记\n\nP2P 下载\nP2P NAT 穿透相关知识在这里：NAT篇 \n需要一个STUN-server做客户端网络侦测\n侦测后上报到一个管理服务器Collect-server做信息收集，并且分发给其他客户端可用的对端信息\nP2P 使用udp协议（因为TCP穿透可能性更小），udp是不可靠传输（是否到达和到达顺序都无法保证），为保证传输稳定，每条消息应尽量保证再一个mtu内\n另外前面提到了，最好不要整个文件传输完了才校验文件是否正确，尽量在中间就校验\n\n问题和处理方案\nmtu常规（这里只是举例，实际还是在两端穿透之后尝试测试一下mtu最好）： 1500 - 20(IP报文) - 16(UDP报文) ~&#x3D; 1450，自己封包也会占用36个字节左右(protobuffer)，然后习惯取整1024，一个数据长度1024，我这里以64个数据长度为一个piece，每个piece都提前计算MD5，然后把这些信息存到 filename.piece 的文件里面。（64来由：因为这段数据要先存到内存等传输完成算MD5，而且同时可以传之多1024个piece，也就是内存里需要占用约 64M空间，主要是为了避免内存占用过高的问题，决定用64这个数值）  (piece_start),(piece_end),(piece_md5)eg. 0,65535,a0ce4f802d03c62c762dbc4d58cecd3665536,131071,b4555bb3dbe47baa2a512da9593652a3\n上面分片完了，发送端在发送数据的时候也按照这个分片规则，每次传输都带上piece的md5和传输的是64个中的哪一个(shot)；接收端收到后就在内存打个piece接收shot的标记，如果这个piece传输完成了，验证一下数据的MD5，通过后写入磁盘，错误的话清掉这个piece，重新请求下载（64KB，影响不大，就全部重新下载吧）\n发送端收到一个请求后，找到对应的文件，验证文件MD5，如果一致，就从请求的piece+shot偏移位置开始以定长的数据长度传输数据，每个数据传输1次，数据没有发送成功需要重新发的话依靠其他消息单独发。\ntorrent 是把文件分成N个没有关系的小块，然后收到那一块填那一块，直到完成\nkcp 的快速重传概念是 发送端发送了1,2,3,4,5几个包，然后收到远端的ACK: 1, 3, 4, 5，当收到ACK3时，KCP知道2被跳过1次，收到ACK4时，知道2被跳过了2次，此时可以认为2号丢失，不用等超时，直接重传2号包，大大改善了丢包时的传输速度。\n在下载器这个功能上看，torrent&#x2F;kcp属于两个极端；既然上面都以piece为单位了，那么这里的处理办法是如果前一个piece没有完成，收到了后一个piece的数据，就把前一个piece缺失的shot重新请求一遍；避免piece一直完不成，也避免带宽占用过满\n\n整体\n附\nzip file infos#!/bin/bashif [ $# != 2 ]; then    echo &quot;Usage: ./format_list.sh pak-file list-file&quot;    exitfi;function zipinfos()&#123;    cnt=1;    pos_s=0;    pos_e=0;    for desc in $(zipinfo -sl &quot;$1&quot; | grep -v &#x27;stor&#x27; | grep &#x27;defN&#x27;); do        unzip_size=`echo $desc | awk -F &#x27; &#x27; &#x27;&#123;print $4&#125;&#x27;`        zip_size=`echo $desc | awk -F &#x27; &#x27; &#x27;&#123;print $6&#125;&#x27;`        filename=`echo $desc | awk -F &#x27; &#x27; &#x27;&#123;print $10&#125;&#x27;`        filename_len=`zipinfo -v &quot;$1&quot; | grep -A 20 &quot;Central directory entry #$cnt:&quot; | grep &#x27;length of filename&#x27; | awk -F &#x27; &#x27; &#x27;&#123;print $4&#125;&#x27;`        extra_len=`zipinfo -v &quot;$1&quot; | grep -A 20 &quot;Central directory entry #$cnt:&quot; | grep &#x27;length of extra field&#x27; | awk -F &#x27; &#x27; &#x27;&#123;print $5&#125;&#x27;`        pos_e=$[$pos_s+zip_size+filename_len+extra_len+30-1]        out=&quot;$pos_s,$pos_e,$zip_size,$unzip_size&quot;        pos_s=$[$pos_e+1]        cnt=$[$cnt+1]        echo $out    done&#125;last_IFS=$IFSIFS=$&#x27;\\n&#x27; zipinfos $1 &gt; format_sub.txtpaste -d, $2 format_sub.txt &gt; format_result.txtIFS=$last_IFS\nfile split &amp; piece md5#!/bin/bashif [ $# != 1 ]; then    echo &quot;Usage: ./sss.sh filename&quot;    exitfi;function sss()&#123;    split -b 64k &quot;$1&quot; -d -a 10 ssssss&#125;function get_md5()&#123;    pos_s=0;    for ffm5 in $(find &quot;$1&quot; -name &#x27;ssssss*&#x27; | sort | xargs md5sum); do        fname=`echo &quot;$ffm5&quot; | awk -F &#x27; &#x27; &#x27;&#123;print $2&#125;&#x27;`        fmd5=`echo $ffm5 | awk -F &#x27; &#x27; &#x27;&#123;print $1&#125;&#x27;`        sz=`ls -l $fname | awk &#x27;&#123;print $5&#125;&#x27;`        pos_e=$[$pos_s+$sz-1]        out=&quot;$pos_s,$pos_e,$fmd5&quot;        pos_s=$[$pos_e+1]        echo $out | sed &quot;s/.\\///g&quot;    done    find &quot;$1&quot; -name &#x27;ssssss*&#x27; -exec rm -f &#123;&#125; \\;&#125;function to_file()&#123;    mkdir -p file_result    for ff in $(find &quot;$1&quot; -type f); do         var=$ff        dir_name=`echo $&#123;var%/*&#125;`        file_name=`echo $&#123;var##*/&#125;`        dir_name=`echo file_result/$dir_name | sed &quot;s/\\.\\.\\///g&quot;`;        # echo $dir_name;        mkdir -p $dir_name        sss $var        get_md5 . &gt; $dir_name/$file_name.piece    done&#125;last_IFS=$IFSIFS=$&#x27;\\n&#x27; to_file $1cd file_resultfor ff in $(find . -type f); do filename=`echo $ff | sed &#x27;s/\\.\\///g&#x27;`; echo &quot;./tool.sh -putfile $filename npl-download-inner -key $filename -replace true&quot;; done &gt; ../upload_doing.shzip -rq file_result.zip file_result/# tar zcf file_result.tar.gz file_resultIFS=$last_IFS\n\n","categories":["网络"],"tags":["网络"]},{"title":"IO模型","url":"/archives/aeafbee0.html","content":"前言\n现在包括C++（asio）已经把网络封装的很简单了，看不到select&#x2F;poll&#x2F;epoll&#x2F;iocp这些就不是很关注了\n其实这些知识还挺重要，至少看那些开源东西介绍的时候了解为什么，或者很多开源选择的时候知道如何选择\n异步IO是指网络IO，关注性能的时候磁盘IO也是经常要留意的点，但是kernel并没有disk IO的解决方案，\n\n关键词\nBIO（block-io）: 同步阻塞IO。send&#x2F;recv阻塞调用，如果开线程while(true)，意味着想要多个session无差别就要开和session 1:1 数量的线程数。基本不会用这种方式\nNIO（non-block-io）: 同步非阻塞IO。相对BIO *N线程的方式，这里用一个线程轮询所有session（fd），判断是否有新的数据，也就是一个没有事件的fd也会被遍历一下，试想如果服务器维护一个很长的队列，这个遍历不仅耗CPU，还容易出现处理不及时。\nIO 多路复用 （系统提供的）\nselect：维护了一个FD_SETSIZE(默认1024)的fds列表，轮询所有fd检查有没有事件，和NIO类似的问题\npoll：相比select没有了FD_SETSIZE的列表长度限制\nepoll：\n\n\n\n参考\nIO-wiki: https://zh.wikipedia.org/wiki/I/O \n\n\n","categories":["知识积累"],"tags":["IO","知识积累"]},{"title":"shell: datetime to","url":"/archives/91542da.html","content":"#!/bin/bashif [ $# != 1 ]; then    echo &quot;Usage: ./date_to.sh [datatime]&quot;    exitfi;datetime_curr=`date &#x27;+%Y-%m-%d %H:%M:%S&#x27;`timestamp_curr=`date +%s`timestamp_to=`date -d &quot;$1&quot; +%s`mongo_ip=&#x27;127.0.0.1&#x27;mongo_port=27000mongo_user=&#x27;test&#x27;mongo_password=&#x27;test&#x27;mongo_dbs=(&#x27;test01&#x27; &#x27;test02&#x27;)redis_cluster_ip=&#x27;127.0.0.1&#x27;redis_cluster_port=6300redis_sentinel_ip=&#x27;127.0.0.1&#x27;redis_sentinel_port=6301echo &quot;!!!!!!! config mongodb: $&#123;mongo_ip&#125;:$&#123;mongo_port&#125; !!!!!!!&quot; for db in $&#123;mongo_dbs[@]&#125;; do    echo &quot;    ####### db: $db #######&quot;doneechoecho &quot;!!!!!!! config redis-cluster: $&#123;redis_cluster_ip&#125;:$&#123;redis_cluster_port&#125; !!!!!!!&quot;echoecho &quot;!!!!!!! config redis-sentinel: $&#123;redis_sentinel_ip&#125;:$&#123;redis_sentinel_port&#125; !!!!!!!&quot;echoechoecho &quot;------- current datetime: $datetime_curr ($timestamp_curr) -------&quot;echo &quot;-------      to datetime: $1 ($timestamp_to) -------&quot;echo# clear database if reset-to older datetimeif [ $timestamp_curr -gt $timestamp_to ]; then    while true; do        read -p &quot;current datetime &gt; reset to, drop database?(y/n)&quot; yn        if echo &quot;$yn&quot; | grep -iq &quot;^y&quot; ; then            echo            echo &#x27;####### mongodb drop start #######&#x27;;            printf &quot;show dbs&quot; | mongo --host $mongo_ip --port $mongo_port --username $mongo_user --password $mongo_password;            for db in $&#123;mongo_dbs[@]&#125;; do                 printf &quot;use $db\\\\n&quot; | mongo --host $mongo_ip --port $mongo_port --username $mongo_user --password $mongo_password;                # printf &quot;use $db\\\\ndb.dropDatabase()&quot; | mongo --host $mongo_ip --port $mongo_port --username $mongo_user --password $mongo_password;            done            echo &#x27;####### mongodb drop end #######&#x27;;            echo            redis_nodes=`redis-cli -h $redis_cluster_ip -p $redis_cluster_port -c cluster nodes | cut -d &#x27; &#x27; -f 2`            for node in $redis_nodes; do                node_redis_ip=`echo &quot;$node&quot; | awk -F &#x27;:&#x27; &#x27;&#123;print $1&#125;&#x27;`                node_redis_port=`echo &quot;$node&quot; | awk -F &#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27;`                echo &quot;------- redis-cluster $&#123;node&#125; $&#123;node_redis_ip&#125; $&#123;node_redis_port&#125; XXX_flushall -------&quot;                # redis-cli -h $node_redis_ip -p $node_redis_port -c flushdb            done            echo            echo &quot;------- redis-sentinel $&#123;redis_sentinel_ip&#125;:$&#123;redis_sentinel_port&#125; XXX_flushall -------&quot;            # redis-cli -h $redis_sentinel_ip -p $redis_sentinel_port -c flushdb            break;        else             break;        fi;    done  # end whilefi;echoecho &#x27;####### datetime reset #######&#x27;;date -s $1echodate &#x27;+%Y-%m-%d %H:%M:%S&#x27;exit","categories":["shell"],"tags":["linux","shell","记录"]},{"title":"旧文章：ENSURE方式的log","url":"/archives/8e2eb46e.html","content":"前述：ENSURE是windows api 里面的函数，assert的一种扩展，没有开放到标准里面，调用的方式是 ENSURE(exp)(msg)(msg)(msg)…;这种写法很不错，我们可以很直观的写需要打印的东西，虽然跟一般C++的语法看起来不协调。\n一般我们习惯使用的记录log的方式是 (“%s : %d”, str, num) printf的组织方式,但是这样经常会遇到的问题是，format部分的代码很容易写错，尤其是 int64 int32这种类型的区分；当然在linux上面其实更习惯用std::cout方式，再做重定向到日志文件中去，避免代码中format的组织。上面代码是参考网上：\n参考了：http://www.cnblogs.com/cbscan/archive/2012/10/26/2740838.html 代码\n去掉了try catch的内容，让ENSURELOG的宏定义只是用来打印日志，外层可以写嵌套assert的内容，或者不同种类log的宏。\n主要解释了宏的展开式，当时看了好一会儿才绕明白，这里记录一下。\n代码：#include &lt;iostream&gt;#include &lt;sstream&gt; //---------------------------------------------//// ENSURE 方式的log//---------------------------------------------//class CEnsureLog&#123;private:    mutable std::string m_osLog;public:    CEnsureLog(const char* func, int line, const char* logType, const char* log)    &#123;        std::ostringstream so;        so &lt;&lt; &quot;[&quot; &lt;&lt; func &lt;&lt; &quot;:&quot; &lt;&lt; line &lt;&lt; &quot;]&quot; &lt;&lt; logType &lt;&lt; log /*&lt;&lt; std::endl*/;        m_osLog = so.str();    &#125;    ~CEnsureLog()    &#123;        if (m_osLog.empty())            return;        std::cout &lt;&lt; m_osLog.c_str() &lt;&lt; std::endl;    &#125;    template&lt;typename T&gt;    CEnsureLog&amp; operator &lt;&lt; (const std::pair&lt;const char*, T&gt; p)    &#123;        std::ostringstream so;        so &lt;&lt; &quot;[&quot; &lt;&lt; p.first &lt;&lt; &quot;=&quot; &lt;&lt; p.second &lt;&lt; &quot;]&quot;;        m_osLog += so.str();        return *this;    &#125;        CEnsureLog&amp; operator &lt;&lt; (int)    &#123;        return *this;    &#125;    const char* write() const    &#123;        return m_osLog.c_str();    &#125;&#125;; static int A = 0, B = 0;#define AB(a, N) std::make_pair(#a, a) &lt;&lt; N#define A(a) AB(a, B)#define B(a) AB(a, A)#define ENSURELOG(b, logType) if (b); else CEnsureLog(__FUNCTION__, __LINE__, logType, #b) &lt;&lt; A /* 宏解释： 例如： ENSURELOG(false, &quot;Info&quot;)(&quot;abc&quot;)(5); 展开式： CEnsureLog 对象 &lt;&lt; AB(&quot;abc&quot;, B)(5);                &lt;&lt; std::make_pair(&quot;abc&quot;, &quot;abc&quot;) &lt;&lt; B(5)                                                &lt;&lt; AB(5, A)                                                &lt;&lt; std::make_pair(5, 5) &lt;&lt; A 后面没有了，所以A取的是 static int A = 0;  0, 调用 operator &lt;&lt; (int) */int main()&#123;    std::string str = &quot;str&quot;;    int num = 11;    ENSURELOG(false, &quot;[info]&quot;)(&quot;abc&quot;)(5)(str)(num);        return 0;&#125;","categories":["知识积累"],"tags":["记录"]},{"title":"shell mongodb sharding index initialize","url":"/archives/ce97278a.html","content":"常用脚本备忘：mongodb initialize sharding &amp; index\n#!/bin/bashif [ $# &lt; 4 ]; then  echo &quot; Usage: ./shell.sh [mongos_ip] [mongos_port] [username] [password] [drop?]&quot;  exitfi;databases=(  &quot;player&quot;)# enablesharding|collection|elementshardings=(  &quot;player|player|id&quot;)# database|collection|indexEle|indexType|uniqueindexs=(  &quot;player|player|id|1|true&quot;)mongos_ip=$1mongos_port=$2mongos_username=$3mongos_password=$4mongos_drop=1if [ $# == 5 ]; then  mongos_drop=$5fi;echo &quot;initialize mongodb&#x27;s database &amp; collection&quot;echo echo &quot;mongos ip:       $&#123;mongos_ip&#125;&quot;echo &quot;mongos port:     $&#123;mongos_port&#125;&quot;echo &quot;mongos username: $&#123;mongos_username&#125;&quot;echo for database in $&#123;databases[@]&#125;; do  if [ $mongos_drop == 1 ]; then    read -p &quot;!!!! mongodb&#x27;s database **** $&#123;database&#125; **** will drop !!!!(y/n)  &quot; drop_yn    if echo &quot;$drop_yn&quot; | grep -iq &quot;^y&quot; ; then      echo &quot;####### drop #######&quot;      mongo --host $mongos_ip --port $mongos_port --username $mongos_username --password $mongos_password --authenticationDatabase admin --quiet &lt;&lt; EOF           use $database;          db.dropDatabase();EOF    fi;  fi;donewhile true; do  read -p &quot;!!!! confirm mongodb not initialize before !!!!(y/n)  &quot; confirm_yn  if echo &quot;$confirm_yn&quot; | grep -iq &quot;^y&quot; ; then    echo     for item in $&#123;shardings[@]&#125;; do      database=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $1&#125;&#x27;`      collection=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $2&#125;&#x27;`      element=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $3&#125;&#x27;`      # printf &quot;show dbs&quot; | mongo --host $mongos_ip --port $mongos_port --username $mongos_username --password $mongos_password --authenticationDatabase admin;      echo       echo &quot;####### sharding #######&quot;      mongo --host $mongos_ip --port $mongos_port --username $mongos_username --password $mongos_password --authenticationDatabase admin --quiet &lt;&lt; EOF        use admin;        sh.enableSharding(&quot;$database&quot;);        use $database;        sh.shardCollection(&quot;$database.$collection&quot;, &#123;&quot;$element&quot;: &quot;hashed&quot;&#125;);EOF      # printf &quot;use admin\\\\nsh.enableSharding(\\&quot;$database\\&quot;)\\\\nuse $database\\\\nsh.shardCollection(\\&quot;$database.$collection\\&quot;, &#123;\\&quot;$element\\&quot;: \\&quot;hashed\\&quot;&#125;)&quot; | mongo --host $mongos_ip --port $mongos_port --username $mongos_username --password $mongos_password --authenticationDatabase admin;      echo     done    echo &quot;####### index #######&quot;    for item in $&#123;indexs[@]&#125;; do      database=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $1&#125;&#x27;`      collection=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $2&#125;&#x27;`      element=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $3&#125;&#x27;`      index=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $4&#125;&#x27;`      uniq=`echo &quot;$item&quot; | awk -F &#x27;|&#x27; &#x27;&#123;print $5&#125;&#x27;`      # printf &quot;show dbs&quot; | mongo --host $mongos_ip --port $mongos_port --username $mongos_username --password $mongos_password --authenticationDatabase admin;      echo       mongo --host $mongos_ip --port $mongos_port --username $mongos_username --password $mongos_password --authenticationDatabase admin --quiet &lt;&lt; EOF        use $database;        db.$collection.createIndex(&#123;$element: $index&#125;,&#123;unique:$uniq, background: true&#125;);EOF      # printf &quot;use $database\\\\ndb.$collection.createIndex(&#123;$element: $index&#125;)&quot; | mongo --host $mongos_ip --port $mongos_port --username $mongos_username --password $mongos_password --authenticationDatabase admin;      echo     done    echo   fi;  exitdone ","categories":["shell"],"tags":["linux","shell","记录"]},{"title":"git 常用备忘","url":"/archives/f47476fc.html","content":"初始化\n设置仓库名字&amp;邮箱 (–global选项表示全局)git config --global user.name xxgit config --global user.email xx@gmail.com\n配置相关[user]        name = xx        email = xx[credential]        helper = manager-core[alias]        lg = log --color --graph --pretty=format:&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#x27; --abbrev-commit[pager]        branch = false[core]        pager =        quotepath = false[color]        ui = auto        pager = false[gui]        encoding = utf-8[i18n]        commitencoding = utf-8        logoutputencoding = utf-8\n\n版本控制本地仓库控制git init - 为目录添加本地 .git 管理git add readme.txt - 添加 readme.txt 到暂存区git add *.txt - 添加 *.txt 到暂存区git add . - 添加包含子目录的所有到暂存区git commit -a -m &quot;test all commit&quot; - 提交所有暂存区修改git commit -m &#39;test one commit&#39; readme.txt - 单个提交git commit -C HEAD -a --amend - 追加提交git status - 查看仓库当前状态git checkout head xx.txt - 撤销还没有到暂存区的修改git reset head &lt;filename&gt; - 撤销已经到暂存区的修改git reset --hard HEAD^ - 回退版本git reset --hard 1094a - 回退到指定版本\n远端仓库控制git push origin --delete test - 删除origin远端test分支\n","categories":["git"],"tags":["记录","git"]},{"title":"模块：时间轮定时器","url":"/archives/de38e5db.html","content":"代码https://github.com/kinly/timer_wheel\n基础数据结构uint64_t       _index;           // guid（时间戳）event_type     _type;            // 业务：事件类型uint32_t       _repeat;          // 业务：重复次数timer_callback _caller;          // 回调: std::function\n\n时间轮数据结构union timer_clock&#123;    time64_t time;    struct    &#123;        uint32_t m5 : 10;     // 分桶：5        uint32_t m4 : 8;      // 分桶：4        uint32_t m3 : 6;      // 分桶：3        uint32_t m2 : 6;      // 分桶：2        uint32_t m1 : 6;      // 分桶：1        uint32_t m0 : 6;      // 分桶：0    &#125;;&#125;;\n\n\n\n\n桶名\n最大容纳\n桶起始位置\n\n\n\nm5\n1024\n0x000\n\n\nm4\n256\n0x400\n\n\nm3\n64\n0x500\n\n\nm2\n64\n0x540\n\n\nm1\n64\n0x580\n\n\nm0\n64\n0x5C0\n\n\n自内向外依次是m5、m4、m3、m2、m1、m0认为m5是最小的桶，m0是最大的桶\nmanagerstd::vector&lt;std::list&lt;time64_t&gt; &gt; _wheelVec;               // 管理每一层，容器可以再考量下std::unordered_map&lt;time64_t, timer_event&gt; _timeSeq2Evt;    // 管理触发时候的callbacktime64_t _timeSeconds;                                     // 时间轮精度下的当前时间戳\n\noperator当前有两个时间戳，一个是数据成员 _timeSeconds，另一个是insert的事件下次要触发的时间戳 deadline，将这两个时间转化为timer_clock类型，确定事件在时间轮里面的位置\nif( t1.m0 != t2.m0 )&#123;    _wheelVec[0x5c0 + t1.m0].push_back(_handle);&#125;else if( t1.m1 != t2.m1 )&#123;    _wheelVec[0x580 + t1.m1].push_back(_handle);&#125;else if( t1.m2 != t2.m2 )&#123;    _wheelVec[0x540 + t1.m2].push_back(_handle);&#125;else if( t1.m3 != t2.m3 )&#123;    _wheelVec[0x500 + t1.m3].push_back(_handle);&#125;else if( t1.m4 != t2.m4 )&#123;    _wheelVec[0x400 + t1.m4].push_back(_handle);&#125;else&#123;    _wheelVec[t1.m5].push_back(_handle);&#125;\n_handle是一个唯一索引，也就是 _timeSeq2Evt 的 key接下来是执行：\ntimer_clock now; // ... 赋值当前时间戳（以时间轮的精度)while( _timeSeconds &lt;= now.time )&#123;\ttimer_clock ts = &#123; tickcount_ &#125;;\tif( ts.m5 )\t&#123;\t\t_clock_step_list( time_wheel_[ts.m5] );\t&#125;\telse if( ts.m4 )\t&#123;\t\t_clock_step_list( _wheelVec[ts.m4 + 0x400] );\t&#125;\telse if( ts.m3 )\t&#123;\t\t_clock_step_list( _wheelVec[ts.m3 + 0x500] );\t&#125;\telse if( ts.m2 )\t&#123;\t\t_clock_step_list( _wheelVec[ts.m2 + 0x540] );\t&#125;\telse if( ts.m1 )\t&#123;\t\t_clock_step_list( _wheelVec[ts.m1 + 0x580] );\t&#125;\telse if( ts.m0 )\t&#123;\t\t_clock_step_list( _wheelVec[ts.m0 + 0x5c0] );\t&#125;\t_timeSeconds += 1;&#125;return true;\n_clock_step_list的入参是一个list的引用（后面需要clear这个list），这个函数需要做的就是检查时间，如果时间 &lt;&#x3D; _timeSeconds 就调用 _caller 执行，否则，重新insert_clock（这个操作其实就是把外层的事件move到内层去），遍历完整个list，做一个clear\n其他存在的问题是如果测试期间修改服务器时间，定时器会循环很多次处理事件，可能引起网络的超时断链，cpu跑满等问题，可以考虑增加一个判断，如果循环超过2000次break一次，其他的等下次主循环跑到了再执行。\n2023.更新\n实际实现的定时器性能还可以，20W数据 + 10ms period + 单线程，误差基本在3ms以内 （因为是单线程的关系，测试的回调只是算了下和应当触发时间的误差）\n为了简化活动一般配置成绝对时间开启、周期开启的情况，引入 https://github.com/mariusbancila/croncpp，抽象 event_interface，对间隔时间方式、计划任务方式兼容\n这里有点遗留问题：因为分桶量级的关系，这里认为最小时间单位是毫秒（ms），计划任务里就有一段硬编码的时间转换，虽然是满足绝大多数游戏开发的需要，但是对于延迟要求特别严格的场景也是一种限制\n解决办法是写个明确的 seconds 换算 tick 的函数\n另外：这个模块里 std::string 相关的位置可以换成 std::string_view，都是只读的场景struct event_interface &#123;\ttimer_handle _handle = handle_gen::invalid_handle;  // 句柄\ttime64_t _next = 0;                                 // 下次执行时间\ttime64_t _period = 0;                               // 间隔时间\tuint64_t _round = 1;                                // 执行轮次（剩余）\ttimer_callback _callback = nullptr;                 // 回调\ttimer_stopped_callback _stopped_callback = nullptr; // 停止回调\tstd::string _remark&#123; &#125;;                             // debug remark\texplicit event_interface(time64_t nxt, time64_t period, uint64_t round, timer_callback&amp;&amp; cb, timer_stopped_callback&amp;&amp; stopped_cb)\t\t: _next(nxt)\t\t, _period(period)\t\t, _round(round)\t\t, _callback(std::forward&lt;timer_callback&gt;(cb))\t\t, _stopped_callback(std::forward&lt;timer_stopped_callback&gt;(stopped_cb)) &#123;\t\t_handle = handle_gen::instance().get();\t\tif (_period == 0)\t\t\t_round = 1;\t&#125;\tvirtual ~event_interface() &#123;\t\tif (_handle == handle_gen::invalid_handle)\t\t\treturn;\t\thandle_gen::instance().put(_handle);\t&#125;\tvirtual time64_t next() = 0;                         // next trigger time&#125;;template&lt;uint64_t precision_tt = 10&gt;struct event_custom : public event_interface &#123;\tstatic constexpr time64_t _precision = precision_tt;\texplicit event_custom(time64_t nxt, time64_t period, uint64_t round, timer_callback&amp;&amp; cb, timer_stopped_callback&amp;&amp; stopped_cb)\t\t: event_interface(nxt, period, round, std::forward&lt;timer_callback&gt;(cb), std::forward&lt;timer_stopped_callback&gt;(stopped_cb)) &#123;\t&#125;\t~event_custom() &#123;\t&#125;\tvirtual time64_t next() &#123;\t\tevent_interface::_next = (tick() + _period) / _precision;\t\treturn _next;\t&#125;\tstatic std::shared_ptr&lt;event_interface&gt; create(time64_t nxt, time64_t period, uint64_t round, timer_callback&amp;&amp; cb, timer_stopped_callback&amp;&amp; stopped_cb) &#123;\t\tstd::shared_ptr&lt;event_custom&gt; result = std::make_shared&lt;event_custom&gt;(nxt, period, round,\t\t\tstd::forward&lt;timer_callback&gt;(cb), std::forward&lt;timer_stopped_callback&gt;(stopped_cb));\t\treturn result;\t&#125;&#125;;template&lt;uint64_t precision_tt = 10&gt;struct event_crontab : public event_interface &#123;\tstatic constexpr time64_t _precision = precision_tt;\tcron::cronexpr _cronexpr;    // cronexpr\texplicit event_crontab(timer_callback&amp;&amp; cb, timer_stopped_callback&amp;&amp; stopped_cb)\t\t: event_interface(tick() / _precision, -1, -1, std::forward&lt;timer_callback&gt;(cb), std::forward&lt;timer_stopped_callback&gt;(stopped_cb)) &#123;\t&#125;\t~event_crontab() &#123;\t&#125;\tvirtual time64_t next() &#123;\t\tauto last = event_interface::_next * _precision / 1000;\t\tevent_interface::_next = cron::cron_next(_cronexpr, last) * 1000 / _precision;\t\treturn event_interface::_next;\t&#125;\tstatic std::shared_ptr&lt;event_interface&gt; create(const std::string&amp; cron_str, timer_callback&amp;&amp; cb, timer_stopped_callback&amp;&amp; stopped_cb) &#123;\t\ttry &#123;\t\t\tstd::shared_ptr&lt;event_crontab&gt; result = std::make_shared&lt;event_crontab&gt;(std::forward&lt;timer_callback&gt;(cb), std::forward&lt;timer_stopped_callback&gt;(stopped_cb));\t\t\tresult-&gt;_cronexpr = cron::make_cron(cron_str);\t\t\tresult-&gt;next();\t\t\treturn result;\t\t&#125; catch (cron::bad_cronexpr const&amp; ex) &#123;\t\t\t// todo: log\t\t\treturn nullptr;\t\t&#125;\t&#125;\tstatic std::shared_ptr&lt;event_interface&gt; create(std::string&amp;&amp; cron_str, timer_callback&amp;&amp; cb, timer_stopped_callback&amp;&amp; stopped_cb) &#123;\t\ttry &#123;\t\t\tstd::shared_ptr&lt;event_crontab&gt; result = std::make_shared&lt;event_crontab&gt;(std::forward&lt;timer_callback&gt;(cb), std::forward&lt;timer_stopped_callback&gt;(stopped_cb));\t\t\tresult-&gt;_cronexpr = cron::make_cron(cron_str);\t\t\tresult-&gt;next();\t\t\treturn result;\t\t&#125; catch (cron::bad_cronexpr const&amp; ex) &#123;\t\t\t// todo: log\t\t\treturn nullptr;\t\t&#125;\t&#125;&#125;;\n\n","categories":["模块"],"tags":["C++"]},{"title":"记录：简易CD-Key算法","url":"/archives/1206f424.html","content":"说明工作业务需求，生成一批随机的CD-Key，要求如下\n\n随机长度10-15字符（大写英文字母+数字）\n带一个自定义前缀用来区分 CD-Key 的批次\n一个批次内不重复\n一个批次的生成以万为数量级\n\n其实是个很简单uuid就好，用语言的set/hashset特性去重，实际写的时候用了觉得会更快的方式\n实现基于洗牌算法\n因为考虑一些字符：1,L,0,O 显示区分上有点烦就考虑去掉这些字符（虽然没有这个需求，后面策划觉得一般都是复制粘贴使用的，这个需求也不重要）\n这样相当于在一些字符里面随机source_list = [&#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;,                &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;, &#x27;H&#x27;,                &#x27;J&#x27;, &#x27;K&#x27;, &#x27;L&#x27;, &#x27;M&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Q&#x27;, &#x27;R&#x27;,                &#x27;S&#x27;, &#x27;T&#x27;, &#x27;U&#x27;, &#x27;V&#x27;, &#x27;W&#x27;, &#x27;X&#x27;, &#x27;Y&#x27;, &#x27;Z&#x27;]\n然后第一个想到的就是洗牌了\n具体实现：比如要生成10长度的串，极端情况这个串里都是相同的字符，也就是初始随机库里每个字符先重复10次，得到新的source_listrand_list = []for src in source_list:    for n in range(length):        rand_list.append(src)\n洗牌一次就可以按照实际长度取出结果了\n洗牌一次可以取出的结果个数: len(source_list)\n这里没有把 source_list 当成一个环队列处理，当成环的话理论上可以取出更多个结果\n当然，这里的结果还是要依赖set&#x2F;hashset来去除重复的\n\n\npython 代码def __gen_alg(self, prefix, length, count):    self._message = &quot;&quot;    if length &lt;= 0 or count &lt;= 0:        self._message = &quot;!!!! [length] and [count] must &gt; 0 !!!!&quot;        return    self._random_set.clear()    self._random_prefix = prefix    source_list = [&#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;,                    &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;, &#x27;H&#x27;,                    &#x27;J&#x27;, &#x27;K&#x27;, &#x27;L&#x27;, &#x27;M&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Q&#x27;, &#x27;R&#x27;,                    &#x27;S&#x27;, &#x27;T&#x27;, &#x27;U&#x27;, &#x27;V&#x27;, &#x27;W&#x27;, &#x27;X&#x27;, &#x27;Y&#x27;, &#x27;Z&#x27;]    merge_len = length    rand_list = []    for src in source_list:        for n in range(merge_len):            rand_list.append(src)    total_len = len(rand_list)    while len(self._random_set) &lt; count:        random.shuffle(rand_list)        index = 0        while index + merge_len &lt; total_len:            result_str = &#x27;&#x27;.join(rand_list[index:merge_len + index])            index += 1            self._random_set.add(prefix + &#x27;-&#x27; + result_str)    while len(self._random_set) &gt; count:        self._random_set.pop()\n实际测下来，30W结果大概需要300ms，达到工具的使用\n\n基于Hash\n英文字符+数字的组合，这符合大部分Hash算法的特征\n直接拷贝库里面hash算法来处理\n局限性是长度最大值，当然也可以用其他办法处理掉\ncpp 代码#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;set&gt;#include &lt;algorithm&gt;#include &lt;thread&gt;#include &lt;time.h&gt;#include &lt;chrono&gt;using namespace std::chrono_literals;std::vector&lt;char&gt; shows;std::vector&lt;std::vector&lt;std::string&gt;&gt; res;static std::string hash(const std::string&amp; key) &#123;    thread_local std::string ret;    ret.clear();    constexpr static uint64_t _FNV_offset_basis = 14695981039346656037ULL;    constexpr static uint64_t _FNV_prime = 1099511628211ULL;    uint64_t _Vals[3] = &#123; _FNV_offset_basis , _FNV_offset_basis , _FNV_offset_basis &#125;;    for (auto iter = key.begin(); iter != key.end();)    &#123;        auto index = rand() % 3;        _Vals[index] ^= static_cast&lt;uint64_t&gt;(*iter);        _Vals[index] *= _FNV_prime;        iter++;    &#125;    static auto show_size = shows.size();    ret.append(1, shows[(_Vals[0] &amp; 0x3FF) % show_size]);    ret.append(1, shows[((_Vals[0] &amp; (0x3FFull &lt;&lt; 10)) &gt;&gt; 10) % show_size]);    ret.append(1, shows[((_Vals[0] &amp; (0x3FFull &lt;&lt; 20)) &gt;&gt; 20) % show_size]);    ret.append(1, shows[((_Vals[0] &amp; (0x3FFull &lt;&lt; 30)) &gt;&gt; 30) % show_size]);    ret.append(1, shows[((_Vals[0] &amp; (0x3FFull &lt;&lt; 40)) &gt;&gt; 40) % show_size]);    ret.append(1, shows[((_Vals[0] &amp; (0x3FFull &lt;&lt; 50)) &gt;&gt; 50) % show_size]);    ret.append(1, shows[(((_Vals[0] &amp; (0xFull &lt;&lt; 60)) &gt;&gt; 60) | (_Vals[1] &amp; 0x3F)) % show_size]);    ret.append(1, shows[((_Vals[1] &amp; (0x3FFull &lt;&lt; 6)) &gt;&gt; 6) % show_size]);    ret.append(1, shows[((_Vals[1] &amp; (0x3FFull &lt;&lt; 16)) &gt;&gt; 16) % show_size]);    ret.append(1, shows[((_Vals[1] &amp; (0x3FFull &lt;&lt; 26)) &gt;&gt; 26) % show_size]);    ret.append(1, shows[((_Vals[1] &amp; (0x3FFull &lt;&lt; 36)) &gt;&gt; 36) % show_size]);    ret.append(1, shows[((_Vals[1] &amp; (0x3FFull &lt;&lt; 46)) &gt;&gt; 46) % show_size]);    ret.append(1, shows[(((_Vals[1] &amp; (0xFFull &lt;&lt; 56)) &gt;&gt; 56) | (_Vals[2] &amp; 0x3)) % show_size]);    ret.append(1, shows[((_Vals[2] &amp; (0x3FFull &lt;&lt; 2)) &gt;&gt; 2) % show_size]);    ret.append(1, shows[((_Vals[2] &amp; (0x3FFull &lt;&lt; 12)) &gt;&gt; 12) % show_size]);    ret.append(1, shows[((_Vals[2] &amp; (0x3FFull &lt;&lt; 22)) &gt;&gt; 22) % show_size]);    ret.append(1, shows[((_Vals[2] &amp; (0x3FFull &lt;&lt; 32)) &gt;&gt; 32) % show_size]);    ret.append(1, shows[((_Vals[2] &amp; (0x3FFull &lt;&lt; 42)) &gt;&gt; 42) % show_size]);    ret.append(1, shows[((_Vals[2] &amp; (0x3FFull &lt;&lt; 52)) &gt;&gt; 52) % show_size]);    ret.append(1, shows[((_Vals[2] &amp; (0x3FFull &lt;&lt; 54)) &gt;&gt; 54) % show_size]); // 不足10bit,特殊处理下    return ret;&#125;int main() &#123;    for (char i = &#x27;A&#x27;; i &lt;= &#x27;Z&#x27;; ++i)    &#123;        shows.emplace_back(i);    &#125;    for (char i = &#x27;2&#x27;; i &lt;= &#x27;9&#x27;; ++i)    &#123;        shows.emplace_back(i);    &#125;    auto iter = std::remove_if(shows.begin(), shows.end(), [](char ch) &#123;        return ch == &#x27;i&#x27;            || ch == &#x27;l&#x27;            || ch == &#x27;I&#x27;            || ch == &#x27;o&#x27;            || ch == &#x27;O&#x27;            || ch == &#x27;0&#x27;;    &#125;);    shows.erase(iter, shows.end());    auto t0 = time(0);    srand(t0);    auto before = std::chrono::system_clock::now();    uint64_t thread_count = 10;    uint64_t count_per_thread = 30000;    std::vector&lt;std::thread&gt; threads;    res.resize(thread_count);    for (uint64_t i = 0; i &lt; thread_count; ++i)    &#123;        threads.emplace_back([i, count_per_thread]() &#123;            for (int k = count_per_thread * i; k &lt; count_per_thread *(i + 1); ++k)            &#123;                res[i].emplace_back(hash(std::to_string(k)));            &#125;        &#125;);    &#125;    for (auto&amp;&amp; t : threads)    &#123;        t.join();    &#125;    auto after = std::chrono::system_clock::now();    std::cout &lt;&lt; &quot;total: &quot; &lt;&lt; count_per_thread * thread_count &lt;&lt; &quot; got: &quot; &lt;&lt; res.size() * count_per_thread &lt;&lt; &quot; cost: &quot; &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(after - before).count() &lt;&lt; &quot;ms&quot;;    return 0;&#125;\n\nend\n最后还是选择了理解上更简单的洗牌方式\n结果组织上写入数据库的SQL语句\n操作上用dearPyGui\n虽然是基于imgui，但是C++里面是循环进入函数刷新的，而这个是类似把控件推入栈的方式，也许还有其他方式暂时没有太多研究\n\n\n完整代码import randomimport dearpygui.core as coreimport dearpygui.simple as simpleclass CDKeyApp:    window_name = &quot;CD-Key Generate: &quot;    cdKey_prefix_src = &quot;cdKey-prefix&quot;    cdKey_length_src = &quot;cdKey-length&quot;    cdKey_count_src = &quot;cdKey-count&quot;    cdKey_length_combo = [&#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;10&#x27;, &#x27;11&#x27;, &#x27;12&#x27;]    _random_set = set()    _random_prefix = &quot;&quot;    _message = &quot;&quot;    copy_cdKeys = &quot;&quot;    copy_cdKeys_mongo = &quot;&quot;    def __init__(self):        core.add_additional_font(&#x27;C:\\\\Windows\\\\Fonts\\\\simyou.ttf&#x27;, 13, glyph_ranges = &#x27;chinese_full&#x27;)        return    def __gen_txt(self):        self.copy_cdKeys = &quot;&quot;        self.copy_cdKeys_mongo = &quot;&quot;        self.copy_cdKeys_mongo += &#x27;try &#123;\\n&#x27;        self.copy_cdKeys_mongo += &#x27;db.DiceCDKey.insertMany([\\n&#x27;        for one in self._random_set:            self.copy_cdKeys += one + &#x27;\\n&#x27;            self.copy_cdKeys_mongo += &#x27;&#123;_id:&quot;&#x27; + one + &#x27;&quot;, keys:&quot;&#x27; + self._random_prefix + &#x27;&quot;&#125;,\\n&#x27;        self.copy_cdKeys_mongo += &#x27;]);&#125; catch(e) &#123; print(e); &#125;&#x27;    def __gen_alg(self, prefix, length, count):        self._message = &quot;&quot;        if length &lt;= 0 or count &lt;= 0:            self._message = &quot;!!!! [length] and [count] must &gt; 0 !!!!&quot;            return        self._random_set.clear()        self._random_prefix = prefix        source_list = [&#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;,                       &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;, &#x27;H&#x27;, &#x27;J&#x27;, &#x27;K&#x27;, &#x27;L&#x27;, &#x27;M&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Q&#x27;, &#x27;R&#x27;, &#x27;S&#x27;, &#x27;T&#x27;, &#x27;U&#x27;,                       &#x27;V&#x27;, &#x27;W&#x27;, &#x27;X&#x27;, &#x27;Y&#x27;, &#x27;Z&#x27;]        merge_len = length        rand_list = []        for src in source_list:            for n in range(merge_len):                rand_list.append(src)        total_len = len(rand_list)        while len(self._random_set) &lt; count:            random.shuffle(rand_list)            index = 0            while index + merge_len &lt; total_len:                result_str = &#x27;&#x27;.join(rand_list[index:merge_len + index])                index += 1                self._random_set.add(prefix + &#x27;-&#x27; + result_str)        while len(self._random_set) &gt; count:            self._random_set.pop()    def __gen(self):        prefix = core.get_value(self.cdKey_prefix_src)        length = int(&#x27;0&#x27;+core.get_value(self.cdKey_length_src))        count = int(&#x27;0&#x27;+core.get_value(self.cdKey_count_src))        self.__gen_alg(prefix, length, count)        self.__gen_txt()        static_item_1 = &quot;static_item_1&quot;        static_item_2 = &quot;static_item_2&quot;        static_item_3 = &quot;static_item_3&quot;        static_item_4 = &quot;static_item_4&quot;        if core.does_item_exist(&quot;##&quot;+static_item_1):            core.delete_item(&quot;##&quot;+static_item_1)            core.delete_item(&quot;##&quot;+static_item_2)            core.delete_item(&quot;##&quot;+static_item_3)            core.delete_item(&quot;##&quot;+static_item_4)        core.add_spacing(name=&quot;##&quot;+static_item_1, count=2, parent=self.window_name)        core.add_input_text(name=&quot;##&quot;+static_item_2, parent=self.window_name,                            default_value=self.copy_cdKeys,                            multiline=True, readonly=True, width=200, height=250)        core.add_same_line(name=&quot;##&quot;+static_item_3, spacing=20, parent=self.window_name)        core.add_input_text(name=&quot;##&quot;+static_item_4, parent=self.window_name,                            default_value=self.copy_cdKeys_mongo,                            multiline=True, readonly=True, width=300, height=250)        if len(self._message) &gt; 0:            core.add_separator(parent=self.window_name)            core.add_text(&quot;ERROR: &quot; + self._message, parent=self.window_name, color=[255, 0, 0])            core.add_separator(parent=self.window_name)    def show(self):        with simple.window(self.window_name):            core.set_main_window_size(550, 550)            core.set_main_window_resizable(False)            core.set_main_window_title(self.window_name)            core.add_spacing()            core.add_separator()            core.add_text(&quot;CD-Key Generate&quot;)            core.add_text(&quot;生成随机兑换码对应的 key 文本&quot;, bullet=True, color=[255, 0, 0])            core.add_text(&quot;生成随机兑换码对应的 mongoDB insert 代码&quot;, bullet=True)            core.add_text(&quot;mongoDB 代码记得提交给运维执行导入到数据库&quot;, bullet=True, color=[255, 0, 0])            core.add_spacing()            core.add_separator()            core.add_spacing(count=8)            core.add_input_text(name=&quot;Prefix&quot;, source=self.cdKey_prefix_src, width=100, hexadecimal=True)            core.add_same_line(spacing=20)            core.add_combo(&quot;Length&quot;, items=self.cdKey_length_combo, source=self.cdKey_length_src, default_value=&#x27;10&#x27;, width=80)            core.add_same_line(spacing=20)            core.add_input_text(name=&quot;Count&quot;, source=self.cdKey_count_src, default_value=&#x27;10&#x27;, width=100, decimal=True)            core.add_spacing(count=2)            core.add_button(&quot;Gen&quot;, callback=self.__gen, width=500)            core.add_spacing(count=2)            core.add_separator()            # self.__render()            # core.set_render_callback(self.render)        core.start_dearpygui(primary_window=self.window_name)if __name__ == &#x27;__main__&#x27;:    cdkeyApp = CDKeyApp()    cdkeyApp.show()\n\n","categories":["知识备忘"],"tags":["常用备忘","算法"]},{"title":"游戏：AI相关","url":"/archives/ae479ce2.html","content":"Pre计划开一个游戏分组，记录学习下游戏内常用模块的知识\n前言绝大部分的游戏都需要AI的支持，手机游戏操作越来越简化的现在，AI更是变成了很重要的一个部分。比较有代表性的就是RPG类游戏里面的怪物&#x2F;NPC&#x2F;技能（后面的大部分内容都以这个为目标）\n","categories":["游戏"],"tags":["游戏","AI"]},{"title":"优化：Tips for Optimizing C/C++ Code","url":"/archives/7a4ba13d.html","content":"前言读到一篇不长但是很有指导性，也很实用的优化相关的文章，虽然标题带C&#x2F;C++，内容基本是以游戏客户端举例，不过里面很多内容都是大部分语言通用的语法，可以通用在任何语言\n为了更好的记录，自己翻译一下 (: 还好文章不长，还好有翻译app\n原文chrome-extension:&#x2F;&#x2F;ikhdkkncnoglghljlkmcimlnlhkeamad&#x2F;pdf-viewer&#x2F;web&#x2F;viewer.html?file&#x3D;https%3A%2F%2Fpeople.cs.clemson.edu%2F~dhouse%2Fcourses%2F405%2Fpapers%2Foptimize.pdf\n翻译&#x2F;记录记住阿姆达尔（Ahmdal）定律:$$Speedup &#x3D; \\frac {time_{old}}{time_{new}} &#x3D; \\frac{1}{(1 - func_{cost}) + func_{cost} &#x2F; func_{speedup}} $$\n\n其中 $func_{cost}$ 是指函数 $func$ 运行时间的百分比，$func_{speedup}$ 是加速函数的因子\n因此，如果优化占运行时间40%的函数 TriangleIntersect()， 使其运行速度提高两倍，那么你的程序运行速度将提高 25%($\\frac{1}{(1 - 0.4) + 0.4 &#x2F; 2} &#x3D; \\frac{1}{0.8} &#x3D; 1.25$)\n这意味着不经常使用的代码（例如，场景加载器）可能应该很少被优化（如果有的话）\n这通常被表述为：让常见的情况快速，让罕见的情况正确\n\n先编写代码以获得正确性，然后再优化！\n这并不意味着编写功能齐全的光线追踪器 8 周，然后再优化 8 周！\n分多个步骤对光线追踪器执行优化\n编写正确性，然后如果您知道函数将被频繁调用，执行明显的优化\n然后分析以发现瓶颈，并消除瓶颈（通过优化或改进算法）\n通常改进算法会极大地改变瓶颈——也许是你意想不到的功能。这是对您知道会经常使用的所有函数进行明显优化的一个很好的理由\n\n我认识的那些编写非常高效的代码的人说，他们优化代码的时间至少是编写代码的两倍Jumps(跳转)&#x2F;branches(分支) 很贵. 尽可能减少它们的使用\n函数调用需要两次跳转，除了堆栈内存操作\n优先使用迭代而不是递归\n对短函数使用内联函数以消除函数开销\n在函数调用中移动循环例如: for(i = 0; i &lt; 100; ++i)     DoSomething();\n修改为DoSomething() &#123;    for(i = 0; i &lt; 100; ++i) &#123;...&#125; &#125;\n很长的 if...else if...else if... else if... 对于链结尾附近的情况，需要跳转很多次（除非需要测试每个条件）。如果可能，请转换为 switch 语句，编译器有时会将其优化为单次跳转的表查找。如果不可能有 switch 语句，请将最常用的子句放在 if 链的开头\n\n关注数组索引的顺序\n二维和更高维的数组仍然存储在一维内存中。这意味着（对于 C&#x2F;C++ 数组）array[i][j] 和 array[i][j+1] 彼此相邻，而array[i][j]和array[i+1][j] 可能距离任意远\n以或多或少的顺序方式访问存储在物理内存中的数据，可以显着加速您的代码（有时是一个数量级或更多）！\n当现代 CPU 将数据从主内存加载到处理器时缓存，它们获取的不仅仅是单个值。相反，它们获取包含请求数据和相邻数据（acacheline）的内存块。这意味着array[i][j]在CPU缓存中之后，array[i][j+1]很有可能已经在缓存中，而array[i+1][j]很可能还在主存中\n\n关注指令级并行运算\n尽管许多应用程序仍然依赖单线程执行，但现代 CPU 已经在单核内具有大量并行性。这意味着单个 CPU 可能同时执行 4 次浮点乘法，等待 4 次内存请求，并为即将到来的分支执行比较\n为了充分利用这种并行性，代码块（即跳转之间）需要有足够的并行指令以允许充分利用 CPU\n考虑展开循环以改善这一点\n这也是使用内联函数的一个很好的理由\n\n避免&#x2F;减少局部变量的数量\n局部变量通常存储在堆栈中。 但是如果数量足够少，它们也可以被存放在寄存器中。在这种情况下，函数不仅可以获得存储在寄存器中的数据的快速内存访问的好处，而且函数还避免了设置堆栈框架的开销\n（但是，不要完全切换到全局变量！）\n\n减少函数参数的数量\n与减少局部变量的原因相同–它们也被存储在堆栈中\n\n通过引用传递struct(结构)，而不是通过值\n据我所知，在光线追踪器中，没有任何情况下结构应该通过值来传递（即使是像矢量、点和颜色这样的简单结构）\n\n如果你不需要一个函数的返回值，就不要定义一个尽量避免casting（强制类型转换）\n整数和浮点指令通常在不同的寄存器上运行，因此强制转换需要复制\n较短的整数类型（char 和 short）仍然需要使用全尺寸寄存器，并且需要将它们填充到 32&#x2F;64 位然后在存储回内存之前转换回较小的大小（但是，此成本必须与较大数据类型的额外内存成本进行权衡）\n\n声明 C++ 对象变量时要非常小心\n使用初始化而不是赋值  Color c(black);\n比下面这种形式快的多Color c; c = black;\n\n让默认的类构造函数尽可能轻巧\n特别是对于简单的、经常使用的类（例如，颜色、向量、点等）\n这些默认的构造函数经常在你意想不到的地方被调用\n使用构造函数初始化器列表使用：Color::Color()     : r(0), g(0), b(0)&#123;&#125;\n而不是Color::Color()&#123; r = g = b = 0; &#125;\n\n尽可能使用位操作&gt;&gt;, &lt;&lt;代替整数乘法和除法谨慎使用表格查询功能\n许多人鼓励对复杂的函数（例如三角函数）使用预先计算的数值表。对于光线追踪来说，这通常是不必要的。内存查找的成本非常高（而且越来越高），重新计算一个三角函数的速度往往和从内存中检索数值的速度一样快（特别是当你考虑到三角函数的查找会污染CPU的缓存）\n在其他情况下，查找表可能非常有用。对于 GPU 编程，对于复杂函数，通常首选表查找\n\n对于大多数对象类型，使用运算符+=、-=、*=和/=，而不是运算符+、-、*和/\n简单的操作需要创建一个未命名的、临时的中间对象\n\n例如：\nVector v = Vector(1,0,0) + Vector(0,1,0) + Vector(0,0,1);\n创建五个未命名的临时Vector对象：Vector(1,0,0)Vector(0,1,0)Vector(0,0,1)Vector(1,0,0) + Vector(0,1,0)Vector(1,0,0) + Vector(0,0,0)\n\n稍微啰嗦的代码：\nVector v(1,0,0); v+= Vector(0,1,0); v+= Vector(0,0,1);\n只创建两个临时Vector：Vector(0,1,0)Vector(0,0,1)这节省了6个函数调用（3个构造函数和3个析构函数）\n\n\n对于基本数据类型，使用运算符+、-、*和/而不是运算符+=、-=、*=和/=延迟声明局部变量\n声明对象变量总是涉及一个函数调用（构造函数）\n如果一个变量只是有时需要（例如在 if 语句中）只在必要时才声明，那么只有在使用这个变量的时侯才调用构造函数\n\n对于对象，使用前缀运算符（++obj）而不是后缀运算符（obj++）\n这在你的光线追踪器中可能不会成为一个问题\n使用后缀操作符必然会对对象进行拷贝（额外调用constructor和destructor），而前缀操作符不需要临时拷贝\n\n谨慎使用模板\n有时候对各种实例可能需要不同方式的优化\n标准模板库优化得相当好，但如果你打算实现交互式光线追踪器，我会避免使用它\n为什么？通过自己实现它，你会知道它使用的算法，所以你会知道使用代码的最有效方式\n更重要的是，我的经验是：STL库的调试编译很慢。 通常情况下，这不是一个问题，除非你需要使用调试版本进行性能剖析。 你会发现STL构造、迭代等使用了15％以上的运行时间，这可能会使性能剖析报告输出很混乱\n\n在计算过程中避免动态内存分配\n动态内存非常适用于存储场景和其他在计算过程中不改变的数据\n然而，在许多（大多数）系统上，动态内存分配需要使用锁来控制对分配器的访问。对于使用动态内存的多线程应用程序，由于需要等待分配和释放内存，增加额外的处理器实际上可能会导致速度减慢\n即使是单线程的应用程序，在堆上分配内存也比在堆上添加内存要昂贵。 操作系统需要进行一些计算来找到一个大小合适的内存块\n\n查找并且利用系统内存缓存相关的信息\n如果一个数据结构适合在一个缓存行中，那么只需要从主内存中提取一次就可以处理整个类\n确保所有数据结构都和cache line边界对齐。 （假设你的数据结构和缓存行都是 128 字节，如果你的结构的 1 个字节在第一个缓存行中，而其他 127 个字节在第二个缓存行中，性能仍然会很差）\n\n避免不必要的数据初始化\n如果你必须初始化一大块内存，考虑使用memset()\n\n尽量提前结束循环和提前返回函数\n考虑将一条射线和一个三角形相交。常见的情况是，射线会错过三角形。因此，这应该被优化\n如果你决定让射线与三角形平面相交，如果射线平面相交的t值为负数，你可以立即返回。 这样你就可以跳过大约一半的射线与三角形相交处的重心坐标计算。这是个大胜利。一旦你知道没有相交发生，相交函数就应该退出\n同样，有些循环可以提前终止。 例如，在拍摄阴影射线时，最近的交叉点的位置是不必要的。 一旦发现任何结论性的相交点，相交程序就可以返回\n\n在纸上简化你的公式\n在许多方程中，等式两边的项会被抵消……要么总是如此，要么在某些特殊情况下如此\n编译器无法找到这些简化，但你可以。只是消除内循环中一些耗时的操作，比其他需要优化好几天的地方更事半功倍\n\nintegers、fixed-points、32-bit floats、64-bit double 在数学运算之间的差别并不像你想象的那么大\n在现代 CPU 上，浮点运算与整数运算的吞吐量基本相同。在光线追踪等计算密集型程序中，这导致整数和浮点成本之间的差异可以忽略不计。这意味着，您不应该特意把浮点数转成整数再运算\n双精度浮点运算可能并不比单精度浮点运算慢，特别是在64位机器上。我见过在同一台机器上，射线追踪器使用所有的双精度运算比所有的浮点运算更快。我也看到过相反的情况\n\n考虑重新表述你的数学的方法，以消除耗时的操作\nsqrt()通常是可以避免的，特别是在比较值的平方时可以得到相同的结果\n如果你反复除以x，可以考虑计算$\\frac{1}{x}$并乘以结果。这曾经是向量归一化的一个大赢家（3次除法），但我最近发现它现在是一个折腾的过程。 然而，如果你做的除法超过3次，它应该还是有好处的\n如果你执行一个循环，确保在迭代之间没有变化的计算被拉出循环\n考虑是否可以在一个循环中增量计算数值（而不是每次迭代都从头计算）\n\n待续https://www.eventhelix.com/embedded/optimizing-c-and-cpp-code/\n","categories":["知识积累"],"tags":["C/C++","优化","翻译/理解"]},{"title":"Modern C++: 语法糖","url":"/archives/d8921827.html","content":"","categories":["C/C++"],"tags":["C/C++"]},{"title":"读书笔记","url":"/archives/7b67faab.html","content":"性能之巅时间单位：\n\n\n单位\n简写\n与1秒比例\n\n\n\n分\nm\n$$ 60 $$\n\n\n秒\nm\n$$ 1 $$\n\n\n毫秒\nms\n$$ 0.001 \\iff 1&#x2F;1000 \\iff 1 * 10^{-3} $$\n\n\n微秒\nus\n$$ 0.000001 \\iff 1&#x2F;1000000 \\iff 1 * 10^{-6} $$\n\n\n纳秒\nns\n$$ 0.000000001 \\iff 1&#x2F;1000000000 \\iff 1 * 10^{-9} $$\n\n\n皮秒\nps\n$$ 0.000000000001 \\iff 1&#x2F;1000000000 \\iff 1 * 10^{-12} $$\n\n\n系统的各种延时：\n\n\n事件\n延迟\n相对事件比例\n\n\n\n1个CPU周期\n0.3 ns\n1 s\n\n\nL1 缓存访问\n0.9 ns\n3 s\n\n\nL2 缓存访问\n2.8 ns\n9 s\n\n\nL3 缓存访问\n12.9 ns\n43 s\n\n\n主存访问(从CPU访问DRAM)\n120 ns\n6 分\n\n\n固态硬盘I&#x2F;O(闪存)\n50-150 us\n2-6 天\n\n\n旋转磁盘I&#x2F;O\n1-10 ms\n1-12 月\n\n\n互联网：从旧金山到纽约\n40 ms\n4 年\n\n\n互联网：从旧金山到英国\n81 ms\n8 年\n\n\n互联网：从旧金山到澳大利亚\n183 ms\n19 年\n\n\nTCP 包重传\n1-3 s\n105-317 年\n\n\nOS 虚拟化系统重启\n4 s\n423 年\n\n\nSCSI 命令超时\n30 s\n3 千年\n\n\n硬件虚拟化系统重启\n40 s\n4 千年\n\n\n物理系统重启\n5 m\n32 千年\n\n\n物理距离-&gt;网速基准值推算公式：\n光速：299792458 m&#x2F;s -&gt; 300000 km&#x2F;s\n光纤是经物理介质的，理论值会比光经空气慢；一般简化用 200000 km&#x2F;s 为参考\neg. 新加坡 - 美弗吉尼亚 物理距离: 15000 km；单程时间：15000 &#x2F; 200000 * 1000 &#x3D; 75 ms；RTT（ping）约 150 ms\n\n术语：\nIOPS: 每秒发生的输入&#x2F;输出操作的次数，是数据传说的一个对量方法。对于磁盘的读写，IOPS 指的是每秒读和写的次数。\n吞吐量: 评价工作执行的速率，尤其是在数据传输方面，这个属于用于描述数据传输速度（字节&#x2F;秒或者比特&#x2F;秒）。再某些情况下（如数据库），吞吐量指的是操作的速度（每秒操作数或每秒业务数）\n相应时间: 一次操作完成的时间。包括用于等待和服务的时间，也包括用来返回结果的时间。\n延时: 延时是描述操作里用来等待服务的时间。再某些情况下，它可以指的是整个操作时间，等同于响应时间。\n使用率: 对于服务所请求的资源，使用率描述再所给定的时间区间内资源的繁忙程度。对于存储资源来说，使用率指的就是所消耗的存储容量（例如，内存使用率）。\n饱和度: 指的是某一资源无法满足服务的排队工作量。\n瓶颈: 在系统性能里，瓶颈指的是限制系统性能的那个资源。分辨和移除系统瓶颈是系统性能的一项重要工作。\n工作负载: 系统的输入或者是对系统所时间的负载叫做工作负载。对于数据库来说，工作负载就是客户端发出的数据库请求和命令。\n缓存: 用于复制或者缓冲一定量数据的高速存储区域，目的是为了避免对较慢的存储层级的直接访问，从而提高性能。出于经济考虑，缓存区的容量要比更慢以及的存储容量要小。\n\n性能分析方法：USE (utilization, saturation, errors)对于所有的资源，查看它的使用率、饱和度和错误\n\n资源：所有服务器物理元器件（CPU、总线…）。某些软件资源也能算在内 （CPU）\n使用率：在规定的时间间隔内，资源用于服务工作的时间百分比。（单个CPU运行在90%的使用率上）\n饱和度：资源不能在服务更多额外工作的程度，通常有等待队列。（CPU的平均运行队列长度是4）\n错误：错误事件的个数。（这个网络接口发生了50次timeout）\n\n\n过程：\n软件资源：\n互斥锁：锁被持有的时间是使用时间，饱和度指的是有线程排队在等锁\n线程池：线程忙于处理工作的时间是使用时间，饱和度指的是等待线程池服务的任务数目\n进程/线程容量：系统的进程&#x2F;线程的总数是有上限的，当前的使用数目是使用率，等待分配认为是饱和度，错误是分配失败（cannot fork）\n文件描述符容量：同进程&#x2F;线程容量一样，只不过针对的是文件描述符\n\n建议：对于使用上述这些指标类型，这里有一些总体的建议。\n\n使用率：100%的使用率通常是瓶颈的信号（检查饱和度并确认其影啊）。使用率超过60%可能会是问题，基于以下理由：时间间隔的均值，可能掩盖了100%使用率的短期爆发，另外，一些资源，诸如硬盘（不是 CPU)，通常在操作期间是不能被中断的，即使做的是优先级较高的工作。随着使用率的上升，排队延时会变得更颜緊和明显。\n饱和度：任何程度的饱和都是问题(非零)。饱和程度可以用排队长度或者排队所花的时间来度量。\n错误：错误都是值得研究的，尤其是随看错误增加性能会变差的那些错误。\n\n操作系统\n内核：内核执行，时钟周期，内核态&#x2F;用户态\n栈：用户栈和内核栈\n中断和中断线程\n中断优先级\n进程：进程创建，进程的生命周期，进程环境\n系统调用\n虚拟内存\n内存管理\n调度器\n文件系统：VFS, I&#x2F;O 栈\n缓存（括号内表示例子）：\n应用程序缓存\n服务器缓存（Apache缓存）\n缓存服务器（Redis缓存）\n数据库缓存（MySQL缓冲区高速缓存）\n目录缓存（DNLC）\n文件元数据缓存（inode缓存）\n操作系统缓冲区高速缓存（segvn）\n文件系统主缓存（ZFS ARC）\n文件系统次级缓存（ZFS L2ARC）\n设备缓存（ZFS vdev）\n块缓存（缓冲区高速缓存）\n磁盘控制器缓存（RAID卡缓存）\n存储阵列缓存\n磁盘内置缓存\n\n\n网络\n设备驱动\n多处理器：CPU 交叉调用\n抢占 &#x2F; 非抢占\n资源管理\n观测性\n\nlinux 内核功能：\nCPU 调度级别：各种先进的CPU调度算法，包括调度域，对于非一致性存储访问架构（NUMA）能做出更好的决策\nI/O 调度级别：开发了不同的块I&#x2F;O调度算法，包括deadline、anticipatory和完全公平队列（CFQ）\nTCP 拥塞：linux内核支持更新的TCP拥塞算法，允许按需选择 net.ipv4.tcp_congestion_control。此外还有很多对TCP的增强\nOvercommit：有out-of-memory(OOM) killer, 该策略用较少内存做更多的事情\nFutex：fast user-space mutex 的缩写，用于提供高性能的用户级别的同步原语\n巨型页：由内核和内存管理单元（MMU）支持的大型内存的预分配\nOprofile：研究CPU使用和其他活动的系统剖析工具，内核和应用程序都适用\nRCU：内核所提供的只读的更新同步机制，支持伴随更新的多个读取的并发，提升了读取频繁的数据和性能和扩展性\nepoll：可以高效的对多个打开的文件描述符做I&#x2F;O等待的系统调用，提升了服务器应用的性能\n模块I/O调度：linux对调度块设备I&#x2F;O提供可插拔的调度算法\nDebugFS：一个简单的非结构化接口，用该接口内核可以降数据暴露到用户级别，通常为某些性能工具所用\nCpusets：进程独占的CPU分组\n自愿内核抢占：这个抢占过程，提供了低延时的调度，并且避免了完全抢占的复杂性\ninotify：文件系统事件的监控框架\nblktrace：跟踪块I&#x2F;O事件的框架和工具（后来迁移到了tracepoints中）\nsplice：一个系统调用，将数据在文件描述符和管道之间快速移动，而不用经过用户空间\n延时审计：跟踪每个任务的延时状态\nIO审计：测量每个进程的各种存储I&#x2F;O统计\nDynTicks：动态的tick，当不需要时（tickless），内核定时中断不会触发，这样可以节省CPU的资源和电力\nSLUB：新的slab内存分配器的简化版本\nCFS：完全公平的调度算法\ncgroups：控制组可以测量并限制进程组的资源使用\nlatencytop：观察操作系统的延时来源的仪器和工具\nTracepoints：静态内核跟踪点（也称静态探针）可以组织内核里的逻辑执行点，用于跟踪工具（之前是内核标记）\nperf：perf是一套性能观测工具，包括CPU性能计数器剖析、静态和动态跟踪\n透明巨型页：这是一个简化巨型（大型）内存页面使用的框架\nUprobes：用户级别软件动态跟踪的基础设施，为其他软件所用（perf、SystemTap等等）\nKVM：基于内核的虚拟机（Kernel-based Virtual Machine，KVM）使得可以创建虚拟的操作系统实例，并运行虚拟机自己的内核\n\n观测工具：计数器（默认开启、零开销）操作系统内核中维护了各种统计数据，称为计数器，用于对事件计数。通常计数器实现为无符号的整形数，发生事件时递增。\n系统级别\nvmstat：虚拟内存和物理内存统计，系统级别\nmpstat：每个 CPU 的使用情况\niostat：每个磁盘 I &#x2F;O 的使用情况，由块设备接口报告\nnetstat：网络接口的统计，TCP&#x2F;IP 栈的统计，以及每个连接的一些统计信息\nsar：各种各样的统计，能归档历史数据\n\n进程级别（&#x2F;proc）\nps：进程状态，显示进程的各种统计信息，包括内存和 CPU 使用\ntop：按一个统计数据排序，显示排名高的进程\npmap：将进程的内存段和使用统计一起列出\n\n跟踪（默认不开启、有CPU和存储开销）系统级别\ntcpdump：网络包跟踪（libpcap lib)\nblktrace：块 I&#x2F;O 跟踪\niosnoop：块I&#x2F;O 跟踪（基于DTrace）\nexescnoop：跟踪新进程（基于DTrace）\ndtruss：系统级别的系统调用缓冲跟踪（基于Dtrace）\nDTrace：跟踪内核的内部活动和所有资源的使用情况，支持静态和动态的跟踪（可编程环境）\nSystemTap：跟踪内核的内部活动和所有资源的使用情况，支持静态和动态的跟踪（可编程环境）\nperf：linux 性能事件，跟踪动态和静态的指针\n\n进程级别\nstrace：系统调用跟踪\ngdb：源码级别的调试器\n\n剖析\noprofile：linux系统剖析\nperf：linux性能工具集，包含有剖析的子命令\nDTrace：程序化剖析，基于时间的剖析用自身的profile provider，基于硬件事件的剖析用cpc provider\nSystemTap：程序化剖析，基于时间的剖析用自身的timer tapset，基于硬件事件的剖析用perf tapset\ncachegrind：源自valgrind工具集，能对硬件缓存的使用做剖析，也能用kcachegrind做数据可视化\nIntel VTune Amplifier XE：linux和windows的剖析，拥有包括源代码浏览在内的图形界面\nOracle Solaris Studio：用自带的性能分析器对Solaris和linux做剖析，拥有包括源代码浏览在内的图形界面\n\n编程语言通常有自己的专用分析器，可以检查语言上下文\n监视（sar）观测来源\n\n\nType\nLinux\n\n\n\n进程级计数器\n&#x2F;proc\n\n\n系统级计数器\n&#x2F;proc, &#x2F;sys\n\n\n设备驱动和调试信息\n&#x2F;sys\n\n\n进程级跟踪\nptrace, uprobes\n\n\n性能计数器\nperf_event\n\n\n网络跟踪\nlibpcap\n\n\n进程级延时指标\n延时核算\n\n\n系统级跟踪\ntracepoints, kprobes, ftrace\n\n\n&#x2F;proc\nlimits：实际的资源限制\nmaps：映射的内存区域\nsched：CPU调度器的各种统计\nschedstat：CPU运行时间、延时和时间分片\nsmaps：映射内存区域的使用统计\nstat：进程状态和统计，包括总的CPU和内存的使用情况\nstatm：以页为单位的内存使用总结\nstatus：stat和statm的信息，用户可读\ntask：每个任务的统计目录\n\n系统级别：\n\ncpuinfo：物理处理器信息，包含所有虚拟CPU、型号、时钟频率和缓存大小\ndiskstats：对于所有磁盘设备的磁盘I&#x2F;O统计\ninterrupts：每个CPU的中断计数器\nloadavg：负载平均值\nmeminfo：系统内存使用明细\nnet/dev：网络接口统计\nnet/tcp：活跃的TCP套接字信息\nschedstat：系统级别的CPU调度器统计\nself：关联当前进程ID路径的符号链接\nslabinfo：内核slab分配器缓存统计\nstat：内核和系统资源的统计，包括CPU、磁盘、分页、交换区、进程\nzoneinfo：内存区信息\n\n&#x2F;sys应用程序目标\n延时：低应用响应时间\n吞吐量：高应用程序操作率或者数据传输率\n资源使用率：对于给定应用程序工作负载，高效的使用资源\n\n大O标记法\n\n\n标记法\n举例\n\n\n\nO(1)\n布尔判断\n\n\nO(logn)\n顺序队列的二分搜索\n\n\nO(n)\n链表的线性搜索\n\n\nO(nlogn)\n快速排序（一般情况）\n\n\nO(n^2)\n冒泡排序（一般情况）\n\n\nO(2^n)\n分解质因数；指数增长\n\n\nO(n!)\n旅行商人问题的穷举法\n\n\n\nhttps://zhuanlan.zhihu.com/p/50516776\n\n","categories":["笔记"],"tags":["笔记"]},{"title":"C# Anti-Cheat 优化","url":"/archives/e3346785.html","content":"简介unity 有个很出名的插件 AntiCheatToolKit，几乎做游戏的都会考虑用这个插件防止数据篡改；但是公共的插件必然有公共的破解方法，面对游戏一直被破解的情况；我们考虑换一下这个加密方式防破解，防外挂的路太长了，在非CS模型下，目前我们也只能遇矛加盾，被动的防御\n原版\n加密：很直接的异或混淆处理\n取值：都用混淆后的值解出真实值给外部用\n检查：数据修改时先检查原值解开后是否和内存里备份的原值相同，不相同的话认为被篡改并抛出回调；然后继续用内部的值\n\n本身的思路很清楚，只是加密的方式过于简单了，想要获取加密用的秘钥，只需用0值传入传出一下就好了\n/// &lt;summary&gt;/// Encrypts passed value using passed key./// &lt;/summary&gt;/// Key can be generated automatically using GenerateKey()./// \\sa Decrypt(), GenerateKey()public static int Encrypt(int value, int key)&#123;    return value ^ key;&#125;/// &lt;summary&gt;/// Decrypts passed value you got from Encrypt() using same key./// &lt;/summary&gt;/// \\sa Encrypt()public static int Decrypt(int value, int key)&#123;    return value ^ key;&#125;\n\n修改\n只考虑加密算法上的修改，一样基于异或，但是做更多的步奏避免从算法层面上直接获取到解密用的秘钥\n核心思路是: 更多层的异或混淆，每次混淆用的key也(看似)没有规则的变更一下\n\nprivate static int left_rotate(uint src, int bits)&#123;    return (int)((src &lt;&lt; bits) | (src &gt;&gt; (32 - bits)));&#125;private static int right_rotate(uint src, int bits)&#123;    return (int)((src &gt;&gt; bits) | (src &lt;&lt; (32 - bits)));&#125;/// &lt;summary&gt;/// Encrypts passed value using passed key./// &lt;/summary&gt;/// Key can be generated automatically using GenerateKey()./// \\sa Decrypt(), GenerateKey()public static int Encrypt(int value, int key)&#123;    value = value ^ key;    value = right_rotate((uint)value, key % 10);              // offset 1    value = value ^ key;    value = right_rotate((uint)value, key % 100000 / 10000);  // offset 5    value = value ^ key;    return value;    //return value ^ key;&#125;/// &lt;summary&gt;/// Decrypts passed value you got from Encrypt() using same key./// &lt;/summary&gt;/// \\sa Encrypt()public static int Decrypt(int value, int key)&#123;    value = value ^ key;    value = left_rotate((uint)value, key % 100000 / 10000);    value = value ^ key;    value = left_rotate((uint)value, key % 10);    value = value ^ key;    return value;    //return value ^ key;&#125;","categories":["anti-cheat"],"tags":["C#","anti-cheat"]},{"title":"性能：linux Performance Analysis in 60,000 Milliseconds","url":"/archives/40317e6a.html","content":"前言关于系统性能优化，Netflix团队的一篇Blog写的很实用；https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55\n正文你登录到一个有性能问题的linux服务器，第一分钟检查什么？在Netflix，拥有庞大的EC2 linux云和众多性能分析工具来监控和侦察性能。包括用于云范围监控的Atlas和用于分析的Vector。虽然这些工具帮我我们解决了大多数问题，但我们又是需要登录到linux实例上，并运行一些标准的linux性能工具。\nFirst 60 Seconds: 概要在这篇文章中，Netflix性能工程管对将向你展示命令行优化性能探查的前60s，使用标准的linux工具，通过运行一下10个命令，你可以在60s内对系统资源使用情况和正在运行的进程有一个更高层次的了解。查找错误(error)和饱和度(saturation)指标，因为他们都很容易表示，以及资源利用率。饱和度是指一个资源的负载超过了他能处理的范围，可以通过请求队列的长度(length of a request queue)或者等待的时间(time spent waiting)来显示。\nuptimedmesg | tailvmstat 1mpstat -P ALL 1pidstat 1iostat -xz 1free -msar -n DEV 1sar -n TCP,ETCP 1top\n其中一些命令需要安装sysstat软件包。这些命令返回的内容将帮助你完成一些 Use Method : 一种定位性能瓶颈的方法。这包括检查所有资源 (CPU、内存、磁盘等) 的利用率、饱和度和错误指标。还要注意什么时候检查和排除某种资源，因为通过排除法，可以缩小研究目标，并指导后续的检查。\n以下总结了这些命令，并提供了生产系统的示例。有关这些工具的更多信息，请参与他们的man pages。\n1. uptime$ uptime 23:51:26 up 21:31, 1 user, load average: 30.02, 26.43, 19.02\n这是一个快速的方法来查看系统平均负载情况，表示了要运行的任务（进程）的数量。在linux系统上，这些数字包含希望在CPU上运行的进程，以及在不间断I&#x2F;O（通常是磁盘I&#x2F;O）中阻塞的进程。他给出了资源负载（或者需求）的高级概念，但如果没有其他工具配合就无法正确理解。仅值得快速浏览一下。\n这三个数字是具有 1 分钟、5 分钟和 15 分钟常数的指数阻尼移动总和平均值。这三个数字让我们对负载如何随时间变化有一些了解。例如，如果您被要求检查有问题的服务器，并且 1 分钟值远低于 15 分钟值，那么您可能登录太晚而错过了问题。\n在上面的示例中，平均负载显示最近有所增加，1 分钟值达到 30，而 15 分钟值达到 19。这么大的数字意味着很多东西：可能是 CPU 需求； vmstat 或 mpstat 将确认，这是本序列中的第3和第4条命令。\n2. dmesg | tail$ dmesg | tail[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0[...][1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.\n这将查看最近 10 条系统消息（如果有）。查找可能导致性能问题的错误。上面的示例包括 oom-killer 和 TCP 丢弃请求。\n不要错过这一步！ dmesg 总是值得检查。\n3. vmstat 1$ vmstat 1procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  032  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  032  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  032  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  032  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0^C\nvmstat(8)是虚拟内存统计 (virtual memory stat) 的简称，是一个常用的工具（几十年前首次为BSD创建）。它在每一行上打印关键服务器统计数据的摘要。\nvmstat运行时的参数为1，以打印一秒钟的摘要。第1行输出（在这个版本的vmstat中）有一些列显示自启动以来的平均数，而不是前一秒。现在，跳过第1行，除非你想学习并记住哪一列是哪一列。\n要检查的列：\n\nr : 在CPU上运行并等待轮次的进程数量。这提供了一个比负载平均数更好的信号来确定CPU的饱和度，因为它不包括I&#x2F;O。解释一下：一个 r 值大于CPU的计数就意味着饱和。\nfree : 以千字节为单位的可用内存。如果要计算的位数太多，则您有足够的可用内存。包含在命令 7 中的 free -m 命令更好地解释了空闲内存的状态。\nsi, so : 换入和换出。如果这些不为零，则表示内存不足。\nus, sy, id, wa, st : 这些是CPU时间的细分，是所有CPU的平均时间。它们是用户时间、系统时间（内核）、空闲时间、等待I&#x2F;O时间和被盗时间（被其他客体，或在Xen中，客体自己的隔离驱动域）。\n\nCPU 时间细分将通过增加 用户 + 系统 时间来确认 CPU 是否繁忙。恒定程度的等待 I&#x2F;O 指向磁盘瓶颈；这是 CPU 空闲的地方，因为任务被阻塞，等待挂起的磁盘 I&#x2F;O。您可以将等待 I&#x2F;O 视为 CPU 空闲的另一种形式，它可以提供有关它们为何空闲的线索。\n系统时间对于 I&#x2F;O 理是必要的。超过 20% 的高系统时间平均值，进一步探索可能会很有趣：也许内核处理I&#x2F;O的效率很低。\n在上面的例子中，CPU时间几乎完全在用户层面，而是指向应用程序层面的使用。CPU的平均利用率也远远超过90%。这不一定是个问题；使用 r 列检查饱和程度。\n4. mpstat -P ALL 1$ mpstat -P ALL 1Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.7807:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.9907:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.0007:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.0007:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03[...]\n此命令打印每个 CPU 的 CPU 时间故障，可用于检查不平衡。单个热 CPU 可以作为单线程应用程序的证据。\n5. pidstat 1$ pidstat 1Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/007:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat^C\npidstat 有点像 top 的 per-process 摘要，但打印滚动摘要而不是清除屏幕。这对于随着时间的推移观察模式很有用，还将您看到的内容（复制-粘贴）记录到您的调查记录中。\n上面的示例将两个 java 进程标识为负责消耗 CPU。 %CPU 列是所有 CPU 的总数； 1591% 表明 java 进程消耗了将近 16 个 CPU。\n6. iostat -xz 1$ iostat -xz 1Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle          73.96    0.00    3.73    0.03    0.06   22.21Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilxvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09xvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25xvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26dm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04dm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00dm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03[...]^C\n这是了解块设备（磁盘）、应用的工作负载和由此产生的性能的绝佳工具。\n重点关注：\n\nr/s, w/s, rkB/s, wkB/s: 这些是交付给设备的每秒读数、写数、读KB和写KB。使用这些来描述工作负载。一个性能问题可能只是由于应用了过多的负载。\nawait: I&#x2F;O 的平均时间（以毫秒为单位）。这是应用程序遭受的时间，因为它包括排队时间和服务时间。大于预期的平均时间可能是设备饱和或设备问题的指标。\navgqu-sz: 向设备发出的平均请求数。大于 1 的值可能是饱和的证据（尽管设备通常可以并行处理请求，尤其是前置多个后端磁盘的虚拟设备。）\n%util: 设备利用率。这实际上是一个繁忙的百分比，显示设备每秒钟进行工作的时间。大于60%的数值通常会导致性能不佳（应该在等待中看到），尽管这取决于设备的情况。接近100%的值通常表示饱和。\n\n如果存储设备是一个逻辑磁盘设备，面向许多后端磁盘，那么100%的利用率可能只是意味着一些I&#x2F;O在100%的时间被处理，然而，后端磁盘可能远远没有饱和，可能能够处理更多的工作。\n请记住，性能不佳的磁盘 I&#x2F;O 不一定是应用程序问题。许多技术通常用于异步执行 I&#x2F;O，因此应用程序不会直接阻塞和遭受延迟（例如，读取的预读和写入的缓冲）。\n7. free -m$ free -m             total       used       free     shared    buffers     cachedMem:        245998      24545     221453         83         59        541-/+ buffers/cache:      23944     222053Swap:            0          0          0\n右边两列显示：\n\nbuffers: 对于缓冲区缓存，用于块设备 I&#x2F;O。\ncached: 用于页面缓存，由文件系统使用。\n\n我们只是想检查它们的大小是否接近于零，这会导致更高的磁盘 I&#x2F;O（使用 iostat 确认）和更差的性能。上面的例子看起来不错，每个都有很多 MB。\n-/+ 缓冲区/缓存 为已用和可用内存提供了较少混淆的值。 Linux 将空闲内存用于缓存，但如果应用程序需要，可以快速回收它。所以在某种程度上，缓存的内存应该包含在空闲内存列中，这一行就是这样做的。甚至有一个网站 linuxatemyram 是关于这种混淆的。\n如果使用linux上的ZFS，就像我们在一些服务中所做的那样，这可能是额外的混乱，因为ZFS有它自己的文件系统缓存，并没有被free -m列正确反映出来。看起来系统的可用内存很低，而实际上这些内存在需要时可以从ZFS缓存中使用。\n\nlinux ate my ram:\n这是怎么回事？Linux 借用未使用的内存用于磁盘缓存。这使您看起来好像内存不足，但实际上并非如此！一切都好！\n为什么要这样做？磁盘缓存使系统更快，响应更快！除了让新手感到困惑之外，没有任何缺点。它不会以任何方式占用应用程序的内存，永远不会！\n如果我想运行更多应用程序怎么办？如果你的应用程序想要更多的内存，他们只需拿回磁盘缓存借来的一大块。磁盘高速缓存总是可以立即还给应用程序的 你的内存并不低!\n我需要更多的交换区吗？不，磁盘缓存只是借用了应用程序目前不需要的内存。它不会使用交换空间。如果应用程序想要更多的内存，他们只是从磁盘缓存中拿回来。他们不会开始交换。\n我如何阻止 linux 这样做？你不能禁用磁盘缓存。任何人想禁用磁盘缓存的唯一原因是，他们认为磁盘缓存占用了他们的应用程序的内存，其实不然。磁盘缓存使应用程序的加载速度更快，运行更流畅，但它永远都不会占用内存。因此，绝对没有理由禁用它。然而，如果你发现自己需要快速清除一些内存来解决另一个问题，比如一个虚拟机表现不佳，你可以用 echo 3 | sudo tee /proc/sys/vm/drop_caches 强制linux无损地丢弃缓存。\n如果不是，为什么 top 和 free 会说我的所有 ram 都已使用？这只是术语上的差异。您和 linux 都同意应用程序占用的内存是 used 的，而没有用于任何事情的内存是 free。但是，您如何计算当前用于某事但仍可供应用程序使用的内存？您可能会将该内存视为 free 和&#x2F;或 available。 Linux 将其视为 used，但也将其视为available：这个something（大致）就是 top 和 free 所说的 buffers 和 cached。由于您的和 linux 的术语不同，您可能会认为自己的内存不足，但实际上并非如此。\n我如何查看我真正拥有多少可用内存？要查看您的应用程序在不交换的情况下可以使用多少内存，请运行 free -m 并查看available列：$ free -m               total        used        free      shared  buff/cache   availableMem:           1504        1491          13           0         855      792Swap:          2047           6        2041\n（对于 2016 年之前的安装，请查看 -/+ buffers/cache 行中的 free 列。）这是你的答案，单位是MIB。如果你只是天真地看着 used和 free，你会认为你的内存是99%，而实际上只有47%!关于Linux计算的 avaukavke的更详细的技术描述，请看添加该字段的提交。\n我应该什么时候开始担心？一个 健康的、有足够内存的Linux系统 在运行一段时间后，会出现以下预期的、无害的行为:\nfree 内存接近 0\nused 内存解决内存总量\navailable 内存 (或者 free + buffers/cache) 有足够的空间 (比如：总数的 20%+)\nswap used 没有变化警告信号 真正的低内存的情况: \navailable 内存 (或者 free + buffers/cache) 接近于 0\nswap used 增加或者波动\ndmesg | grep oom-killer 显示有 outofmemory-killer 的内容\n\n\n我如何验证这些事情？有关更多详细信息以及如何试验磁盘缓存以显示此处描述的效果，请参阅此页面。很少有事情比在您自己的硬件上测量一个数量级的加速更能让您欣赏磁盘缓存！\n\n\n8. sar -n DEV 1https://linux.die.net/man/1/sar\n$ sar -n DEV 1Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.0012:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.0012:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.0012:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.0012:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.0012:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00^C\n使用此工具检查网络接口吞吐量：rxkB/s 和 txkB/s，作为工作量的衡量标准，并检查是否已达到任何限制。在上面的示例中，eth0 接收达到 22 Mbytes&#x2F;s，即 176 Mbits&#x2F;sec（远低于 1 Gbit&#x2F;sec 的限制）。\n这个版本也有%ifutil用于设备利用率（全双工的两个方向的最大值），这也是我们使用Brendan的 nicstat 来测量的东西。和nicstat一样，这很难搞清楚，而且在这个例子（0.00）中似乎不工作。\n9. sar -n TCP,ETCP 1https://linux.die.net/man/1/sar\n$ sar -n TCP,ETCP 1Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)12:17:19 AM  active/s passive/s    iseg/s    oseg/s12:17:20 AM      1.00      0.00  10233.00  18846.0012:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s12:17:20 AM      0.00      0.00      0.00      0.00      0.0012:17:20 AM  active/s passive/s    iseg/s    oseg/s12:17:21 AM      1.00      0.00   8359.00   6039.0012:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s12:17:21 AM      0.00      0.00      0.00      0.00      0.00^C\n这是一些关键 TCP 指标的汇总视图。这些包括：\n\nactive/s: 每秒本地发起的 TCP 连接数（例如，通过 connect()）。\npassive/s: 每秒远程启动的 TCP 连接数（例如，通过 accept()）。\nretrans/s: 每秒 TCP 重传次数。\n\n主动和被动计数通常作为服务器负载的一个粗略衡量标准：新接受的连接数（被动），以及下游连接数（主动）。把主动看作是出站，把被动看作是入站，可能会有帮助，但这并不严格正确（例如，考虑一个本地主机到本地主机的连接）。\n重传是网络或服务器问题的标志；它可能是一个不可靠的网络（例如，公共互联网），或者可能是由于服务器过载并丢弃数据包。上面的例子只显示了每秒一个新的 TCP 连接。\n10. top$ toptop - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffersKiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init     2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd     3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H     6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0     8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched\ntop 命令包括我们之前检查过的许多指标。运行它可以很方便地查看是否有任何内容与之前的命令有很大不同，这表明负载是可变的。\ntop 的一个缺点是随着时间的推移很难看到模式，这在提供滚动输出的 vmstat 和 pidstat 等工具中可能更加清晰。如果您没有足够快地暂停输出（Ctrl-S 暂停，Ctrl-Q 继续），也可能会丢失间歇性问题的证据，并且屏幕会清除。\n后续分析您可以应用更多命令和方法来进行更深入的钻探。请参阅 Velocity 2015 中 Brendan 的 linux 性能工具教程，该教程通过 40 多个命令进行工作，涵盖可观察性、基准测试、调整、静态性能调整、分析和跟踪。\nTODO:https://www.linuxatemyram.com/play.html\n","categories":["知识积累"],"tags":["linux","优化","翻译/理解"]},{"title":"一些问题 & 处理","url":"/archives/302e5c65.html","content":"前言\n工作过程中对于一些问题的处理方案记录，也包含一些常用轻巧的伪代码\n\nJAVA，C++\n近几年工作，主语言从C++切换到了Java，当时最主要的原因是Java更适合快速开发(有较完备的轮子)，Java是门有GC的语言，内存有较严格的管理，不会像C++一样容易出现内存问题；近些年流行的GO也是如此\nQ： 两者区别\nR： 最大的区别是在GC上。C++对于内存的使用，或者说所有权不明确，没有严格的限制（管理），这点上C++是一个开放的态度；带GC的语言对内存的管理更为严格，开发者更关注业务和框架本身。\n\nCDN 强制回源\n访问： cdn_domain&#x2F;file?x&#x3D;123 （一个随机数）\n确认： postman 这样的工具可以看下回执的header里面是否有类似 X-Cache 的值包含类似 Miss 信息\n\ntc 命令\ntc qdisc add dev eth0 root netem delay 100ms\n这个是对网卡eth0 添加策略， 发送的数据包 延时100ms\ntc qdisc add dev ens160 root netem delay 120ms 10ms\n该命令将 eth0 网卡的传输设置为延迟 120ms ± 10ms (90 ~ 130 ms 之间的任意值)发送。\ntc qdisc add dev eth0 root netem loss 20% 40%\n该命令将 eth0 网卡的传输设置为随机丢掉 20% 的数据包,成功率为 40% \ntc qdisc del dev ens160 root netem\n重启网卡或者命令删除\n\n日志解析\n先截取第92-最后的字符，再以 &#125; 分割截取倒数第二个 &#125; 之前的所有内容，再补一个 &#125;，再替换 \\&quot; 为 &quot;\n\ngrep &#x27;BI&#x27; logs/aaa.log | cut -b 92- | rev | cut -d &#x27;&#125;&#x27; -f 3- | rev | sed &#x27;s/$/&#125;/g&#x27; | sed &#x27;s/\\\\&quot;/&quot;/g&#x27;\n\n\ngrep 结果逐行解析，取出eventTime时间戳转时间字符串，再组织输出\n\ngrep &#x27;BI&#x27; aaa.log  | cut -b 92- | rev | cut -d &#x27;&#125;&#x27; -f 3- | rev | sed &#x27;s/$/&#125;/g&#x27; | sed &#x27;s/\\\\&quot;/&quot;/g&#x27; | while read line ; do etime=$(echo $line | jq &#x27;.eventTime&#x27; | cut -b -10) ; xtime=$(date -d @$etime &#x27;+%F %T&#x27;); echo &quot;$xtime  -&gt; $line&quot;; done\n\n\n日志IP分析：\n\n## disconnect 的uuid存到u.txtgrep &quot;disconnect,&quot; aaa.log  | grep &#x27;2020-10-13 18:00&#x27; | awk -F &#x27; &#x27; &#x27;&#123;print $4&#125;&#x27;   &gt; u.txt## 查u.txt里用户登录的IPcat u.txt |while read id; do echo $id;grep $id  aaa*.log |grep &#x27;login success&#x27;; echo ; done|tee /tmp/k.log## 用户登录的IP查运营商信息cat /tmp/k.log grep city|awk -F: &#x27;&#123;print $24&#125;&#x27;|awk &#x27;&#123;print $2&#125;&#x27;|grep ^[0-9]|sort|uniq |while read ip; do  res=` curl &quot;https://www.sudops.com/ipq/?format=json&amp;token=9a3061dc225dedc7d87e9ca02997b8de&amp;ip=$ip&quot; 2&gt;/dev/null|grep -P -o &#x27;desc1&quot;:.*&#x27;`; echo &quot;$ip $res&quot;; sleep 1; echo; done|tee /tmp/queryip_isp.txt\n\n\nIP解析参考： https://www.sudops.com/interface-ip-query-json-format.html\n\n缺省情况下，各协议的老化时间为：\n\n\n协议\n时间\n\n\n\nDNS\n120 s\n\n\nftp\n120 s\n\n\nftp-data\n120 s\n\n\nHTTP\n120 s\n\n\nicmp\n20 s\n\n\ntcp\n600 s\n\n\ntcp-proxy\n10 s\n\n\nudp\n120 s\n\n\nsip\n1 800 s\n\n\nsip-media\n120 s\n\n\nrtsp\n60 s\n\n\nrtsp-media\n120 s\n\n\n\n可用undo firewall-natsession &#123; all | dns | ftp | ftp-data | http | icmp | tcp | tcp-proxy | udp | sip | sip-media | rtsp |rtsp-media &#125; aging-time 命令恢复对应会话表项的超时时间为缺省值。\n\nBBR&#x2F;CUBIC 算法测试\ncubic TC 内网测试\nbbr TC 内网测试\n去掉TC\ntc只设置delay的时候两者差不多，但是一旦有了lose，差别就很大了\n公网：香港-&gt;杭州（杭州机器带宽小）\n\n唯一ID\n老生常谈的问题，但是这个问题在期望动态扩容架构上，使用传统的**雪花算法**不是特别方便，因为随时可能会加机器，但是加机器的时候就需要考虑给这个机器单独编码才行，面对这个问题反倒是老套的**依赖数据库跳级**的方式更简单了\n\nQ： 雪花，redis自增 优缺点\n\nR：\n\n雪花优点： 不依赖数据库，可以根据自增位确定单位时间（一般是ms）最多的ID数量，也比较好确定算法可用的时长，一版是在80年+，对于大部分互联网业务，这都够用了\n雪花缺点： 强依赖时间，有回调问题需要处理；对于相同的服务，需要预先分配服务的占位Index，这个Index是有长度限制的；这方面对运维侧不友好（因为一般会把这个值放在启动项，会导致服务启动参数不同；当然也可以从数据库自己获取，先取到先占用，但是这样就又依赖了数据库）\n自增优点： 简单，除此之外好像其他都不明显\n自增缺点： 强依赖数据库（+redis），产出的ID需要混淆\n\n\nQ： 雪花的回调处理\n\nR:  一般的处理办法是缓存上次生成ID的时间，如果下次的时间比上次小，就不变更这个时间，并且用 ms 的 sequence 自增位的回调位标记，假设 sequence 有 4096(12bits) 可用，那么用最高位 1位标记回调，剩余每 毫秒 2048 个ID可用；如果遇到 反复回调，还是 报错交上层处理把\n\nQ： ID混淆（避免外面很容易的猜到ID生成的规则）\n\nR： 常用的方式是按位转换，比如每2位和另外2位的位置做交换，最后得到的依然是一个数值类型的值；实际业务中还有这个ID过长的问题，这里采用的是把最后的ID做下转码，比如常见的转成16进制，36进制；有转码的需求在，混淆也可以混在转码过程中，比如10进制的混淆把 0-9 数字随机打乱，然后做10进制-&gt;10进制的转码就好，到其他进制同理\n\n\n# - shell 打乱字符串echo &quot;0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot; | fold -w1 | shuf | tr -d &#x27;\\n&#x27;\n\n\nQ： 多个区保证唯一\nR： 首先要给多个区编码，如果这个是登陆账号，那么需要架设一组global服务器，这个ID由global检查account没有在其他区注册过之后再生成\n\n签名 token\n最简单的token就是缓存在redis中的uuid了，只要有明确的重置、续期规则就好\n对于分布式系统，不想多个系统都依赖redis的情况下，token还会做成加密后的值\nQ： 具体方式\nR： 核心思想是一段可解析，一段作为验证，有时间戳概念。\n定义一个加密Key列表，根据随机码（mn）从列表中选出一个加密Key；-&gt; secure\n基于当前时间戳一定偏移的ts；-&gt; ts\nts、playerId 混淆后的 obscured -&gt; obscured\n组合：\n验证部分：mn + obscured + secure 组合 md5 取部分字符\n解析部分：mn + ts 组合的 hex 值\n\n\n校验：\n先解出2部分\n从解析部分解析出 mn + ts\n根据 mn 拿到 secure\n根据 ts 和 playerId 解出 obscured\n组合起来验证\n\n\n额外：\n这里也可以设置一个超时时间，如果这个 token 没有在本地redis中缓存，就校验 ts 是否超时了\n因为这里认为正常逻辑里，玩家登陆后会请求覆盖到所有服务的数据\n\n\n\n\n\n// 结构private static class Signature &#123;    public int mn;           // 随机码（magic number）    public long ts;          // 时间戳    public long obscured;    // 混淆ID&#125;;\n\n防破解 - Timing Attack\n简单的解释就是hack利用密码、token等一般验证（逐个字符验证，验证到错误字符停止并返回错误）中根据验证返回的时间判断到哪个字符出错了，暴力破解的一种\n简单的应对如下代码// compare const, safe signature compare function (see: Timing Attack)// size: std::min(a.length, b.length)inline bool compare_const(const void* a, const void* b, const size_t size)&#123;    if (a == nullptr || b == nullptr || size == 0) return false;    if (a == b) return true;    const unsigned char* _a = (const unsigned char*)a;    const unsigned char* _b = (const unsigned char*)b;    unsigned char result = 0;    for (size_t i = 0; i &lt; size; i++) &#123;        result |= _a[i] ^ _b[i];    &#125;    return result == 0; /* returns 0 if equal, nonzero otherwise */&#125;\n\n跨服务交互\n服务器在同一局域网： 基于数据访问隔离的思想一般是S1向S2要数据，通常是RPC调用\n服务器不在同一局域网： 可以把数据做加密后由客户端带给服务器，这里加密（签名）方式有很多，不再赘述\n\n确保玩家同一时间只在一个服务器区\n这里假设有3个区：A, B, C\nA, B 都只能到 C： 有点像传统MMO的跨服玩法，一般的做法是 A 保存数据，标记玩家到 C 了，把数据带给 C，数据的保存还是要到 A 保存\nA, B, C 可以互相跳： 玩家从A到C，A检查玩家当前是在自己服务器的前提下，A先去C请求一个token，然后标记玩家此刻在C上，客户端后面用这个token去C交互\n\n匹配服务\n避免业务层的锁： redis standalone 下 lua，避免锁，lua 里面解析结构，在结构里做标记\n\n避免死锁\n避免嵌套锁避免发生AB, BA这种情况（这里A,B表示两个不同的互斥量(std::mutex)），每个线程拿到一个锁之后，别再去获取另一个锁，每个线程只持有一个锁，如果一定需要锁多个，使用下面这些对获取锁的操作上锁\nstd::lock (C++11 https://en.cppreference.com/w/cpp/thread/lock)\nstd::scoped_lock (C++17 https://en.cppreference.com/w/cpp/thread/scoped_lock)\n\n\n避免在持有锁时调用外部代码外部代码可能发生的情况是我们不确定的，在我们持有一个外部锁的情况下，外部其他代码可能也需要获取锁，如果我们和外部代码对于使用者来说都是可以独立调用的，那么就很容易产生前一种情况了\n控制好锁的粒度，使用固定顺序获取锁std::lock&#x2F;std::scoped_lock 虽然可以锁多个互斥量，但是要求这些互斥量是一起作为入参的，如果出现不能使用这种方式的情况，就只好控制好锁的粒度，使用固定顺序去锁\n对于一个可能会多次锁的对象，使用 std::recursive_mutex\n\n服务器基础性能测试\n工具：sysbench (https://github.com/akopytov/sysbench)\ncpu 测试：\n\nsysbench --threads=N cpu --time=300 run\n\n\n内存测试：\n\nsysbench --threads=N memory --time=300 run\n\n\n网络吞吐测试：\n\niperf3 -c &#123;ip&#125; -p &#123;&#125; -t 100\n\n\nIO 测试\n\nfio -filename=/data/test -direct=1 -iodepth=1 -thread -rw=randrw -rwmixread=50 -ioengine=libaio -bs=4k -size=20G -numjobs=1 -runtime=60 -group_reporting -name=mytest\n\n\nPS. https://mp.weixin.qq.com/s/wF4M2pqlVq7KljaHAruRug\n\n\n一个程序的性能构成要件大概有三个，即算法复杂度、IO开销和并发能力。首要的影响因素是大家都熟悉的算法复杂度。一次核心算法优化和调整，可以对应用性能产生的影响甚至是代差级别的。在实际工程实现层面，无论是犯错几率，还是留下的优化空间，反而会大为下降。甚至极端情况下，可能作为非科研主导的工程师，在进行性能优化时鲜少遇到改良算法的场景，分析问题选择合适算法会有一定占比，但是可能范围也有限。\n\n语言艺术 - 通用函数简单封装\nanyone &amp; container single// anyonestatic auto anyone = [](auto&amp;&amp; src, auto&amp;&amp;... args) -&gt; bool &#123; return ((args == src) || ...); &#125;;// singletemplate&lt;typename Container&gt;static bool single(Container container)&#123;    auto it = std::cbegin(container);    return it != std::cend(container) &amp;&amp; ++it == std::cend(container);&#125;\n自旋锁 spin lockclass spin_lock&#123;private:    std::atomic_flag _flag = ATOMIC_FLAG_INIT;    // 只是一个经验值，也可以作为lock入参    static const unsigned yield_stage = 16;    static const unsigned nonsleep_stage = yield_stage * 2;public:    bool try_lock()    &#123;        return _flag.test_and_set(std::memory_order_acquire);    &#125;    bool lock(unsigned max_count = std::numeric_limits&lt;unsigned&gt;::max())     &#123;        unsigned i = 0;        for (; i &lt; max_count &amp;&amp; !try_lock(); ++i)        &#123;            if (i &lt; yield_stage)                std::this_thread::yield();            else if (i &lt; nonsleep_stage)                std::this_thread::sleep_for(std::chrono::microseconds(0));            else                 std::this_thread::sleep_for(std::chrono::microseconds(1000));        &#125;        return i &lt; max_count;    &#125;    void unlock()    &#123;        _flag.clear(std::memory_order_release);    &#125;&#125;;\ninstanceof （还需要修改，最好能做成java那种调用的样子）// instanceoftemplate&lt;class _Src&gt;class __instanceof &#123;public:    using base_type = _Src;public:    template&lt;class _Ty&gt;    bool instanceof() &#123;        return std::is_base_of&lt;_Ty, base_type&gt;::value;    &#125;&#125;;template&lt;class _Base, class _Xx,     typename std::enable_if&lt;std::is_class_v&lt;_Base&gt; &amp;&amp; std::is_class_v&lt;_Xx&gt;, bool&gt;::type = true&gt;static bool instanceof() &#123;    return std::is_base_of&lt;_Base, _Xx&gt;::value;&#125;template&lt;class _Base, class _Xx,    typename std::enable_if&lt;std::is_class_v&lt;_Base&gt;&amp;&amp; std::is_class_v&lt;_Xx&gt;, bool&gt;::type = true&gt;static bool instanceof(_Xx xx) &#123;    return std::is_base_of&lt;_Base, std::decay_t&lt;decltype(xx)&gt;&gt;::value;&#125;\n\n弱网环境\n服务端网络选型上尽可能离玩家更近、网络质量更好的地方和网络提供商\n物理距离不能避免，但是也不是物理距离最近的就一定是最快的，线路的带宽（一定要预估好服务器需要的带宽，并且对带宽做监控，比如一旦超过50%就要准备扩了）、链路的拥塞程度、吞吐量、跨网络运营商（选多线IDC）很多因素影响\n比如单独把对网络延迟要求高的服务分大区域部署多个服务节点（离玩家更近），这里需要服务端在逻辑上做好对玩家网络的判断和分配，最简单的方法在节点服务同机房开一个探测RTT的服务，客户端拿到区域内所有节点的IP，并行探测自行选择更优的节点；根据业务逻辑的需求，这个分配更可能是由玩家自主选择（类似MMO的分线、分区）、服务端基于一定指标（玩家IP所在区域、服务器存活、负载情况等）直接给玩家分配服务器；一些业务需要提前分配服务并下发Token类似的验签用于后续目标服务器对玩家身份和可进入的验签\n可以选择 cloudflare&#x2F;cloudfront 这种 anycast 的加速服务（CDN回源），大致原理是玩家先接入边缘节点，再回源到游戏服务器，网络供应商一般会对边缘节点到服务器的网络路由做优化（最优链路，减少跳跃点），而且一般会在边缘节点卸载TLS，减少RTT\n\n\n修改系统里的一些网络参数：拥塞窗口大小、读写缓冲、time wait reuse&#x2F;recycle、retransmission timeout等等\n使用BBR的拥塞算法，可以减少拥塞重传窗口折半这种情况带来的影响，网络也更平滑\n如果不是一定要DNS的，用IP就好，DNS也需要消耗1RTT，DNS本身就会有劫持、老化等很多问题\n根据业务需要看是不是可以开多个链接并行发送消息，甚至是2种协议，比如用udp处理帧数据，tcp&#x2F;rudp处理关键帧数据\n2个比较出名的rudp：KCP，QUIC\nKCP: 超发的处理方式，实际测试中效果并不好，弱网环境下的游戏表现也不好（之前没有做更深度的测试，最早我们游戏客户端的同步数据量很大，断网需要重新拉战场完整数据，对于这种很大的包KCP表现得延迟不如TCP好，可能和客户端当时的处理方式也有一定的关系，测试带宽也只有1M）\nQUIC: 已知目前IOS端在HTTP&#x2F;S上已经优先选择QUIC&#x2F;TLS1.3的方式了，quic替换长链接TCP的还没有实际应用过，需要TODO\n\n\n如果也用的是TCP的长链接方式，对于手机端一定要自己定义异步的keepalive消息，避免切后台导致链接断开（unity update在切后台会停止）；需要重连的时候，避免一个循环没有时间等待的反复重连重试，避免重连带给服务端瞬间的accept（半链接队列）压力\n对于客户端的网络实现，优先分别给Android&#x2F;IOS单独写，用系统上最优的socket，比如unity的webHttpSocket的封装，服务端支持的情况下，IOS端会优先用QUIC+TLS1.3的方式\n短连接需要避免每次都要握手的情况（http keepalive、QUIC），长链接需要异步keepalive\n打开TCP_NODELAY选项，这个基本是游戏里的默认选项了\n尽量控制传输数据包大小在一个MSS内，避免分片，任何一个分片的出现丢失都可能会造成多次传输、确认（还有分片、拼接的开销）；建议不要超过1400&#x2F;1360字节，虽然MTU&#x3D;1500情况下，TCP的MSS&#x3D;1500 - 20(IP) - 20(TCP) &#x3D; 1460，但是很多服务器、网络设备的MTU设置是小于1500的\n协议编码上尽量用占字节少的二进制编码方式（protobuffer），减小包体大小，有必要的话做压缩，用CPU时间换网络时间\n同步类型的消息尽量计算差异后再组包发送，而不是把所有都序列化到包里，数据对表现的驱动方式最好是状态类型的驱动，比如一个跑步的驱动，如果用状态可能只需要1-5个字节（标记枚举），但是要从动画驱动的话，一次跑动胳膊腿甚至手持的装备都是动画差异，包体也就更大了（游戏里我看到是先迈的左脚和你看到先迈右脚其实没有区别吧），这里也是要跟业务走，可以混合状态、动画驱动\n减少双端同步量&amp;处理量，避免无谓的消息处理和带宽占用。场景同步的游戏中，可以考虑在玩家处于某些状态的时候不要同步那么多事件到客户端；例如在九宫格地图（玩家一屏的可见视野是9个格子）中我正在打怪，而我攻击的最大范围只有一个格子，这时候服务端同步的主要内容应该集中在这一个格子里对象的事件，对于周边的其他格子信息，可以换成更小的数据包（减少客户端解析数据&amp;处理数据的时间消耗），或者由客户端以lazy帧的频率主动向服务端请求变化信息（当然这样相比服务端主动推送多了1次RTT）\n关于让客户端主动请求的题外话：服务器端一般情况下对于每个客户端相同行为处理的消耗时间是相同的，也就是服务端会以相同的频率向客户端广播消息（排除一些时间服务端由于性能问题处理的差异），而客户端是玩家的设备，也就是不同设备支持的最高帧率、不同网络环境的延迟都是不一样的；客户端的处理事件需要一个个处理，可能A设备1档机处理一个事件1s（比较用的单位时间），B设备3档机需要3s，服务端以相同的频率给到2个客户端的消息，他们实际处理的效率是不一样的，无端的浪费了带宽；所以是不是或者至少在某些状态下，由客户端主动发起请求，服务端再回执而不是主动push到客户端表现会更好。\n在gateway做广播目标对象的筛选：这里认为传统服务器单个场景是在一个gameservice的，但是单个场景的玩家是在多个gateway的，一次事件gs只需要把事件本身（也就是消息同步的message-body）广播到gateway上，由gateway做需要广播玩家的筛选，因为gateway是多组并且可以水平扩展，这样子做可以减轻gs遍历玩家的成本，也减轻gs到gateway的带宽压力（即使常规认为内网通讯是1Gbps的带宽，跑了网络传输，大包和小包影响还是很大的）；这样子做就需要gateway上有一部分场景的信息，比如九宫格放到gateway上，用二维（三维）数组方式空间换时间，拿到需要广播的对象，把消息广播出去\n客户端超发：前面提到了多个链接（甚至多种协议并行），但是这里需要做不同链接协议处理的解耦、合并等策略，需要看游戏是怎么拆分协议的，也需要看是不是有些协议上的丢弃在其他协议补偿之后可以足够满足游戏表现和数据上需要的内容；在这个基础上，如果用的是udp或者http的协议，如果用多通道超发的方式，也许能提高一些网络性能，但是会牺牲掉流量成本也会提高服务端的带宽压力；（由于拥塞控制的关系，tcp在这里是不合适的。）\n…….\n还有很多没想到或者实际遇到处理的问题\n\n防作弊从安全性上来说，客户端计算 模型 远远弱于 服务端校验，而 服务端校验 又弱于 服务端计算作弊的技术手法，有这些大类\n\n按键精灵类；\n加速(变速齿轮类)；\n改内存数值(比如改合作回合数、改SP、锁血等)；\n破解游戏包(比如直接改骰子配置参数)；\n修改网络包，包括：拦截包、修改包、重放包等等；\n脱机外挂类；\n其他；以上作弊手法，对作弊者的技术要求大体是逐渐升高的。目前出现的尚集中于前4种。外挂攻防是一个螺旋上升的过程\n\n通常，作为典型加速器的速度档会改变过程时间。这意味着游戏客户端的内部时间比服务器快。我们可以检测服务器和客户端之间的时间，以判断玩家是否通过加速器作弊。这就是重点。\n        t0                                            t3Server  |---------------------------------------------|         &gt;&gt;&gt;&gt;                                     &gt;&gt;&gt;&gt;Client        |-----------------------------------|             t1                                  t2\n\nt0：服务器向客户端发送初始化包（如游戏开始事件）。当前服务器时间为t0；\nt1：客户端在从服务器接收到init数据包后的每个间隔（例如1秒）后发送一个心跳数据包。t1是指发送第一心跳包的客户端时间，也是客户端游戏的开始时间；\nt2: 表示从客户端发送的最后一个心跳包的客户端时间；\nt3: 是服务器完成游戏或服务器随时检测到作弊的服务器时间；\n\n显然，我们可以安全地说（t3-t0）&gt;&#x3D;（t2-t1）。实际上（t3-t0）≈ ((t2-t1）+ TTL*1）。服务器如何知道（t2-t1）？作为替代，我们可以使用((heartheat_count+1）* interval）作为（t2-t1）。为了更安全，我们可以检查（t3-t0）*（1+冗余）&gt;= ((heartheat_count+1）* 间隔）。例如，间隔可以是1秒，冗余可以是0.02。首先，该解决方案无法检测到所有欺诈行为，如假客户端。但这应该足以赶上速度档。第二，这个解决方案被用于一些在线游戏（包括MMORPG、赛车游戏、塔防游戏等），在我的职业生涯中，这些游戏的PCCU（最高在线人数）远远超过了100K。\n即使正常玩家在游戏期间更改了操作系统时间，也很少会对他们造成伤害，因为我们使用心跳计数而不是客户端时间。我确实发现有些电脑的时钟芯片比平时快得多。但冗余保护了这种情况。因此，解决方案非常安全。\n在服务端是2块的校验，包数量和时间；比如检测加速（10s或者300个移动包）检测一次距离\n防破解\n协议非对称加密交换秘钥，对称加密传输内容，保护好服务端私钥，防止中间人攻击。流式加密，同样包发2次内容不一样不用标准序列化工具如protocolbuf，用修改版或者自己实现的客户端加密加壳防止调试和注入，程序签名防止篡改二进制重要的代码放虚拟机或者脚本里运行（脚本字节码需要改），一般黑客主要分析反汇编，你复杂逻辑多套基层他就晕了关键数据不落内存，一律使用getxx，setxx之类的接口，后面将真实数据经过变换以后才落内存守护进程动态跟踪监控情况决定性逻辑永远放在服务端服务端定期校验消息合理性，比如 10s 内最大的移动步长是多少，实际发上来的合理不合理，不合理就踢掉，比如按键点击频率是否超过正常人不定期弹出反外挂答题，答正确奖励经验，错误就掉线必须要放在客户端计算的内容将输入和结果hash同步给其他客户端验算，不对就踢掉当检测到客户端触碰到某规则不要急着踢掉它，而是有概率的被踢掉，还要随机几秒踢掉，这样黑客发现一会这里断一会那里断，就蒙圈了发现某黑客&#x2F;外挂工具利用某漏洞破解了游戏，先看影响大不大，再看他挣不挣钱，影响一般又不挣钱的话可以先养着他，等他挣钱了用户多了，大型活动之前，一条指令就把它封了，用户退款都可以弄得他爬不起来\n\n","categories":["知识积累"],"tags":["备忘"]},{"title":"ZGC","url":"/archives/ce87bb9c.html","content":"背景昨天临下班同事贴了张top的图，在测试过程中进程 VIRT 项异常的高\n\n测试机器是新到手的 Rocky Linux release 8.5 kernel 4.18，刚好我也有这台机器的权限，就爬上去看一眼。\nstep….s1. top\n和同事截图一致，VIRT 200G+，基于之前的印象第一感觉是不是程序线程开多了，一个线程 64M\n拿到 processId，继续检查\n\n2. cat /proc/9432/statusName:   javaUmask:  0022State:  S (sleeping)Tgid:   9432Ngid:   0Pid:    9432VmPeak: 212897896 kBVmSize: 212884428 kBVmLck:         0 kBVmPin:         0 kBVmHWM:  11635800 kBVmRSS:  11635800 kBRssAnon:          613024 kBRssFile:           24524 kBRssShmem:       10998252 kBVmData:   817140 kBVmStk:       132 kBVmExe:         4 kBVmLib:     23368 kBVmPTE:     24832 kBVmSwap:        0 kBHugetlbPages:          0 kBThreads:        84......\n\n84个线程，算下来也不该这么大的占用\n\n3. pmap -x 9432 or cat /proc/9432/maps[root@localhost xxxxx]# cat /proc/9432/stat9432 (java) S 1 9424 7983 34816 9886 1077952512 2169485 0 48 0 47084 41243 0 0 20 0 85 0 2341714 217993654272 3035148 18446744073709551615 93986510553088 93986510556840 140733418035776 0 0 0 0 3 16800972 0 0 0 17 2 0 0 5 0 0 93986510564600 0733418041311 0[root@localhost xxxxx]# cat /proc/9432/maps800000000-800003000 rwxp 00001000 08:03 67125341                         /opt/jdk-15.0.1/lib/server/classes_nocoops.jsa800003000-8003e6000 rw-p 00004000 08:03 67125341                         /opt/jdk-15.0.1/lib/server/classes_nocoops.jsa8003e6000-800b23000 r--p 003e7000 08:03 67125341                         /opt/jdk-15.0.1/lib/server/classes_nocoops.jsa800b23000-800b24000 ---p 00000000 00:00 0 800b24000-8014e4000 rw-p 00000000 00:00 0 8014e4000-810324000 ---p 00000000 00:00 0 40000000000-40100000000 rw-s 00000000 00:01 423464                       /memfd:java_heap (deleted)40100000000-41000000000 ---p 00000000 00:00 0 80000000000-80100000000 rw-s 00000000 00:01 423464                       /memfd:java_heap (deleted)80100000000-81000000000 ---p 00000000 00:00 0 100000000000-100100000000 rw-s 00000000 00:01 423464                     /memfd:java_heap (deleted)100100000000-101000000000 ---p 00000000 00:00 0 557af0934000-557af0935000 r-xp 00000000 08:03 67125607                   /opt/jdk-15.0.1/bin/java557af0936000-557af0937000 r--p 00001000 08:03 67125607                   /opt/jdk-15.0.1/bin/java557af0937000-557af0938000 rw-p 00002000 08:03 67125607                   /opt/jdk-15.0.1/bin/java557af12e5000-557af19ed000 rw-p 00000000 00:00 0                          [heap]......\n[root@localhost qa_winter-game-battle]# pmap -x 94329432:   java -Dfile.encoding=UTF-8 -Denv=dev -Dapollo.cluster=dev -Deureka.client.registerWithEureka=false -Xms4g -Xmx4g -XX:+UseZGC -XX:MaxMetaspaceSize=256m -XX:MaxDirectMemorySize=1g -Xlog:gc*:./logs/gc.log -ea -jar game-battle.jarAddress           Kbytes     RSS   Dirty Mode  Mapping0000000800000000      12       8       4 rwx-- classes_nocoops.jsa0000000800003000    3980    1760      20 rw--- classes_nocoops.jsa00000008003e6000    7412       0       0 r---- classes_nocoops.jsa0000000800b23000       4       0       0 -----   [ anon ]0000000800b24000    9984    9632    9040 rw---   [ anon ]00000008014e4000  243968       0       0 -----   [ anon ]0000040000000000 4194304 3407192 3407192 rw-s- memfd:java_heap (deleted)0000040100000000 62914560       0       0 -----   [ anon ]0000080000000000 4194304 3357220 3357220 rw-s- memfd:java_heap (deleted)0000080100000000 62914560       0       0 -----   [ anon ]0000100000000000 4194304 3356636 3356636 rw-s- memfd:java_heap (deleted)0000100100000000 62914560       0       0 -----   [ anon ]0000557af0934000       4       0       0 r-x-- java0000557af0936000       4       0       0 r---- java0000557af0937000       4       0       0 rw--- java0000557af12e5000   38776   21236   21232 rw---   [ anon ]......\n\n看到了三块很大的分配， 加起来 180G；这块内存的位置看起来更像是进程启动所需的堆空间Address           Kbytes     RSS   Dirty Mode  Mapping0000100100000000 62914560       0       0 -----   [ anon ]0000100100000000 62914560       0       0 -----   [ anon ]0000100100000000 62914560       0       0 -----   [ anon ]  \n\n这里也注意到，程序启动特别设置了 +UseZGC\n\n\n","categories":["知识积累"],"tags":["内存"]},{"title":"protobuf","url":"/archives/99fac5be.html","content":"前言protobuf 基本是 IDL(interface description language) 最常用的序列化&#x2F;反序列化组件了\n2 VS 3\n默认值：proto2 使用 default 明确指明默认值；proto3 不允许自定义默认值，所有字段都有零默认值\n语法  ：proto3 去掉了 required, optional 也不需要了\n枚举  ：proto3 需要一个具有 0 的 enums 作为默认值，会多一个 UNRECOGNIZED 用作没有覆盖的条目；proto2 用第一个作为默认值；\nUTF8 ： string 字段 proto3 会强校验 utf8 编码\n\nscalar value typeshttps://developers.google.com/protocol-buffers/docs/proto3#scalar\n\n\n\nproto Type\nNotes\nC++ Type\nJava&#x2F;Kotlin Type[1]\nPython Type[3]\nGo Type\nRuby Type\nC# Type\nPHP Type\nDart Type\n\n\n\ndouble\n\ndouble\ndouble\nfloat\nfloat64\nFloat\ndouble\nfloat\ndouble\n\n\nfloat\n\nfloat\nfloat\nfloat\nfloat32\nFloat\nfloat\nfloat\ndouble\n\n\nint32\nUses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint32 instead.\nint32\nint\nint\nint32\nFixnum or Bignum (as required)\nint\ninteger\nint\n\n\nint64\nUses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint64 instead.\nint64\nlong\nint&#x2F;long[4]\nint64\nBignum\nlong\ninteger&#x2F;string[6]\nInt64\n\n\nuint32\nUses variable-length encoding.\nuint32\nint[2]\nint&#x2F;long[4]\nuint32\nFixnum or Bignum (as required)\nuint\ninteger\nint\n\n\nuint64\nUses variable-length encoding.\nuint64\nlong[2]\nint&#x2F;long[4]\nuint64\nBignum\nulong\ninteger&#x2F;string[6]\nInt64\n\n\nsint32\nUses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s.\nint32\nint\nint\nint32\nFixnum or Bignum (as required)\nint\ninteger\nint\n\n\nsint64\nUses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s.\nint64\nlong\nint&#x2F;long[4]\nint64\nBignum\nlong\ninteger&#x2F;string[6]\nInt64\n\n\nfixed32\nAlways four bytes. More efficient than uint32 if values are often greater than 228.\nuint32\nint[2]\nint&#x2F;long[4]\nuint32\nFixnum or Bignum (as required)\nuint\ninteger\nint\n\n\nfixed64\nAlways eight bytes. More efficient than uint64 if values are often greater than 256.\nuint64\nlong[2]\nint&#x2F;long[4]\nuint64\nBignum\nulong\ninteger&#x2F;string[6]\nInt64\n\n\nsfixed32\nAlways four bytes.\nint32\nint\nint\nint32\nFixnum or Bignum (as required)\nint\ninteger\nint\n\n\nsfixed64\nAlways eight bytes.\nint64\nlong\nint&#x2F;long[4]\nint64\nBignum\nlong\ninteger&#x2F;string[6]\nInt64\n\n\nbool\n\nbool\nboolean\nbool\nbool\nTrueClass&#x2F;FalseClass\nbool\nboolean\nbool\n\n\nstring\nA string must always contain UTF-8 encoded or 7-bit ASCII text, and cannot be longer than 232.\nstring\nString\nstr&#x2F;unicode[5]\nstring\nString (UTF-8)\nstring\nstring\nString\n\n\nbytes\nMay contain any arbitrary sequence of bytes no longer than 232.\nstring\nByteString\nstr (Python 2)\nbytes (Python 3)\n[]byte\nString (ASCII-8BIT)\nByteString\nstring\n\n\ndefault values\nstring: empty string\nbytes: empty bytes\nbool: false\nnumeric: 0\nenum: the default value is the first defined enum value, which must be 0\n\nnumerical 类型序列化\n\n\n编码方式\nkey(Type)\n覆盖类型\n\n\n\nvarint\n0\nint32, int64, uint32, uint64, sint32, sint64, bool, enum\n\n\n64-bit (8字节)\n1\nfixed64, sfixed64, double\n\n\n32-bit (4字节)\n5\nfixed32, sfixed32, float\n\n\n– length delimited\n2\nstring, bytes, enbedded messaged, packed repeated fields\n\n\n– start group\n3\ngroups\n\n\n– end group\n4\ngroups\n\n\n\nvarint 编码简单点说就是数值越小的数字使用的字节数越少；最高位表示编码是否继续，如果该位为1，表示接下来的字节仍然是该数字的一部分，如果该位为0，表示编码结束。字节里的其余7位用原码补齐，采用低位字节补齐到高位的办法\n\n64-bit &#x2F; 32-bit 是固定字节数\n\n\nsyntax = &quot;proto3&quot;;package inlay.test;message numerical_int &#123;    int32 id = 1;&#125;message numerical_sint &#123;    sint32 sid = 1;&#125;message numerical_uint &#123;    uint32 uid = 1;&#125;message numerical_fixed &#123;    fixed32 fid = 1;3&#125;\n\n\n运行一段小程序，对比 int32 &amp; sint32  \n\nint32 负值数据部分占了10个字节的\n\n对于负数 (高位 1)， 大于 1 &lt;&lt; 28 的大数 (高位有部分bit被占用)，varint会额外多占空间，protobuf 分别用 sint &amp; fixed 类型处理这个问题\n\nsint32 是为负值做优化 zigZag 编码 (将有符号数统一映射到无符号数的一种编码方案)\n\nsint32 因为是映射的zigZag编码方式，是不能和 int32 互转的，例如上面 sint32 里面 1 映射的值实际是 2 \n\nfixed32 和 int32\n\nfixed32 数据部分是固定 4 字节的（即使实际数据是 1，也是需要 4 字节的），相比 int32, 对于大数值（超过 1 &lt;&lt; 28）可以比 varint 编码方式少 1 byte\n\nfixed32 的前缀是 0x0d (1 &lt;&lt; 3 | 5) 这里的 5 表示 numerical 编码方式对应的 key(Type) &#x3D; 5\n\nint32 的前缀是 0x08 (1 &lt;&lt; 3 | 0); 由于 int32 &amp; sint32 的编码方式占位是一样的，但实际上用的又是两种，这里对于 int32 &amp; sint32 的互转是会出错的…\n\n\nstring&#x2F;bytes 类型序列化\nstring &amp; bytes 的序列化规则是一样的：(1 &lt;&lt; 3 | 2) + varint(length) + value\n\n\n\nstring 会强制检查value 是否是 utf-8 编码，bytes 是 memcpy 的\n\n\n参考\nhttps://developers.google.com/protocol-buffers/docs/proto3\n\n","categories":["知识备忘"],"tags":["常用备忘","protobuf"]},{"title":"知识点备忘","url":"/archives/41a6a3ab.html","content":"pre\n很久没有找过工作了，之前以为需要关注的重点是经验、架构、设计、性能问题的处理；写了2年java做了微服务方式的架构设计以为是优势，没想外面大部分公司已经开始找大世界、偏重度游戏开发经验的人了，休闲游戏的经验显得没有点简单；再之前MMO的经验是个很传统的方式，做的内容也显得有点浅；一种已经和现在的游戏脱节的感觉….而且现在开始面算法题，知道原理的还好，一些突然出现的题目有点慌张没头绪，用笨拙的方法，甚至还很可能是错误的实现….是落后了不少，心态也慢慢着急了\n记录下这些问题吧，也是成长\n\n问题TCP 关闭后需要等 2MSL 的时间：\n这个等待也就是 TIME_WAIT 状态，发起关闭的一方在发完最后一个ACK后进入 TIME_WAIT 状态，因为这时候session已经关闭了，发起方会占用着这个端口等待 2*MSL 是因为不确定 ACK 是否被对端接收到，一个MSL也就是一个报文在网络中最大的保留时间，超时会被丢弃；这里认为对端没有收到，那么对端会重发 FIN 的消息，一个FIN + 自己的ACK 两个消息在网络中最大保留时间就是 2MSL；避免延迟的数据段被相同的4元组连接收到\n\n自旋锁、互斥锁、原子：\n自旋锁 是一个以消耗CPU不断轮训为代价更快获得锁的方式\n互斥锁 是sleep-wait condition 的方式，不耗CPU\n原子 是最小的执行单位\n\nlogin服务这种没有token验证的请求，怎么防御攻击：\nlogin更及时的反馈需要更快的缓存、更小粒度的锁；\n熔断策略：对于某个IP单位时间内请求超过一定次数后，屏蔽后续请求，至少不让他影响内部服务；\n也可以选择抵御ddos攻击的lb、cf服务作为网络入口；\n带token的可以用相同的熔断策略，下发token的可以用令牌桶的方式限制token的下发数量。这里还有一个比较常见的场景，比如登录这种，一般会到第三方服务器做账号认证，这个过程是个异步的过程，会有一定的延迟。\n\n场景同步的优化：\n减少双端同步量&amp;处理量，避免无谓的消息处理和带宽占用。场景同步的游戏中，可以考虑在玩家处于某些状态的时候不要同步那么多事件到客户端；例如在九宫格地图（玩家一屏的可见视野是9个格子）中我正在打怪，而我攻击的最大范围只有一个格子，这时候服务端同步的主要内容应该集中在这一个格子里对象的事件，对于周边的其他格子信息，可以换成更小的数据包（减少客户端解析数据&amp;处理数据的时间消耗），或者由客户端以lazy帧的频率主动向服务端请求变化信息（当然这样相比服务端主动推送多了1次RTT）\n关于让客户端主动请求的题外话：服务器端一般情况下对于每个客户端相同行为处理的消耗时间是相同的，也就是服务端会以相同的频率向客户端广播消息（排除一些时间服务端由于性能问题处理的差异），而客户端是玩家的设备，也就是不同设备支持的最高帧率、不同网络环境的延迟都是不一样的；客户端的处理事件需要一个个处理，可能A设备1档机处理一个事件1s（比较用的单位时间），B设备3档机需要3s，服务端以相同的频率给到2个客户端的消息，他们实际处理的效率是不一样的，无端的浪费了带宽；所以是不是或者至少在某些状态下，由客户端主动发起请求，服务端再回执而不是主动push到客户端表现会更好。\n在gateway做广播目标对象的筛选：这里认为传统服务器单个场景是在一个gameservice的，但是单个场景的玩家是在多个gateway的，一次事件gs只需要把事件本身（也就是消息同步的message-body）广播到gateway上，由gateway做需要广播玩家的筛选，因为gateway是多组并且可以水平扩展，这样子做可以减轻gs遍历玩家的成本，也减轻gs到gateway的带宽压力（即使常规认为内网通讯是1Gbps的带宽，跑了网络传输，大包和小包影响还是很大的）；这样子做就需要gateway上有一部分场景的信息，比如九宫格放到gateway上，用二维（三维）数组方式空间换时间，拿到需要广播的对象，把消息广播出去\n\nC11一些语法，auto和decltype, move foward区别, lamada表达式实现原理。\nauto 根据&#x3D;右边的初始值 value 推导出变量的类型；变量必须初始化，也就是在定义变量的同时必须给它赋值\ndecltype 根据 exp 表达式推导出变量的类型，跟&#x3D;右边的 value 没有关系。\nstd::move执行一个无条件的对rvalue的转化。 对于它自己本身来说， 它不会move任何东西；若对一个对象做move操作，就不要声明为 const. 因为对const对象的move请求会执行到copy操作上\nstd::forward在参数被绑定为rvalue的情况下才会将它转化为rvalue\nstd::move和std::forward在runtime时啥都不做\n下面的代码，如果函数 fn 参数去掉 &amp;&amp; 符号，将是不一样的结果，这里的 &amp;&amp; 符号是取地址#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;memory&gt;struct tt &#123;    std::string name_ = &quot;defaulted&quot;;    tt() &#123; std::cout &lt;&lt; &quot;1:&quot; &lt;&lt; this &lt;&lt; std::endl; &#125;;    tt(const char* name) : name_(name) &#123; std::cout &lt;&lt; &quot;2:&quot; &lt;&lt; this &lt;&lt; std::endl; &#125;    tt(tt&amp;&amp; rhs) &#123; std::swap(name_, rhs.name_); name_ += &quot; moved&quot;;  std::cout &lt;&lt; &quot;3:&quot; &lt;&lt; this &lt;&lt; std::endl; &#125;    ~tt() &#123;std::cout&lt;&lt; &quot;destroy:&quot; &lt;&lt; this &lt;&lt; std::endl;&#125;    std::string print() &#123; name_ += &quot;:1&quot;; return (name_); &#125;&#125;;void fn(std::string&amp;&amp; s) &#123; std::cout &lt;&lt; &quot;string(&quot; &lt;&lt; s &lt;&lt; &quot;)\\n&quot;; &#125;void fn(tt&amp; s) &#123; std::cout &lt;&lt; &quot;----lfn(&quot; &lt;&lt; s.print() &lt;&lt; &quot;)\\n&quot;; &#125;void fn(tt&amp;&amp; s) &#123; std::cout &lt;&lt; &quot;----fn(&quot; &lt;&lt; s.print() &lt;&lt; &quot;)\\n&quot;; &#125;void fn(tt* &amp;&amp;s) &#123; std::cout &lt;&lt; &quot;--------fn_ptr(&quot; &lt;&lt; (s != nullptr ? s-&gt;print() : &quot;empty&quot;) &lt;&lt; &quot;)\\n&quot;; &#125;void fn(std::shared_ptr&lt;tt&gt; &amp;&amp;s) &#123; std::cout &lt;&lt; &quot;------------fn_sptr(&quot; &lt;&lt; (s != nullptr ? s-&gt;print() : &quot;empty&quot;) &lt;&lt; &quot;|&quot; &lt;&lt; s.use_count() &lt;&lt; &quot;)\\n&quot;; &#125;template&lt;typename T&gt;void fwd_test(T&amp;&amp; t) &#123;    fn(std::forward&lt;T&gt;(t));    fn(std::forward&lt;T&gt;(t));&#125;template&lt;typename T&gt;void move_test(T&amp;&amp; t) &#123;    fn(std::move(t));    fn(std::move(t));&#125;int main() &#123;    tt tt_(&quot;lvalue&quot;);    fwd_test(tt_);    fwd_test(tt(&quot;source&quot;));    move_test(tt(&quot;source&quot;));    fwd_test(new tt(&quot;ptr&quot;));    move_test(new tt(&quot;ptr&quot;));    fwd_test(std::make_shared&lt;tt&gt;(&quot;sptr&quot;));    move_test(std::make_shared&lt;tt&gt;(&quot;sptr&quot;));&#125;\n2:0x7ffe8fe310e0----lfn(lvalue:1)----lfn(lvalue:1:1)2:0x7ffe8fe31100----fn(source:1)----fn(source:1:1)destroy:0x7ffe8fe311002:0x7ffe8fe31120----fn(source:1)----fn(source:1:1)destroy:0x7ffe8fe311202:0x2279ec0--------fn_ptr(ptr:1)--------fn_ptr(ptr:1:1)2:0x2279ef0--------fn_ptr(ptr:1)--------fn_ptr(ptr:1:1)2:0x2279f30------------fn_sptr(sptr:1|1)------------fn_sptr(sptr:1:1|1)destroy:0x2279f302:0x2279f30------------fn_sptr(sptr:1|1)------------fn_sptr(sptr:1:1|1)destroy:0x2279f30destroy:0x7ffe8fe310e0\n\nrvo : result value optimization\n\nhttps://en.cppreference.com/w/cpp/language/copy_elision 之前对 move 的使用有误区，上面一些测试作为参考，关键词 RVO 优化，编译级别的优化，受编译器影响\n\nvolatile：\n编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问，当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据\n\nmalloc 申请内存：\n分配的是虚拟内存，如果分配后的虚拟内存没有被访问的话，是不会将虚拟内存不会映射到物理内存，这样就不会占用物理内存了。小于 128 KB，则通过 brk()  free 后不释放，大于 128 KB，则通过 mmap()  free后释放\n\nconstexpr\n是尽量在编译器处理的常量，string不可以，因为编译期无法调用string的构造函数\n\n开发流程上避免崩溃：\n开发前会规定进程的职责，减小崩溃的影响面，使用vld、libasan检查内存问题，使用压测方式尽量覆盖所有功能点，使用segvcatch在运行期捕获崩溃并生成codedump（进程要不要继续需要根据项目结构来定，比如说踩坏内存那种崩溃，有可能踩坏到了别的内存，这时候再继续跑可能会有更严重的问题）；上线的进程一定是高可用部署的，避免崩溃造成服务不可用这种情况。崩溃了需要有监测程序快速把进程拉起来，如果解决了问题了就更新或者热更掉，没有的话可以给功能模块加开关，先关掉这部分功能。\n\nvirtual关键字是必须的么？什么情况必须有有这个关键字：\n是必须的，如果没有这个关键字，子类对象转换为父类之后服务调用到子类自己重写的函数；父类的析构必须有这个关键字，不然析构的时候调用不到父类的析构。\n\nvirtual template区别：\nvirtual是动多态，template是静多态，virtual是相同的入参不同的函数实体，template是不同的入参类型，相同的处理函数实体\n\nredis 雪崩的原因：\nredis缓存中大量的key同时失效，此时又刚好有大量的请求打进来\n\n….做了一段时间的架构，这套架构确实解决了一些问题，甚至在某些方面的处理是讨巧且有效的，但是耐不住在面试中被一次次打击；做好自己的当前应该做的事情吧，希望有机会做一款满意的游戏，希望不是日常的996\n一切都是最好的安排","categories":["知识备忘"],"tags":["知识备忘"]},{"title":"spdlog wrapper","url":"/archives/3f7b4a3f.html","content":"代码：https://github.com/kinly/easy_logger\n2025-04-18 更新：\n抛弃掉之前的版本，使用 logger.h 作为基础版本\n去掉复杂的内容，只保留日志最简单的样子\n关键点是增加了编译期的 std::format placeholders\n目前 logger.h 里保留的是简易的原始版本\nauto_format_rules.h 里是一个期望自定义 format 样式的版本（模板类重载，具体下面的测试用例：test_struct）\n也许这样才更合适，后期考虑把 filename 提出来作为模版，这样还可以用 spdlog 做些其他事情\n以下是这次版本 AI 协助产出的文档：\n\n编译期格式字符串自动推导工具：实现与演进记录本文记录了我在实现一个编译期类型感知的格式字符串生成工具的过程中所遇到的问题、优化思路与最终实现细节，旨在为有类似需求的 C++ 开发者提供思路。\n背景需求在使用 std::format 或 spdlog::log 等格式化日志时，频繁地手写格式字符串容易出错、不统一，也不够自动化。尤其是当参数较多，且类型不同（如 float 需保留小数）时，维护一套规范的格式变得棘手。\n为此，我希望实现以下目标：\n\n✅ 编译期推导格式字符串，无运行期开销\n✅ 不依赖 RTTI、反射或宏系统\n✅ 支持 tuple 嵌套类型展开\n✅ 针对 float&#x2F;double 提供默认精度控制（如 &#123;:.2f&#125;）\n✅ 可缓存格式字符串结构，供日志框架使用\n\n\n常见实现尝试与问题尝试 1：直接拼接 &#123;&#125; 占位符最早我直接构造 “{} {} {}” 类似的字符串，但无法体现类型特性，float 没法自动变成 &#123;:.2f&#125;，而且对 tuple、结构体等复杂类型也不友好。\n尝试 2：基于格式描述元组生成我尝试写了如下模板：\nstd::string make_fmt&lt;float, int, double&gt;() =&gt; &quot;&#123;:.2f&#125; &#123;&#125; &#123;:.2f&#125;&quot;\n\n思路不错，但写法冗长、不能递归 tuple 内容。\n尝试 3：递归处理 tuple我引入了 SFINAE 检查是否 tuple，并用 index_sequence 展开内部字段，但发现格式串缓存和拼接过程容易越界或丢失分隔符，遂引入中间格式缓存。\n最终演化出了以下结构。\n\n最终代码实现与解释顶层宏配置#ifndef AUTO_FORMAT_LOGGER_MAX_ARGS#define AUTO_FORMAT_LOGGER_MAX_ARGS 20#endif\n\n允许你限制支持的最大参数数量，避免浪费空间或越界访问。\n类型到格式映射机制template &lt;typename tt&gt;struct type_format &#123; static constexpr const char* value = &quot;&#123;&#125;&quot;; &#125;;// 对于 float/double 提供默认格式template &lt;&gt; struct type_format&lt;float&gt; &#123; static constexpr const char* value = &quot;&#123;:.2f&#125;&quot;; &#125;;template &lt;&gt; struct type_format&lt;double&gt; &#123; static constexpr const char* value = &quot;&#123;:.2f&#125;&quot;; &#125;;\n\n这是系统的核心机制，用于指定不同类型在格式字符串中的默认格式。可以很方便扩展其他类型，比如 bool 显示为 true&#x2F;false，或者为用户自定义类型注册格式化方案。\n检测类型是否为 tupletemplate &lt;typename tt&gt;concept is_tuple_like = requires &#123; typename std::tuple_size&lt;tt&gt;::type; &#125;;\n\n使用 C++20 的 concept 特性，判断某个类型是否具备 tuple 接口。\n编译期格式符收集（支持 tuple 展开）template &lt;typename tt, typename collector_tt&gt;consteval void collect_type_formats(collector_tt collector);\n\n这个递归 constexpr 函数会：\n\n如果是 tuple，就展开 tuple 的每个元素，继续递归收集\n如果是普通类型，就调用 type_format&lt;T&gt; 获取对应格式字符串，并送入 collector\n\n编译期拼接格式串template &lt;std::size_t count_vv, char sep_vv = &#x27; &#x27;&gt;consteval auto make_format_string(const std::array&lt;const char*, count_vv&gt;&amp; formats, std::size_t used);\n\n此函数将格式占位符如 &quot;&#123;:.2f&#125;&quot;, “{}” 等拼接为完整格式字符串，如：\n&#123;:.2f&#125; &#123;&#125; &#123;:.2f&#125;\n支持指定分隔符，默认是空格。\n注意我们对格式字符串进行了逆序整数输出（用于兜底），并用 std::reverse 修正顺序，这属于基本的编译期字符处理技巧。\n编译期格式缓存结构template &lt;typename... args_tt&gt;struct type_format_string_placeholders &#123;  static constexpr auto fmt = make_type_format_string_ct&lt;args_tt...&gt;();  static constexpr auto sv = std::string_view&#123;fmt.first.data(), fmt.second&#125;;&#125;;\n\n通过该结构，我们可以以任意模板参数组调用 type_format_string_placeholders&lt;Ts...&gt;::sv 获取格式字符串。\n由于格式串内容是 consteval 拼接的 std::array&lt;char&gt;，我们提供 .sv 封装为 string_view，供 std::vformat 或 spdlog::log 使用。\n多参数处理流程总结：\n模板参数包输入类型\n展开收集每个类型的格式占位符\n编译期拼接为完整字符串 char[]\n提供静态缓存字段供外部访问\n\n\n示例使用constexpr auto fmt = auto_format_rules::detail::make_type_format_string_ct&lt;float, int, float, float&gt;();std::string_view sv(fmt.first.data(), fmt.second);float a = 1.2345f, c = 3.14f, d = 2.71f;int b = 42;std::string result = std::vformat(sv, std::make_format_args(a, b, c, d));std::cout &lt;&lt; result &lt;&lt; &#x27;\\n&#x27;;// 输出: 1.23 42 3.14 2.71\n\n支持空参数：\nstatic constexpr auto fmt2 = auto_format_rules::detail::type_format_string_placeholders&lt;&gt;::sv;\n\n支持 tuple 嵌套：\nusing my_tuple = std::tuple&lt;int, float, std::tuple&lt;double, int&gt;&gt;;constexpr auto fmt = auto_format_rules::detail::type_format_string_placeholders&lt;my_tuple&gt;::sv;\n\n\n后续可扩展点\n支持结构体字段名导出（结合反射或宏）\n对于特定字段自动附加单位（如 %, ms, MB）\n自定义格式规则注册机制，如：register_format&lt;MyType&gt;(&quot;&#123;:X&#125;&quot;)\n添加 format string 校验器（在编译期验证格式与参数是否一致）\n\n\n总结这个工具让我们能够完全在编译期自动生成类型安全、规范统一的格式字符串，非常适合日志系统、调试工具、序列化预设等场景。\n如果你也在追求高性能和低维护成本的日志格式生成，不妨尝试将这个方案引入你的项目！\n欢迎评论交流和优化建议！\nprespdlog 是一个很不错的日志库，自定义程度很高，之前就用过，只是有同事封装过了就直接用了，没有细看很多，前面看到老顾头博客更新了相关的博文，看了下他在github分享的wrapper封装，就起了兴致在这个基础上扩展一下，因为用的是 mac + vscode + clang 环境，有些东西也值得记录一下\n封装\n支持基础的 daily_file, rotate, hourly_file\nif (options._daily_or_hourly == 1) &#123;    sinks.push_back(std::make_shared&lt;spdlog::sinks::daily_file_sink_mt&gt;(options._filename, 0, 2));&#125;else if (options._daily_or_hourly == 2) &#123;    sinks.push_back(std::make_shared&lt;spdlog::sinks::hourly_file_sink_mt&gt;(options._filename));&#125;if (options._rotating_file) &#123;    sinks.push_back(std::make_shared&lt;spdlog::sinks::rotating_file_sink_mt&gt;(options._filename, max_file_size, 1024));&#125;\n增加 key 的方式，支持多个分文件的日志，常见的用法里会把异步的行为单独放一个日志文件，比如：网络基础日志 net.log、三方sdk日志 sdk.log….\ntemplate&lt;const char* Key&gt;class easy_logger final : public easy_logger_static&#123;...&#125;;#define LOG_TRACE(key, msg,...) &#123; if (util::logger::easy_logger_static::should_log(spdlog::level::trace))    util::logger::easy_logger&lt;key&gt;::get().log(&#123;__FILENAME__, __LINE__, __FUNCTION__&#125;, spdlog::level::trace,    msg, ##__VA_ARGS__); &#125;;\n扩展支持 daily_folder (日常使用上希望每天一个日志目录，这样想拉日志的时候比较容易打包)，基本是参考 daily_file_sink 写的\ntemplate&lt;typename Mutex, typename FolderNameCalc = daily_foldername_calculator&gt;class daily_folder_sink final : public base_sink&lt;Mutex&gt;&#123;...&#125;\n\nfuture：支持rotating的daily日志，日志还是按天分比较合理，但也不希望一个日志文件过大\n\n\n需要注意的地方\nmac + vscode + clang 的环境，编译时遇到了一些问题\n没有直接用 xcode 是觉得之后做这种小的开发 vscode 更合适，也需要配置好本地的 vscode c++ 开发环境\n主要依赖的一些 extensions：\nc&#x2F;c++\nc&#x2F;c++ project generator\nc&#x2F;c++ themes\ncode runner\ncodelldb\nmakefile tools\n\n\n开始时候 easy_logger.h 头文件依赖是这么写的#include &lt;sstream&gt;#include &lt;memory&gt;#include &lt;utility&gt;#include &lt;filesystem&gt;#include &lt;spdlog/spdlog.h&gt;#include &lt;spdlog/async.h&gt;#include &lt;spdlog/fmt/bundled/printf.h&gt;\n编译遇到 link errorclang++ -std=c++17 -Wall -Wextra -g -Iinclude -Iinclude/sinks -I3rd -I3rd/spdlog -I3rd/spdlog/fmt -I3rd/spdlog/fmt/bundled -I3rd/spdlog/sinks -I3rd/spdlog/details -I3rd/spdlog/cfg -o output/main src/main.o  Undefined symbols for architecture x86_64:  &quot;fmt::v9::format_error::~format_error()&quot;, referenced from:      fmt::v9::detail::adjust_precision(int&amp;, int) in main.o      void fmt::v9::detail::vprintf&lt;char, fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;(fmt::v9::detail::buffer&lt;char&gt;&amp;, fmt::v9::basic_string_view&lt;char&gt;, fmt::v9::basic_format_args&lt;fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;) in main.o      int fmt::v9::detail::parse_header&lt;char, void fmt::v9::detail::vprintf&lt;char, fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;(fmt::v9::detail::buffer&lt;char&gt;&amp;, fmt::v9::basic_string_view&lt;char&gt;, fmt::v9::basic_format_args&lt;fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;)::&#x27;lambda&#x27;(int)&gt;(char const*&amp;, char const*, fmt::v9::basic_format_specs&lt;char&gt;&amp;, fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;int, 0&gt;(int) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;unsigned int, 0&gt;(unsigned int) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;long long, 0&gt;(long long) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;unsigned long long, 0&gt;(unsigned long long) in main.o      ...  &quot;fmt::v9::format_system_error(fmt::v9::detail::buffer&lt;char&gt;&amp;, int, char const*)&quot;, referenced from:      spdlog::spdlog_ex::spdlog_ex(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt;&gt; const&amp;, int) in main.o  &quot;fmt::v9::detail::assert_fail(char const*, int, char const*)&quot;, referenced from:      fmt::v9::detail::format_decimal_result&lt;char*&gt; fmt::v9::detail::format_decimal&lt;char, unsigned int&gt;(char*, unsigned int, int) in main.o      std::__1::make_unsigned&lt;long&gt;::type fmt::v9::detail::to_unsigned&lt;long&gt;(long) in main.o      fmt::v9::detail::format_decimal_result&lt;char*&gt; fmt::v9::detail::format_decimal&lt;char, unsigned long long&gt;(char*, unsigned long long, int) in main.o      fmt::v9::detail::format_decimal_result&lt;char*&gt; fmt::v9::detail::format_decimal&lt;char, unsigned __int128&gt;(char*, unsigned __int128, int) in main.o      std::__1::make_unsigned&lt;int&gt;::type fmt::v9::detail::to_unsigned&lt;int&gt;(int) in main.o      fmt::v9::appender fmt::v9::detail::write_exponent&lt;char, fmt::v9::appender&gt;(int, fmt::v9::appender) in main.o      int fmt::v9::detail::snprintf_float&lt;long double&gt;(long double, int, fmt::v9::detail::float_specs, fmt::v9::detail::buffer&lt;char&gt;&amp;) in main.o      ...  &quot;fmt::v9::detail::is_printable(unsigned int)&quot;, referenced from:      fmt::v9::detail::needs_escape(unsigned int) in main.o  &quot;char fmt::v9::detail::decimal_point_impl&lt;char&gt;(fmt::v9::detail::locale_ref)&quot;, referenced from:      char fmt::v9::detail::decimal_point&lt;char&gt;(fmt::v9::detail::locale_ref) in main.o  &quot;fmt::v9::detail::thousands_sep_result&lt;char&gt; fmt::v9::detail::thousands_sep_impl&lt;char&gt;(fmt::v9::detail::locale_ref)&quot;, referenced from:      fmt::v9::detail::thousands_sep_result&lt;char&gt; fmt::v9::detail::thousands_sep&lt;char&gt;(fmt::v9::detail::locale_ref) in main.o  &quot;fmt::v9::detail::throw_format_error(char const*)&quot;, referenced from:      fmt::v9::detail::error_handler::on_error(char const*) in main.o      fmt::v9::appender fmt::v9::detail::write_int_noinline&lt;char, fmt::v9::appender, unsigned int&gt;(fmt::v9::appender, fmt::v9::detail::write_int_arg&lt;unsigned int&gt;, fmt::v9::basic_format_specs&lt;char&gt; const&amp;, fmt::v9::detail::locale_ref) in main.o      fmt::v9::appender fmt::v9::detail::write&lt;char, fmt::v9::appender, long double, 0&gt;(fmt::v9::appender, long double, fmt::v9::basic_format_specs&lt;char&gt;, fmt::v9::detail::locale_ref) in main.o      fmt::v9::appender fmt::v9::detail::write&lt;char, fmt::v9::appender&gt;(fmt::v9::appender, char const*) in main.o      fmt::v9::detail::fill_t&lt;char&gt;::operator=(fmt::v9::basic_string_view&lt;char&gt;) in main.o      fmt::v9::appender fmt::v9::detail::write_int_noinline&lt;char, fmt::v9::appender, unsigned long long&gt;(fmt::v9::appender, fmt::v9::detail::write_int_arg&lt;unsigned long long&gt;, fmt::v9::basic_format_specs&lt;char&gt; const&amp;, fmt::v9::detail::locale_ref) in main.o      fmt::v9::appender fmt::v9::detail::write_int_noinline&lt;char, fmt::v9::appender, unsigned __int128&gt;(fmt::v9::appender, fmt::v9::detail::write_int_arg&lt;unsigned __int128&gt;, fmt::v9::basic_format_specs&lt;char&gt; const&amp;, fmt::v9::detail::locale_ref) in main.o      ...  &quot;fmt::v9::detail::dragonbox::decimal_fp&lt;double&gt; fmt::v9::detail::dragonbox::to_decimal&lt;double&gt;(double)&quot;, referenced from:      fmt::v9::appender fmt::v9::detail::write&lt;char, fmt::v9::appender, double, 0&gt;(fmt::v9::appender, double) in main.o      int fmt::v9::detail::format_float&lt;double&gt;(double, int, fmt::v9::detail::float_specs, fmt::v9::detail::buffer&lt;char&gt;&amp;) in main.o  &quot;fmt::v9::detail::dragonbox::decimal_fp&lt;float&gt; fmt::v9::detail::dragonbox::to_decimal&lt;float&gt;(float)&quot;, referenced from:      fmt::v9::appender fmt::v9::detail::write&lt;char, fmt::v9::appender, float, 0&gt;(fmt::v9::appender, float) in main.o      int fmt::v9::detail::format_float&lt;double&gt;(double, int, fmt::v9::detail::float_specs, fmt::v9::detail::buffer&lt;char&gt;&amp;) in main.o  &quot;fmt::v9::vformat(fmt::v9::basic_string_view&lt;char&gt;, fmt::v9::basic_format_args&lt;fmt::v9::basic_format_context&lt;fmt::v9::appender, char&gt;&gt;)&quot;, referenced from:      spdlog::logger::sink_it_(spdlog::details::log_msg const&amp;) in main.o      spdlog::sinks::daily_foldername_calculator::calc_foldername(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt;&gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt;&gt; const&amp;, tm const&amp;) in main.o      spdlog::sinks::daily_filename_calculator::calc_filename(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt;&gt; const&amp;, tm const&amp;) in main.o      spdlog::sinks::hourly_filename_calculator::calc_filename(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt;&gt; const&amp;, tm const&amp;) in main.o      spdlog::sinks::rotating_file_sink&lt;std::__1::mutex&gt;::calc_filename(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt;&gt; const&amp;, unsigned long) in main.o  &quot;typeinfo for fmt::v9::format_error&quot;, referenced from:      fmt::v9::detail::adjust_precision(int&amp;, int) in main.o      void fmt::v9::detail::vprintf&lt;char, fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;(fmt::v9::detail::buffer&lt;char&gt;&amp;, fmt::v9::basic_string_view&lt;char&gt;, fmt::v9::basic_format_args&lt;fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;) in main.o      int fmt::v9::detail::parse_header&lt;char, void fmt::v9::detail::vprintf&lt;char, fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;(fmt::v9::detail::buffer&lt;char&gt;&amp;, fmt::v9::basic_string_view&lt;char&gt;, fmt::v9::basic_format_args&lt;fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;&gt;)::&#x27;lambda&#x27;(int)&gt;(char const*&amp;, char const*, fmt::v9::basic_format_specs&lt;char&gt;&amp;, fmt::v9::basic_printf_context&lt;fmt::v9::appender, char&gt;) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;int, 0&gt;(int) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;unsigned int, 0&gt;(unsigned int) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;long long, 0&gt;(long long) in main.o      unsigned int fmt::v9::detail::printf_width_handler&lt;char&gt;::operator()&lt;unsigned long long, 0&gt;(unsigned long long) in main.o      ...  &quot;vtable for fmt::v9::format_error&quot;, referenced from:      fmt::v9::format_error::format_error(char const*) in main.o  NOTE: a missing vtable usually means the first non-inline virtual member function has no definition.ld: symbol(s) not found for architecture x86_64clang: error: linker command failed with exit code 1 (use -v to see invocation)make: *** [main] Error 1\nfmt 对应的代码是，这里的析构是有default实现的#if !FMT_MSC_VERSIONFMT_API FMT_FUNC format_error::~format_error() noexcept = default;#endif\n后面尝试了用 g++ &#x2F; clang++ 命令行直接编译没有问题clang++ -g -o main src/main.cpp -I./include -I./3rd --std=c++17\n放到xcode编译也没有问题\n网上查了些资料: -std&#x3D;libc++, -lstdc++ 但是都不行\n用 spdlog 的例子编译了下是没有问题的#include &quot;spdlog/spdlog.h&quot;int main() &#123;    spdlog::info(&quot;Welcome to spdlog!&quot;);    spdlog::error(&quot;Some error message with arg: &#123;&#125;&quot;, 1);        spdlog::warn(&quot;Easy padding in numbers like &#123;:08d&#125;&quot;, 12);    spdlog::critical(&quot;Support for int: &#123;0:d&#125;;  hex: &#123;0:x&#125;;  oct: &#123;0:o&#125;; bin: &#123;0:b&#125;&quot;, 42);    spdlog::info(&quot;Support for floats &#123;:03.2f&#125;&quot;, 1.23456);    spdlog::info(&quot;Positional args are &#123;1&#125; &#123;0&#125;..&quot;, &quot;too&quot;, &quot;supported&quot;);    spdlog::info(&quot;&#123;:&lt;30&#125;&quot;, &quot;left aligned&quot;);        spdlog::set_level(spdlog::level::debug); // Set global log level to debug    spdlog::debug(&quot;This message should be displayed..&quot;);            // change log pattern    spdlog::set_pattern(&quot;[%H:%M:%S %z] [%n] [%^---%L---%$] [thread %t] %v&quot;);        // Compile time log levels    // define SPDLOG_ACTIVE_LEVEL to desired level    SPDLOG_TRACE(&quot;Some trace message with param &#123;&#125;&quot;, 42);    SPDLOG_DEBUG(&quot;Some debug message&quot;);&#125;\n然后才发现我的头文件引入顺序上，c++相关的是放在前面的\n尝试调整了头文件的引入顺序就可以正常编译了#include &lt;spdlog/spdlog.h&gt;#include &lt;spdlog/async.h&gt;#include &lt;spdlog/fmt/bundled/printf.h&gt;...#include &lt;sstream&gt;#include &lt;memory&gt;#include &lt;utility&gt;#include &lt;filesystem&gt;\n怀疑是 spdlog&#x2F;fmt 有一些环境判定的宏相关的代码，但是在 .o -&gt; bin 的时候 .o 没有正确的包含，比如上面的 ~format_error() 的实现函数\n只是还没有完全弄清楚\n搭建了vscode开发环境，是开心的，希望自己继续写日志\n\n源码\nhttps://github.com/kinly/easy_logger\n\n","categories":["知识积累"],"tags":["记录"]},{"title":"c++ xlsx 解析 xlsxio 编译","url":"/archives/ef34a010.html","content":"pre\n之前用的 xlnt，编译很简单，功能支持很多，但是运行速度很慢，解析200行的xlsx需要超过10s\n我们仅需要xlsx的简单格式，减少转csv的步骤而已；就打算换个纯文本解析的xlsx库\n语言版本 c++11；看到两个库：xlsxio &amp; xlsx_drone （openXlsx 基于C++17，代码很工整但是我们用不了）\n\n比较xlsx_drone\nhttps://github.com/damian-m-g/xlsx_drone\n因为xlsxio相关的依赖没有在工程里，这个比较轻巧就先用了这个，但是后来发现一些cell解析不出来\n\nxlsxio\nhttps://github.com/brechtsanders/xlsxio\npython的解析应该也是用的这个库，C语言版本\n先用bin版本试了下，xlsx_drone 的问题这个库是没有的，就开始弄这个库的编译（static版本），记录一下是中间还是遇到一些坑点的\n\nxlsxio 编译下载\nxlsxio https://github.com/brechtsanders/xlsxio\nzlib https://github.com/madler/zlib\nexpat https://libexpat.github.io/\n\nzlib\n用的cmake，编译的 zlibstatic\nfind 一个 zconf.h 的文件拷贝到 zlib 头文件所在的目录\nminizip 新建了个工程，把 contrib\\minizip 的东西都加载进来，编译静态库使用\nminizip linux 写了个简单的makefile编译静态库project(minizip C)set(CMAKE_POSITION_INDEPENDENT_CODE ON)  // .a库会被.so引用add_library(minizip STATIC zip.c unzio.c mztools.c ioapi.c)\n\nexpat\n也是用的cmake，windows静态库编译简单\nlinux CMakeList.txt\n改了 set(_EXPAT_SHARED_LIBS_DEFAULT OFF)\n靠前面的位置加了 set(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\n\n(如果用的静态库，xlsxio library 编译时需要添加宏 XML_STATIC)\n\nxlsxio\n创建一个 3rd 的目录，把前面编译好的 libz.a, libminizip.a, libexpat.a 拷贝进来\nMakefile INCS 行 添加前面三个库头文件的位置 (minizip 只用到 contrib 这一级就好)\nMakefile LDFLAGS 行 添加 -L./3rd\nMakefile ZIPLIB_LDFLAGS 行 添加 -lz\nMakefile STATIC_CFLAGS 行 添加 -fPIC\n基本改了这些就可以正常编译了\n\nwindow 平台：\n遇到编译报错：\nerror LNK2019: unresolved external symbol __imp_...错误中的 __imp_ 前缀通常表示链接器期望动态库（.dll）版本的符号，但您可能链接了静态库（.lib 或 .a）。\nexpat 使用静态库：xlsxio library 编译时需要添加宏 XML_STATIC\n\nxlsxio 使用静态库：引入的执行文件工程 编译时需要添加宏 BUILD_XLSXIO_STATIC\n\n以下来自：chatgpt来自：chatgpt\n\n\nlibxls 编译xls 和 xlsx\n是两个东西，对于解析来说 xls是二进制的格式（解析代码也看到了大小端的处理），xlsx是基于xml的压缩格式\nxls 支持宏，这是当前需要支持这个版本的需求来源\n\n下载\nhttps://github.com/libxls/libxls/releases/tag/v1.6.2\n\n编译\ninstall 里的描述看 linux 编译很简单\n依赖项：sudo yum install autoconfig-archivesudo yum install gettext-devel\n按照文档说明执行：./bootstrap./configure CFLAGS=-fPIC CXXFLAGS=-fPIC --prefix=/xxx/libxls-1.6.2/install --enable-static=yesmake &amp; make install\nwindows 端想开个工程不用cygwin，报错看到少 config.h，这个是 configure 命令生成的文件；没敢冒险用 cygwin 把这个文件跑出来，其实这个文件和linux下的基本是一致的\n其他windows端的修改：\nxlstypes.h#ifdef _WIN32typedef int64_t ssize_t;#define strdup _strdup#endif\n注释掉了 xls2csv.c 的代码（win端没有getopt）\n指定工程编译 static library\n\n\n\n","categories":["代码"],"tags":["C++"]},{"title":"nginx openresty example","url":"/archives/8413b431.html","content":"nginx 相关备忘安装 openresty nginxyum install pcre-devel openssl-devel gcc curlwget https://openresty.org/download/openresty-1.21.4.1.tar.gztar -xvf openresty-1.21.4.1.tar.gzcd openresty-1.21.4.1./configure --prefix=/data/soft/openresty --with-luajit --with-http_iconv_module -j21gmake -j 4gmake install\n\n配置servicevim /usr/lib/systemd/system/openresty.service\n[Unit]Description=The OpenResty Application PlatformAfter=syslog.target network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/data/soft/openresty/nginx.pidExecStartPre=/data/soft/openresty/nginx/sbin/nginx -tExecStart=/data/soft/openresty/nginx/sbin/nginxExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target\n\n\n之后的操作命令：systemctl start|stop|restart|reload openresty\n报错systemd[1]: PID file /data/soft/openresty/nginx.pid not readable (yet?) after start. 可能是 service 配置的 PIDFile 和 nginx.conf 的不一样，或者是 nginx.conf 用的用户没有示例 &#x2F;data&#x2F;soft&#x2F;openresty 的读写权限\n\n配置nginx.conf\n需要注意 user 配置，需要确认这个用户的权限\n需要注意 pid 配置，需要和 service 配置一致user  root;worker_processes auto;worker_rlimit_nofile 102400;error_log  logs/error.log ;pid   /data/soft/openresty/nginx.pid;\n\n示例：pay 路由\npay.route.conf示例展示用 pay.route.lua 里的规则重置 ngx.proxy，然后代理到对应处理里面需要用 rewrite_by_lua/rewrite_by_lua_file 重写 ngx.proxy 需要注意这里的相对路径是从 /data/soft/openresty/nginx 开始的server &#123;    listen 8080;    location / &#123;        limit_except POST &#123; deny all; &#125;        set $proxy &quot;&quot;;        rewrite_by_lua_file conf/vhosts/pay.route.lua;        proxy_pass http://$proxy$uri;    &#125;&#125;server &#123;    listen 3000;    location = /pay &#123;        client_max_body_size 50k;        client_body_buffer_size 50k;        content_by_lua_block &#123;            ngx.say(&quot;3000....&quot;)            ngx.exit(200)        &#125;    &#125;&#125;server &#123;    listen 3001;    location = /pay &#123;        client_max_body_size 50k;        client_body_buffer_size 50k;        content_by_lua_block &#123;            ngx.say(&quot;3001....&quot;)            ngx.exit(200)        &#125;    &#125;&#125;server &#123;    listen 3002;    location = / &#123;        client_max_body_size 50k;        client_body_buffer_size 50k;        content_by_lua_block &#123;            ngx.say(&quot;error&quot;)            ngx.exit(400)        &#125;    &#125;&#125;\npay.route.lua-- pay routelocal default_proxy = &quot;127.0.0.1:3002&quot;local route_proxy_config = &#123;    [&quot;1012&quot;] = &quot;127.0.0.1:3000&quot;,    [&quot;1016&quot;] = &quot;127.0.0.1:3001&quot;,    [&quot;1018&quot;] = &quot;127.0.0.1:3002&quot;,&#125;;local area_args_key = &quot;ext&quot;local area_index = 2-- route_proxylocal route_proxy = default_proxyngx.req.read_body()local args, err = ngx.req.get_post_args()if args[area_args_key] then    local index = 1    for area in string.gmatch(args[area_args_key], &quot;[^|]+&quot;) do        if index == area_index then            if route_proxy_config[area] ~= nil then                route_proxy = route_proxy_config[area]                break            end        end        index = index + 1    endendngx.var.proxy = route_proxy\n\n","categories":["linux"],"tags":["linux"]},{"title":"判断某个点是否在矩形范围内","url":"/archives/ab5d3c6d.html","content":"pre\n一个业务需求，45°俯视角的游戏场景如果用正方向矩形拉范围视觉上是个菱形\n这时候需要用到45°矩形\n\n判断某个点是否在矩形内struct point &#123;    int x = -1;    int y = -1;&#125;;\n正方向矩形\n需要2个point: left_top 和 right_down\n只需要检查目标点 ptpt.x &gt;= left_top.x &amp;&amp; pt.y &gt;= left_top.y    &amp;&amp; pt.x &lt;= right_down.x &amp;&amp; pt.y &lt;= right_down.y\n\n方向矩形\nhttps://math.stackexchange.com/questions/190111/how-to-check-if-a-point-is-inside-a-rectangle/190373#190373\n靠前的回答：M of coordinates (x,y) is inside the rectangle iff(0 &lt; AM ⋅ AB &lt; AB ⋅ AB) ∧ (0 &lt; AM ⋅ AD &lt; AD ⋅ AD)(scalar products of vectors, ∧ stands for logical AND).\n\n画图理解：\n假设是正方向的矩形\n\n贯穿全文的公式：\n\n向量 a ⋅ b = |a|*|b|*cos(角度)\n\n\ncos(角度) 对应值：\n\n公式里两个 &gt; 0 的是由 cos 的正负决定的\n\nAM ⋅ AB &gt;= 0 表示点在 y 轴左边 （1,2象限）\nAM ⋅ AD &gt;= 0 表示点在 x 轴上面 （1,3象限）  \n重合的就是 1 象限\n\n\nAM ⋅ AB &lt; AB ⋅ AB:\n\nAM ⋅ AB = |AM| |AB| cos(角度)\nAB ⋅ AB = |AB| |AB| cos(0) = |AB| |AB|\n|AM| |AB| cos(角度) &lt; |AB| |AB| cos(0) 得出\n|AM| cos(角度) &lt; |AB|\n\n\n\n    - 图里 A 代表 AM, B 代表 AB\n\n\nAM ⋅ AD &lt; AD ⋅ AD 同理\n\n参考\nhttps://www.jianshu.com/p/bde70668b1bc\nhttps://math.stackexchange.com/questions/190111/how-to-check-if-a-point-is-inside-a-rectangle/190373#190373\nhttps://stackoverflow.com/questions/2752725/finding-whether-a-point-lies-inside-a-rectangle-or-not\nhttps://en.wikipedia.org/wiki/Dot_product\n\n","categories":["模块"],"tags":["游戏"]},{"title":"可执行的全球服设计","url":"/archives/b8b38dba.html","content":"整体架构\n依赖缓存服务器 redis\n依赖高性能存储 MongoDB\n依赖消息队列 message-queue\n战斗服务器外都是无状态服务\n战斗服仅内存，数据修改通过message-queue同步到无状态逻辑服务器处理\n\n\n登录流程\n依赖中心节点（accout的唯一性）\n\n\n匹配战斗\n缓存、数据库对战斗服不可见\n匹配、战斗依赖数据加密后由客户端转发到服务\n\n\n","categories":["架构"],"tags":["游戏"]},{"title":"游戏服务端经验法则","url":"/archives/9d84ce3f.html","content":"pre\n我是个游戏服务端开发。刚出校门就进入了游戏行业，一直觉得没有学满和对不熟悉行业谨小的性格让自己困在这个行业。\n过往的主要使用的语言是c++，也有两款游戏使用java。重要的节点是九城、盛大、网易，都很深刻。\n一直在一线工作，最开始的做业务，到独立负责模块，再到后来做架构、设计，现在做重构，一直都在写代码\n没有结婚、很少的恋爱经历，过往大部分时间都在工作里，近几年才坚决的想逃避996，也更多的自怨自艾。\n我喜欢开发游戏这件事情，是不是是喜欢的游戏倒还好，我不喜欢当前环境做游戏的这帮人；可谨慎的性格随着年龄上涨越来越严重，也不敢说浪费金钱、健康去押宝理想；在悖论里\n也是近几年，开始在git上整理记录一些东西，上传一些代码片段。\n上述没有太多意义，但觉得出现在这里并不突兀，在时间、荷尔蒙溜走的重复里，想逃掉。\n下面是一些经验的备忘、认为，毕竟很多知识系统都很庞大，关联、影响，记录的完整、正确比简单逐条的备忘、经验复杂的多，轻松一点\n\n自己 · 羡慕新一代有更好的环境资源\n开这么个tag，今天看综艺，2个小时看了6期，只看了傻白的主唱和蒲羽，反复听蒲羽雾也至的送别（脑补原词部分更清澈的慢一点更上头\n当前公司是内外网隔离的两台办公机器，一直没觉得会融入团队或者想要融入团队就任性的根据工作需要做自己的事情，团队里只给一个小朋友分享了博客的链接，像蒲羽说的，我羡慕小朋友经历的学生时代有比我当时好太多的环境，上大学之前基本只有高中在网吧摸过电脑打游戏\n当前工作上想实现的东西会有私心的先在外网搭个框架再挪到内网用，可是最近做的时间基类不想麻烦套过去了，没人看，没人用，可能之后的也不会了；也想到自己不是理想中有开源精神的人；需要对手或者观众，即使做的东西是个很应用层的东西\n蒲羽 送别.雾也到达世界 太好了，现场可能会止不住流眼泪，上次是万青现场，秦皇岛，忍着不被看到，旁边是喜欢的女生\n我一直认为技术应该是精致的，当前觉得这种想法不太对，或者说因为太过完美主义不太对；毕竟一直工作在应用层，需求导向\n追求新的技术不是完全是精致的样子，更多是相信技术的演化应该可以让在应用层的我们工作的更轻松，不过当下所处的环境真实发生的和这个理解是相反的，被引入的新的问题被认为是新的技术导致的，限制使用比指导使用轻松的多；\n我个人的认识，基础知识是很重要的，计算机于我已经是个复杂的体系，需要严密的逻辑，这些支撑我发挥创造、基于开源的超越，我是个工匠，想轻松应对赚钱这件事情，有时间和空间看的更多\n这是个应该被反思的问题，计算机没有宇宙的探索浪漫，可对应用者一样是有想象、创造的学科，而且基于经验和实践，应该能让我们更轻松构建上层世界\n经验更多是试错积累的，通过别人的文档看别人得到的经验或者自己积累的经验；可是如果所处不被认为想要成为、构建一个新时代，试错往往不会被接受\n遗憾还没有参与到过理想的环境，也还没有能力、勇气、机会构建理想环境，被推着走，只是希望自己去想、尝试、记录更多东西，如果有机会有更多准备，虽然这个过程可能进度很慢\n\n语言 · 箱子里的工具总是不够用，但箱子里拿出来的应该用的趁手\n我自己的主语言是C++，因为做了不少项目，未来的C++也值得期待\n也用Java做过2款休闲游戏，当时主要的考虑是团队技术栈，选型的时候综合考虑团队是否能cover住语言、中间件、组件等，在出问题的时候可以解决掉问题是必须的\n游戏停服一次丢一半玩家的常识让 C++&#x2F;go + lua 的组合变得流行，不过做过无状态的服务之后觉得当前的手游如果不是强mmo的那种样子，战斗服以外的服务使用无状态方式更合适\n在处理简单（偏向解析类）工作的时候，以前最多考虑的是用shell bash，常见的日志解析还是一行shell最简单，其他稍复杂的会选择用python，例如之前用python处理excel配置数据-&gt;定制的json\n一些场景下也选择用 node.js，一些并发场景，例如解析代码文件生成markdown的接口文档\n除了GC，Java和C++一个很大的区别是反射，当然这算是个功能\n\n设计 · 追求精致，接受不完美进程、服务网络\ntcp 相比 udp（rudp）使用重度的多\n游戏更多是REQ&#x2F;ACK模型，有序的一来一回，使用任何 rudp 都建议考虑单条消息payload的大小，尽量不要超过 1kbytes(1KB) 或者尽量更小，不然因为丢包造成一条消息总是收不完整造成的用户体验会很差；\nkcp：原理、部分测试（我一直认为网上的测试覆盖并不完整）比TCP更快，但没有用拨测的方式覆盖时间、地区测量之前，我都对他持谨慎态度\n网络拥挤的时候，运营商会选择先丢弃udp包\nBBR 是很有必要做尝试的选择，之前测试过BBR比CUBIC在弱网环境处理包的能力高很多，而且BBR是只在服务端开启就可以得到明显的提升\n对于HTTP的协议，之前上过cloudflare的代理，IOS在目标地址支持QUIC的情况下会选择HTTP3的通讯方式，虽然还没有实际使用过QUIC，不过当前看也是未来打有可能更多应用的方向\nrpc\ntodo: 超时: 服务间通讯的小概率网络问题\n\n\n\n数据、对象对象模型\n相比近些年热度很高的ecs模型，我更习惯继承链的方式，可能对我来说继承链是更严格的样子\n功能上多继承、数据成员方式上如果是 java 更常用多继承，c++ 倒没有特别的倾向；更多的是如果这个东西很小又想要独立出来会使用多继承，相反如果很复杂，有较多的数据成员的模块，会倾向作为对象的数据成员使用\n\n数据处理\ntodo: 等幂性：\ntodo: 乐观锁:\nC11 基础上越来越多的 non-lock, less-lock 内容（std::atomic内存屏障基础上实现），但我还不是个有足够经验、测试用例去实现、验证一个无锁的功能，所以还是习惯用这种方式：class non_lock final &#123;public:    void lock() &#123;&#125;    void unlock() &#123;&#125;&#125;;template&lt;typename _Lock = non_lock&gt;class entity_pool &#123;    // anything....&#125;;entity_pool new_handle() &#123;    return entity_pool&lt;non_lock&gt;::instance().new_handle(ptr);&#125;entity_pool new_handle_mt() &#123;    return entity_pool&lt;std::mutex&gt;::instance().new_handle(ptr);&#125;\n\n容器\n容器是离不开的东西\nstd::vector 基本是第一选择\n指针还是栈对象？因为vector是连续的内存空间，空间不够会开辟新的空间，把老的内容拷贝到新的空间，拷贝对于指针来说只是8字节，栈对象基本都更大，但是习惯上还是更常使用栈对象方式，用reserve&#x2F;resize避免拷贝的情况\nreserve: 如果是常驻容器，会动态增长并且不能确定增长频次、上限的情况下可以不做这个，用系统默认的2倍方式；因为是常驻的，认为运行一段时间之后基本不会在有重新开辟空间的情况。特别在意内存占用除外；或者考虑选择 std::list&#x2F;deque&#x2F;queue；如果是临时的，尽量做reserve（虽然经常遗漏）\nresize: 明确长度的时候使用，或者使用c++11的 std::array\n\n\nstd::list 一般在动态缓存场景使用，比如lru_cache\nstd::queue&#x2F;deque 明确一端插入一端取出的场景，比如thread_pool’s task\nstd::stack 明确先进后出的场景，比如依次打开界面，而后以后打开的界面先关闭的顺序关闭界面\nstd::set&#x2F;unordered_set 数据有唯一性的，unordered比non-unordered占用更多的空间，不在意这个占用优先选择 unordered_set，忽略hash本身的消耗\nstd::map&#x2F;unordered_map 键值对\nstruct hash 实现上优先选择 std::hash\nmulti 的容器很少用~\n一些不错的图片：\nhttps://belaycpp.com/2022/02/02/i-dont-know-which-container-to-use-and-at-this-point-im-too-afraid-to-ask/    \n\nhttps://hackingcpp.com/cpp/cheat_sheets.html#hfold3a    \n\n\n\nemplace&#x2F;push\n写法上：  struct move_test &#123;    std::string _non_used = &quot;1&quot;;    int _number = 2;    move_test(std::string&amp;&amp;, int n) : _number(n) &#123;        std::cout &lt;&lt; &quot;construct :&quot; &lt;&lt; _number &lt;&lt; std::endl;    &#125;&#125;;// teststd::vector&lt;move_test&gt; vec;vec.push_back(&#123; &quot;10&quot;, 1 &#125;);vec.emplace_back(&quot;10&quot;, 2);\n\n\nmove&#x2F;copy constructor: https://stackoverflow.com/questions/64378721/what-is-the-difference-between-the-copy-constructor-and-move-constructor-in-c\n\n存储\n这里一般是指存储玩家数据\n游戏回放数据一般不会有很严格的实时要求，但会有被广播观看需求，认为以文件形式存储以方便同步到cdn更重要\n抛弃掉传统架构的 db_server, 我更倾向的组合是 redis + mongodb，对应无状态的架构方式\nmysql&#x2F;mongodb, redis, leveldb 这些是过往用到比较多也很有代表性的三种数据存储（缓存）；\nmysql 传统的、关系型\n游戏更常靠一个玩家一行数据，数据块序列化后存储在 blob 里面，很少会用到事务相关的东西\n依赖 binlog 的时间点回档也是选择 mysql 一个重要的选项\n\n\nmongodb 集群式的、非关系型\n当时使用 mongodb 有语言（java）的关系\nmongodb 的 bson 和 json 格式基本一致，数据展示上比 blob 方便太多\nnosql 的特性也使得扩展变得很容易\n如果选择的是云商的PaSS服务，没有很特别的集群需求，standalone 永远是首选\n集群的 mongo 因为 mongoS、mongoC 的方式，效率比单点低\n集群需要考虑清楚使用什么样的分片规则\n当然价钱也是很重要的一个方面\n\n\nredis 缓存（集群、单点）\n集群：一般作为数据存储，游戏是个读多写少的场景（MMO常见的做法是使用进程的内存），redis在架构图上一般被画在Hard_DB之前，也表述了redis主要作用是减轻DB读取的压力\n单点：在成本考虑上也经常被用于数据存储，之前就有游戏前期考虑并发压力使用集群方式，后期数据下滑换成了单点\n单点：还有场景是需要使用lua完成一些复杂、原子的操作\n读取策略：先从redis读，读不到从DB读，并写入redis\n写入策略：先写DB，成功后更新redis，失败删除redis数据（数据一致性）\nexpire：原则上任何数据都需要设置过期时间（一般2小时），游戏这种数据由热数据变成冷数据基本是玩家的行为；这里对于访问特别频繁、并发量可能很大的数据，过期时间需要加随机值，避免同时过期造成的雪崩\n\n\nlevelDB：需要本地存储场景很合适，也是我的首选\nmysql、mongodb 在数据上用序列化的名词解释，mysql有idl类似protobuf，mongodb没有idl类似json，虽然mongodb会有更多的带宽消耗，不过一般在部署上都是和服务在同一内网区域，带宽的影响可以忽略\nclickhouse 列式数据库，在处理关联查询上相比行式数据库需要读取的数据量更小，优势明显，未来有机会考虑在 event log 这类场景使用这个数据库\n\n\n进程内存存储和以上存储方式最显著的区别是：进程内存是对象数据(反序列化后的数据)，后者取出来的数据都是需要经过反序列才好再序列化成消息数据给到客户端；一些离线数据场景，也可以直接存储需要给到客户端消息的序列化后的数据在redis&#x2F;db；具体需要看应用场景；考虑是否需要进程对象的（反序列后）lru\n\n事务ACID\nAtomicity 原子\n对数据的所有更改都像单个操作一样执行。也就是说，要么执行所有更改，要么不执行任何更改。例如，在将资金从一个帐户转移到另一个帐户的应用程序中，原子性属性可确保如果从一个帐户成功借记，则相应的贷记将记入另一个帐户。\n\n\nConsistency 一致\n当事务开始和结束时，数据处于一致状态。例如，在将资金从一个帐户转移到另一个帐户的应用程序中，一致性属性可确保两个帐户中的资金总价值在每次交易开始和结束时相同。\n\n\nIsolation 隔离\n一个事务的中间状态对于其他事务是不可见的。因此，并发运行的事务看起来是串行化的。例如，在将资金从一个帐户转移到另一个帐户的应用程序中，隔离属性可确保另一笔交易在一个帐户或另一个帐户中看到转移的资金，但不能在两个帐户中看到转移的资金，也不能在两个帐户中都看到转移的资金。\n\n\nDurability 可用\n事务成功完成后，即使发生系统故障，数据更改也会持续存在并且不会撤消。例如，在将资金从一个帐户转移到另一个帐户的应用程序中，持久性属性可确保对每个帐户所做的更改不会被撤销。\n\n\n\n测试\n安全工具windows&#x2F;桌面系统\nwireshark、fiddler 查看网络、数据包问题，对于手机端，需要一个移动wifi，只能在电脑上抓包\nprocexp、tcpview 已经是必然被放在开始菜单自定义组的工具了，分别对应查看进程信息、链接情况\npostman http消息测试，现在也支持websocket了\nterminal: tabby 可以分屏是我比较关注的功能\n\nlinux&#x2F;命令行\nhtop\ntcpdump\nnc\n临时监听端口：nc -l 51300. 客户端有链接断开后，监听端也会跟着关闭\n监听端口：nc -lk 51300. 客户端有链接断开后，监听端不会关闭\n\n\ntc\n\n运维负载\npre: 大区的游戏越来越多了，或者说混服的玩法越来越多了；过去分区一方面是技术上大区很麻烦，一方面是避免晚来的玩家输在起跑线太多；然后游戏一直在开区、滚服、合服。平台开发基本都是分布式的部署，负载均衡是个很重要的名词\n物理机：机房多活（反亲和）：部署选机器的时候需要避免机器在同一机房，免得机房整体故障\n如果机房间网络链路优化的不好，多了几次路由、交换机这样的跳转点设备，会导致高并发量下，内部网络转发有一定的差距（没实测过）游戏的场景不太考虑这个问题，并发量远没有达到\n\n\n域名：DNS 负载：在dns上给一个域名映射多个ip，用轮询、随机、负载、区域解析等条件负载到不同ip；之前游戏在全球部署，尝试使用公司内部dns区域解析的负载方式，但是测试结果不好经常判断错误；\nlvs&#x2F;haproxy&#x2F;nginx 网络负载、代理：这种是开发接触最多的部分了；经常用到的：\nha tcp层的端口映射，8001端口映射转发到 10.1.2.100:8000 端口，8002到 10.1.2.101:8000 端口；\nnginx：可以做很多规则，到不同服务、不同进程，卸载tls….需要提前设计利用好 http header\n\n\n进程、服务内部的负载：上面一些负载策略一般都比较简单，着重在转发需求上，服务内部的负载则比较多考虑服务当前的业务压力，比如当前多少玩家在这个进程上；多数由注册发现进程统计、记录服务负载信息（类似zookeeper、eureka…）比如匹配服务匹配完成需要找一个可用的负载相对较低的战斗服把玩家信息给过去\n\n部署：网络、业务、数据分离\n网络分离比较容易理解，不想服务所在的宿主机对外暴露，透明的网络层加规则也更方便内部负载扩容，比如nginx\n如果是带tls的需求，对外的服务需要载入证书卸载tls（比如常用的nginx），而内部服务一般不需要tls（比如mysql需要一般都会关闭tls）\n业务服务器是最容易出问题（资源耗尽、crash、无响应）\n数据分离一个是因为数据部分的服务器不能对外（相对网络）、需要稳定（相对业务），另一个原因是数据服务器（mysql、mongodb）这种一般需要禁用 transparent_hugepage (THP)\nTHP 是linux为了提高内存分配效率的东西，一般 1 page = 2M，系统分配内存是先分配虚拟内存地址，需要使用的时候发现没有映射物理内存，内核触发 page fault 分配物理内存，普通页大小是 4k；1G 虚拟内存以 4K 分配的时候需要 1G / 4K = 256 * 1024 次；如果是 THP 的 2M 页只需要 1G / 2M = 500 次 page fault 以此得到更高的效率；但是对于数据库这种访问分散的数据，一次分配 2M 会造成大量的内存碎片，比如mongoDB 官网表示建议禁止 THP；mongo 官网解释的更直接，也给了禁用的方法； 这个是 mongoDB 宿主机设置的另一个建议  $ cat /proc/meminfo | grep -i &#x27;hugepage&#x27;HugePages_Total:       0              -- 分配了多少页HugePages_Free:        0              -- 空闲多少页HugePages_Rsvd:        0HugePages_Surp:        0Hugepagesize:       2048 kB           -- 一页多大\n\n\n\n问题分析\n遇事不要慌，能保留现场先保留现场\n不能保留现场的先记录时间点、备份当时的监控、core、log等可以帮助分析问题的信息\n有需要的话能重启先重启，重启前需要判断是否需要回档等，需要回档的话先拉维护，把流量切走\n问题已经出了，不要焦虑，确定问题解决问题才是重点\n\n\n运营迭代管理\n像简介里说的，我一直在写代码，管理上其实没太多经验；\n\n没有尝试、实践、验证过的东西都是不确定、怀疑的态度，经常忽略方法论\n\n之前领导明确指出过需要关注方法论的问题，可能我的学习过程总习惯有面镜子参考，之前的同事也都是实战的样子，这个点一直没有做好\n\n当前的工作中看到一个很注重方法论的同事，也正在强迫自己学习这个点；用强迫是因为可能他已经确定了自己是朝着管理方向走的，太多只关注方法论可在实际写代码上拉下太多了，这个样子又让我觉得不应该，就在我需要学习和以此为耻之间反复横跳\n\n只关注方法论问题很明显，\n\n比如知道想要提高性能可以做缓存，可实现上release的时候把可复用的数值（比如object uuid）缓存了，get的时候却没有先从缓存拿，导致缓存暴涨；\n再比如我这边做的一些重构核心代码、关键点上都有注释说明，重构过程中的思路、问题点最后会整理成文档放在wiki上，可是同事更倾向直接问为什么这么做，我的内心（代码文档都在你会自己看的么….），好像他只关心这个东西如果换他跟别人讲应该怎么讲，一个只是讲方法论的问题\n并且听完思路表示和他设想的是差不多的，我的内心（那倒是实现掉呀….）\n这位有很强方法论的同事不是我认为好的样子，剥离开只关注他好的地方也容易被日常零碎的事情影响着不想变成这样子\n\n\n不过计算机是一个既定模式的学科，非0既1，不像生物、物理；而且工作只是在应用层，不像芯片制造那种开发需要基础设计、制造的理论；总的来说其实是个简单的东西，我不是个特别有天赋的人，只能勤补拙\n\n这样子看其实我需要的可能是相信自己基于基础知识的推断，在架构设计上抓住需要解决问题的重点，不过分在没有实践验证、不够完善这些问题上慌张，更多的时间用来扩宽视野，用新的技术解决新的问题\n\n之前晋升答辩，架构设计上注册发现是个单点，因为觉得是个很简单轻量的服务，没想着做成高可用的，可是答辩被老师问到楞在怀疑挂掉重启这个操作是不够的，一下子就不自信了（设计上做了挂掉也不影响其他服务正常运行的样子），这个场景记忆深刻；\n\n还是那次答辩，在业务贡献和技术深度两个大方向上选了技术深度，主要的内容基本只在一个技术点上，领导一直觉得需要多加点内容，即使不是我负责的内容，怯懦也实诚的性格没有加更多的东西，答辩被问细节到用了多大mtu，庆幸也只有是自己实际做的才会关注着这个细节\n\n这些好像和管理并没有太多关系，也还确实没有太多管理的内容记录\n\n游戏开发的工作内容和制造业的定件很像，需求可以被明确到结果的样子，经历了这么多年也几乎没有不可被实现的需求（即便优化不下来的面片也有硬件的更新承载）\n\n当前是996的状态，受《重来1、3》这本书和其他可能很多方面可能有成熟却越来越没有激情、身体相比没有10年前的活力的影响，抗拒又无能为力当前的状态，自上传导一个理念比自下向上传导要容易得多，当下所处的环境确实是这样的，我没有信心把我认为好的管理想法传导到上级，索性就被动的被推着走；想到已故的左耳朵耗子，致敬\n\n游戏是一个大众产品，和绝大多数工业产品一样明确的分工可以让人专注、发挥所长，明确职责搭建完整产品；我相信每个人都有产品思维，严谨思考更多受态度影响，这可以弥补可能不好改动的设计上的不足；比如一个商店售卖功能，遇到问题发现需要检查客户端输入的购买数量是否合法\n\nA同学：找到对应位置，添加if语句\nB同学：联想到是否开宝箱等批量使用物品的功能也有类似问题，检查、修改相关代码\nC同学：对于客户端输入的地方都不能信任，数值是最容易越界的地方，考虑在协议层加一个通用的数值类型，根据不同的功能注册策略函数检查这种数值类型，覆盖数值、数值运算等可能越界情况\n\n\nB同学已经是一个积极看待问题的样子了，如果团队里大部分都可以做到这个样子，这个产品在技术层面不会出现太多太严重的问题；保持积极多思考的样子，之后也会用更完善的设计来提前避免这类问题\n\n我相信即便是刚入行的程序，明白具体原因都会发散考虑到其他类似场景；可是当前看到的大都是A同学，甚至下次写的时候还是会有相同的问题\n\n开发人员停止思考，边缘化技术能力的价值，像是拿着不再打磨而锈迹斑驳的凿刀，像是用灰黄的泥土修补破损的玻璃雕像\n\n\n重复、繁重工作让人觉得工作只是工作这件事情？那么看到新的技术、设计，完成、优化了一个小东西会兴奋一下么？\n\n\n\n发觉技术的迭代并不能解决自己朝10晚10的状态，干脆得过且过？\n\n\n\n不一致的想法却无能为力的样子放弃了对项目的想象和热爱？\n\n\n\n看到抄捷径、卷加班还没有摔跤甚至得到更多糖果时，是想也这么做还是放弃挣扎了呢？\n\n\n\n或者阴差阳错选错了行业？\n\n\n\n还有什么让你觉得不适合、甚至厌恶了当前的工作甚至这个行业？\n\n\n这是否是人们对经历的当下丧失或者抗拒了敏感，为什么会这样？如果我是一个管理者，会探究这个问题\n\n我理解产品和代码是两回事，也许作为一个管理者在商业的思维下探究的是产品，可作为一个技术管理者需要完全丢弃技术价值才能实现产品理想的探究么？\n\n摘自：https://mp.weixin.qq.com/s/HoFSNCd1U3eoUqYaQiEgwQ\n\n\n谚语曰: “Talk Is Cheap, Show Me The Code”。知易行难，知行合一难。嘴里要讲出来总是轻松，把别人讲过的话记住，组织一下语言，再讲出来，很容易。设计理念你可能道听途说了一些，以为自己掌握了，但是你会做么？有能力去思考、改进自己当前的实践方式和实践中的代码细节么？不客气地说，很多人仅仅是知道并且认同了某个设计理念，进而产生了一种虚假的安心感——自己的技术并不差。但是他根本没有去实践这些设计理念，甚至根本实践不了这些设计理念，从结果来说，他懂不懂这些道理&#x2F;理念，有什么差别？变成了自欺欺人。\n\n\n\n\n重构 · 习惯的东西更得心应手，也是禁锢自己的枷锁过往基本上都是自己在做事情，从0-1的做，review别人的代码也更多的是看一些完整、规范、细节等；这份工作才真正意义上重构一份代码；到目前为止2023.01-2023.08主要重构了场景、aoi、对象继承关系、对象管理、背包、定时器；记录一些可执行的实践\n\n先要了解这是个什么类型的游戏，有那些过往经验是可以参考的；比如当前这款是2D MMO，于我参考的比较多的是之前做端游的经验\n看下过往代码的问题，构想好重构后是什么样子的，解决了什么问题（代码很乱也是很严重的问题）；比如之前的背包操作，添加一个物品有10几种函数实现，扣除等比量，很多实现看起来严格的写法（开宝箱）是先遍历检查物品够不够-&gt;检查背包剩余格子够不够-&gt;遍历扣除-&gt;遍历添加，大段大段类似的代码，重构目标很清楚: 用事务的方式操作背包，操作失败回滚就是，成功了最后commit，commit是void返回值的调用。\n捡自己更好cover住的方式：对象模型上，ecs的模型近些年很流行，但是我更熟悉继承方式，而且对于MMO也还是觉得继承方式的对象在场景里处理更直接\n我也热衷追求、使用新的技术，互联网是个瞬息万变的行业，业务推进技术的迭代、演进、革新，遇到新的问题，应该尝试研究、引入新的技术去解决问题，如果一味用老的技术或者架构无法支撑技术的演进，那么这个团队、架构应该是有问题的\n具体操作上：\n简化日志 friend std::ostream&amp; operator &lt;&lt; (std::ostream&amp; os, xxx* so)，日志是重构过程中很重要的一个点，做好简化，区分级别，先多记录日志\n简化判定  #define MAP_ASSERT_RETURN(expr, ret, ...) if (!(expr)) &#123;LOGE() &lt;&lt; &quot;MAP_ASSERT_RETURN. &quot; &lt;&lt; #expr &lt;&lt; &quot;. &quot; &lt;&lt; _VA_ARGS__; return ret; &#125;#define MAP_ASSERT_BREAK(expr, ret, ...) if (!(expr)) &#123;LOGE() &lt;&lt; &quot;MAP_ASSERT_RETURN. &quot; &lt;&lt; #expr &lt;&lt; &quot;. &quot; &lt;&lt; _VA_ARGS__; break; &#125;#define MAP_ASSERT_CONTINUE(expr, ret, ...) if (!(expr)) &#123;LOGE() &lt;&lt; &quot;MAP_ASSERT_RETURN. &quot; &lt;&lt; #expr &lt;&lt; &quot;. &quot; &lt;&lt; _VA_ARGS__; continue; &#125;#define MAP_ASSERT_MESSAGE(expr, ret, ...) if (!(expr)) &#123;LOGE() &lt;&lt; &quot;MAP_ASSERT_RETURN. &quot; &lt;&lt; #expr &lt;&lt; &quot;. &quot; &lt;&lt; _VA_ARGS__; &#125;\n明确好名词，并严格按照这个名词规则来\n地图 -&gt; map\n场景 -&gt; scene\n配置id -&gt; meta_id\n唯一id -&gt; uuid\n\n\n用命名空间、用 using rename，一方面可以很直接找到重构用的代码，另外在重构过程中发现数据类型定的不合适还方便修改  namespace map_v2 &#123;    using map_meta_id = uint32_t;    using map_uuid    = uint64_t;    static constexpr map_meta_id invalid_meta_id = 0;&#125;; // end namespace map_v2\n合并原有相同作用的函数，一起替换\n多用 explicit、final、const、enum class 等带有限定作用的关键字，多让编译器就检查出问题（平时编码也该如此）\n\n\n命名上，不喜欢带数据类型的命名方式 m_dwID -&gt; m_id（换数据类型更轻松，auto一样），相比驼峰更喜欢下划线 m_metaId 也可以是 m_metaID 那不如用 m_meta_id\n很可能遇到重构过程中，改完之前无法测试的情况，耐心、耐心\n用好 git，diff 工具，很方便\n\n中间件\nlb&#x2F;lvs&#x2F;nginx\n\nmessage queue\n\n没有MQ\n有MQ\n\n\nredis（常用的用途）\n\n\n杂乱的零件static variable\nhttps://stackoverflow.com/questions/3837490/initializing-a-static-variable-in-header\n\n\n头文件有一个static global variable数据的生命，2个引用头文件的地方将产生2个数据副本；\n用c++的方式解决办法是放到类的成员函数里，作为成员函数的局部变量\nC++11 magic static thread-safe 之后，static 使用越来越多（https://blog.mbedded.ninja/programming/languages/c-plus-plus/magic-statics）这个问题比较容易被踩到；理解原因的同时换种方式，习惯性加上namespace，习惯性把class作为namespace的空间域\n\nclass test &#123;    static std::map&lt;int, int&gt;&amp; __inner_variable() &#123;        static std::map&lt;int, int&gt; result;        return result;    &#125;&#125;;\n\nstd::this_thread::sleep_for\nwindows 和 linux 不一样：https://github.com/gabime/spdlog/issues/609\n\nstd::min&#x2F;max; #define min&#x2F;max 冲突:\nhttps://stackoverflow.com/questions/13416418/define-nominmax-using-stdmin-max\n\n\nvisual studio pre-define 添加 NOMINMAX\n或者在 include win 头文件之前#ifndef NOMINMAX#    undef min#    undef max#endif\n\ntemplate 问题\n使用 luaBridge 的时候遇到一个问题，大意是这样:\n\nclass super_cls &#123;public:    void super_function() &#123;        std::cout &lt;&lt; &quot;xyz&quot; &lt;&lt; std::endl;    &#125;&#125;;class sub_cls : public super_cls &#123;&#125;;// test codelua_bridge    .deriveClass&lt;sub_cls, super_cls&gt;(&quot;sub_cls&quot;)        .addFunction(&quot;super_func&quot;, &amp;sub_cls::super_function)    .endClass()    ;\n\n\n这里编译会报错：no matching function for call to addFunction....\n解决办法很简单，修改为 .addFunction(&quot;super_func&quot;, static_cast&lt;void(sub_cls::*)()&gt;(&amp;sub_cls::super_function))即可\n分析这个问题的原因(自己的理解)：addFunction 是模版方式，属于编译期多态，sub_cls 是继承方式运行期多态，调用 addFunction 的模版无法再编译期推导运行期的继承关系，也就无法匹配到 super_function 对 sub_cls 也是可见的\n但是：这种写法在做模版的时候经常写，比如 std::bind(&amp;sub_cls::super_function, sub_cls_point) 是没有问题的 另一段代码:template&lt;class _Cls, class _Ret, class... _Args&gt;void caller(_Ret(_Cls::*func)(_Args...)) &#123;&#125;// testcaller(&amp;sub_cls::super_function);            // ok：func=(void (super_cls::*)(super * const))caller&lt;sub_cls&gt;(&amp;sub_cls::super_function);   // error: no matching function for call to caller....\nluaBridge 也是类似报错行的方式，类的类型是从 deriveClass 调用萃取出来的，导致 addFunction 写法报错\nvisual studio 上述写法可以编译通过，应该是做了类似 is_base_of 或者其他什么原因，没有细究\n\nwindows TCP SO_REUSEADDR and SO_EXCLUSIVEADDRUSE\nmsdn: https://learn.microsoft.com/zh-cn/windows/win32/winsock/using-so-reuseaddr-and-so-exclusiveaddruse?redirectedfrom=MSDN\nstackoverflow: https://stackoverflow.com/questions/14388706/how-do-so-reuseaddr-and-so-reuseport-differ\nSO_REUSEADDR: 基本不应该被使用，没有使用组播（多播）方式的情况下，多个进程可监听统一IP+端口，但是只有1个进程可以收到消息\nSO_EXCLUSIVEADDRUSE: 表现同linux\n端口占用与唤起其他进程问题：1. A 进程 listen port: 528002. system(&#x27;.\\B.exe&#x27;); 唤起 B 进程3. 关闭 A 进程，52800 端口可以在 TCPView 看到还在监听状态4. 这时候再开启 A 进程将 bind 端口失败5. 关掉 B 进程，52800 端口就会释放出来解决方式：使用 CreateProcess 替换 system 指令暂时没有细究为什么\n\n","categories":["知识积累"],"tags":["知识积累","游戏"]},{"title":"easy datetime","url":"/archives/b6e30e08.html","content":"pre重构模块，一个过期时间的功能点，想要实现更灵活的配置，支持：\n\n时间长度过期：after 3600s (3600秒之后过期)\n时间点过期： appoint 2023-10-09 05:00:00 (localtime 过期)\n以天为单位的时刻过期：point 04:00:00 (每天4点过期)\n当天4点前获得道具，当天4点过期\n当天4点后获得道具，第二天4点过期\n\n\n\n旧的样子之前老的时间模块有这些函数：\n\nget_current_timestamp       - 获取当前时间戳\nget_timestamp_from_string   - 获取指定时间戳的format string\nget_string_from_timestamp   - 获取指定format string 对应的时间戳\nget_day_start_timestamp     - 获得当天开始的时间戳（localtime 0点）\n\n期望的样子看起来好像是够用的，组合一下，基本可以实现上面的需求；不过可能是这个模块本身写的比较乱（命名不是像上面整齐、函数实现有用c的，有用std::chrono的、ms&#x2F;s用了两个函数，而且命名看不出取到的是什么、数据类型有int32,int64,uint64,time_t）就打算重新整理一下，期望：\n\ntimestamp 相关的函数用模版区分 seconds&#x2F;millisecs\nformat string 提供只提供一种方式（基本都是内部使用，不涉及utc&#x2F;http不同格式的format）\nfrom string 也就只从一种格式解析，但是期望同时能解析只有date，只有time的情况（覆盖上面的第三种配置方式）\n性能上 format string 同一秒不做重复解析，需要缓存上次解析后的字符串，对日志这种经常获取当前时间字符串的场景可以提升不少性能\n因为主要用在游戏开发上，精度到millisecs基本够用\n基于std::chrono，之后升级到c++20可以更灵活的替换部分函数\n\n实现实现上其实没太复杂，只有 from string 的处理上需要覆盖期望没有用 std::get_time&#x2F;strptime，自己写了解析，代码长了点，实测性能比 std::get_time 高1倍\ncode: https://github.com/kinly/anything/blob/main/easy_datetime.h\n后之前有印象google的时间解析库比 std::get_time 快10倍还是20倍的样子，想着有什么办法能给自己写的提高点性能，尝试无果后找隔壁桌的大佬帮忙。\n\n首先他觉得这样的东西应该在逻辑层处理，作为datetime模块基本只需要 旧的样子 就好（我觉得日常场景挺频繁的，基础模块做好这些没关系，毕竟已经写好了….）\nformat string 用 ms 级别缓存，后来看他写的也是用 s 的，但是可能因为他的精度是macro second 记混了，明确下：一般场景用 ms 反而会拖累性能，用 s 更合适\ndatetime 模块需要缓存 loacltime，不然做时间偏移的时候会有问题，这也是当时有最大争论的点~那会儿我也给绕晕了，怀疑是否没考虑完整…概念\n结论：一切基于timestamp的只有在需要转换成string，或者从string转换的时候才需要考虑localtime问题\ntimestamp 本身是 long long 类型，表示 time since epoch （1970）到当前时间经历的秒数（seconds）0时区的\n也就是 timestamp 永远是个相对数值量\n无论是判断两个 timestamp 是否是同一天、同一月、年，只要都是一种规则的偏移，判断一定是准确的，小学数学：[(x + a), (x + b)] 的关系和 [(x + 8hours + a), (x + 8hours + b)] 在数值比较运算上没有区别….\n后来他给了我他的测试用例（大佬的测试用例确实完善，很值得学习），套在我的代码上是这样的auto _00 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(0);                 // 1970-01-01 00:00:00auto _01 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(57600);             // +16 hoursauto _02 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(86400);             // +24 hoursauto _03 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(90000);             // +25 hoursauto _04 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(144000);            // +1 days 16 hoursauto _05 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(172800);            // +2 daysauto _06 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(28800 - 28800);     // 0auto _07 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(57600 - 28800);     // +16 hours - 8 hoursauto _08 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(86400 - 28800);     // +24 hours - 8 hoursauto _09 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(90000 - 28800);     // +25 hours - 8 hoursauto _10 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(144000 - 28800);    // +40 hours - 8 hoursauto _11 = easy::datetime::from_timestamp&lt;std::chrono::seconds&gt;(172800 - 28800);    // +48 hours - 8 hoursstd::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_00) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_00) &lt;&lt; &quot;  // 0&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_01) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_01) &lt;&lt; &quot;  // +16 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_02) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_02) &lt;&lt; &quot;  // +24 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_03) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_03) &lt;&lt; &quot;  // +25 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_04) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_04) &lt;&lt; &quot;  // +1 days 16 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_05) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_05) &lt;&lt; &quot;  // +2 days&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_06) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_06) &lt;&lt; &quot;  // 0&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_07) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_07) &lt;&lt; &quot;  // +16 hours - 8 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_08) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_08) &lt;&lt; &quot;  // +24 hours - 8 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_09) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_09) &lt;&lt; &quot;  // +25 hours - 8 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_10) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_10) &lt;&lt; &quot;  // +40 hours - 8 hours&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;local: &quot; &lt;&lt; easy::datetime::localtime_string(_11) &lt;&lt; &quot; utc: &quot; &lt;&lt; easy::datetime::utc_string(_11) &lt;&lt; &quot;  // +48 hours - 8 hours&quot; &lt;&lt; std::endl;\n后面在他的建议上加了一些相对时间的函数，看了c++20新增的一些 help types，加了 std::chrono::days 的写法using days = std::chrono::duration&lt;long long, std::ratio_multiply&lt;std::ratio&lt;24&gt;, hours::period&gt;&gt;;// weak 这样子~这个也比较常用using days = std::chrono::duration&lt;long long, std::ratio_multiply&lt;std::ratio&lt;7&gt;, days::period&gt;&gt;;\n\n\n新标准下的 c++ 未来可期！\ntodo: 后面有办法了还是要优化下从字符串解析的性能\n\n","categories":["模块"],"tags":["知识积累","游戏","模块"]},{"title":"mongodb 被黑","url":"/archives/4b1350ef.html","content":"pre\n前面在云主机部署了mongoDB做一些测试，部署方式基本是参考 https://www.mongodb.com/docs/v6.0/tutorial/install-mongodb-on-ubuntu/\n设置了简单的密码，验证也只是连到数据库执行 db.auth 指令没问题就结束了\n因为机器在云主机上，为了方便本地程序测试使用，开放了 0.0.0.0 27017 的端口权限…\n2023-09-26 登录账户遇到被清档的情况，登录进去发现自建的数据库都没有了\n\n被清库\nday 1 : 服务报错从db没有获取到数据，以为是服务出问题了，当时没有再复现就没有再细查\nday 2 : 又出现从db加载不到数据的情况；下载mongo client ide 看到数据库里只有新建的数据，这两天跑的测试不应该只有这点数据，mongo 服务还在，当时怀疑是部署的有什么遗漏\nday 3 : 到机器上查mongo的log，看到database被drop的记录，和一个奇怪的 READ_ME_TO_RECOVER_YOUR_DATA，这才知道是遇到攻击了，还好数据不重要\n\n处理\n确认自己是有设置密码的，当时确认的方式还是链接到数据库执行指令看是否成功use admindb.auth(&quot;user&quot;, &quot;123456&quot;)\n可以处理的办法：\n关掉公网开发的mongo端口（而且这里还使用的是默认端口，太容易被扫到了）\n修改数据库密码，之前用的密码太简单了，机器的登录记录是没有查到恶意用户的（密码生成工具：windows devToys）\n\n\n虽然关闭端口能解决问题，但是当时想着应该是密码太简单了，改了密码之后就想着看下hacker还能不能进来，所以还是保持端口对外的样子\n第二天到机器发现又被清库了….\n用 mongo log 记录的过程信息试着复现操作，竟然还真把数据库给删了….(注意下面指令是没有db.auth的)mongosh mongodb://127.0.0.1:27017use test_databasedb.test.insert(&#123;name: &quot;1&quot;&#125;)db.dropDatabase()\nmongo auth 形同虚设….\n搜索到相同的问题：\nhttps://stackoverflow.com/questions/73260190/why-is-my-mongo-collection-being-wiped-on-azure-ubuntu-instance\nhttps://www.mongodb.com/community/forums/t/database-deleted-auto/99623\nhttps://www.mongodb.com/docs/manual/administration/security-checklist/?_ga=2.22459901.77527625.1695801349-1690052969.1694834164\n\n\n后来发现问题出在 mongod.conf 上 security 项是注释状态，（我这糟糕的运维意识）打开这个#security:security:  authorization: &quot;enabled&quot;\n再执行上面语句会报错&gt; db.test.insert(&#123;name: &quot;1&quot;&#125;)DeprecationWarning: Collection.insert() is deprecated. Use insertOne, insertMany, or bulkWrite.Uncaught:MongoBulkWriteError: command insert requires authenticationResult: BulkWriteResult &#123;  insertedCount: 0,  matchedCount: 0,  modifiedCount: 0,  deletedCount: 0,  upsertedCount: 0,  upsertedIds: &#123;&#125;,  insertedIds: &#123; &#x27;0&#x27;: ObjectId(&quot;6514fd829155c9c6f72a6fcd&quot;) &#125;&#125;Write Errors: []\n执行auth之后：kinly&gt; use adminswitched to db adminadmin&gt; db.auth(&quot;adminXXXX&quot;, &quot;xxxxxxx&quot;);&#123; ok: 1 &#125;admin&gt; use kinlyswitched to db kinlykinly&gt; db.test.insert(&#123;name: &quot;1&quot;&#125;);&#123;  acknowledged: true,  insertedIds: &#123; &#x27;0&#x27;: ObjectId(&quot;6514fdd09155c9c6f72a6fce&quot;) &#125;&#125;\n还没完，我自己不能删库了…kinly&gt; db.dropDatabase();MongoServerError: not authorized on kinly to execute command &#123; dropDatabase: 1, lsid: &#123; id: UUID(&quot;8a2107dd-8768-4413-a5be-e9fb7a27744a&quot;) &#125;, $db: &quot;kinly&quot; &#125;\nkinly&gt; use adminswitched to db adminadmin&gt; show users[  &#123;    _id: &#x27;admin.xxxx&#x27;,    userId: new UUID(&quot;xxxx-xxx-xxx-xxx-xxx&quot;),    user: &#x27;xxxx&#x27;,    db: &#x27;admin&#x27;,    roles: [      &#123; role: &#x27;readWriteAnyDatabase&#x27;, db: &#x27;admin&#x27; &#125;,      &#123; role: &#x27;userAdminAnyDatabase&#x27;, db: &#x27;admin&#x27; &#125;    ],    mechanisms: [ &#x27;SCRAM-SHA-1&#x27;, &#x27;SCRAM-SHA-256&#x27; ]  &#125;]\nhttps://stackoverflow.com/questions/47130379/mongoerror-not-authorized-on-to-execute-command-find-app-updates-filter\nhttps://dba.stackexchange.com/questions/45735/mongo-authentication-user-cant-drop-databaseadmin&gt; db.grantRolesToUser(&quot;xxxx&quot;, [&quot;root&quot;]);\nOK 了，取消设置：# 取消Rolesadmin&gt; db.revokeRolesFromUser(&quot;xxxx&quot;, [&quot;root&quot;]);\n继续开着端口等hacker来…\n\nmysql 被黑 2023-09-29\n上午发现apollo无法访问，到机器上发现无法连接数据库了\nskip_grant_tables&#x3D;1 模式重启mysql，看到一个README的数据库\n机器像是变成互联网上的肉鸡….\n这个库是给apollo用的，当时因为apollo版本更新表结构变更导致模版数据导不进去就开了对外端口方便在本地用ide对比区别，后面没有在意也没有关掉端口\n这个库里数据很多，眼里噙着泪重新初始化数据库… 参考 https://blog.csdn.net/qq_22938603/article/details/125569850\n\n个人开发者安全意识\n端口对外需要谨慎，很多时候部署组件在远端的云主机，自己在本地开发总要开一些端口，那就指定IP开放吧，虽然国内ip资源不多，还是基本缩小掉被外部攻击的可能\n数据库这种需要特别小心，有必要的时候学习使用一些备份相关的内容，验证auth相关需要全面点，别让auth形同虚设\nredis 这种缓存形式丢了就丢了，不能对业务产生影响\n连接云主机还是用key更安全，密码一言难尽\n只是想做点简单的开发，这些黑客低劣的扫描端口，删库勒索也太过分了….\n\nconnect mysql&#x2F;mongo by ssh-tunnel\nhttps://linuxize.com/post/mysql-ssh-tunnel/\nbash 1:\nssh -NL 3306:127.0.0.1:3306 server_user_name@server_address\nenter server’spassword\n\n\nbash 2:\nmysql -u root -p\nenter mysql’s password\n\n\nmongo 同理\n\n","categories":["mongodb 被黑"],"tags":["linux"]},{"title":"cloudflare 加速 github.io website","url":"/archives/d0620e28.html","content":"pre\ngit 相关地址在国内访问的情况很不稳定\ngithub.io website 情况也是一样，并且由于站点上经常会放一些图片，链接状况差导致图片基本是刷不出来的\n前面知道 cloudflare 有免费的 cdn 加速，一直没有想好自己的域名就一直没有尝试\ncloudflare 加速的必要条件：\n可访问的站点（白嫖的 github.io 相当于已经做了这一步）\n独立的域名（加速的方式是 dns解析+cdn边缘节点，github.io 的dns解析是动不了的，这里就需要有个自己的域名用 cloudflare 的 dns 解析到 cdn 服务器再跳转到实际站点，这里 cdn 只是一个 anycast 方式的代理转发，减少用户侧到站点间的路由跳转；dns到实际服务端还可以做稳定的路由链路优化、卸载tls等加速的操作），简单点想就是 cloudflare 这样的国际公司，节点到 github 的服务器肯定不会差的\n\n\n\n阿里云购买域名\n想申请个后面也方便在国内备案的域名，阿里云比较简单一点，自己造的单词也便宜\n阿里云域名申请地址：https://wanwang.aliyun.com/domain/searchresult/?spm=5176.100251.111252.15.38ac4f15tbPZE7&amp;keyword=klysisle&amp;suffix=com\n选定的域名是 .space，海外可以申请到的 .me 在国内是备案不来的，完全个人喜好，kinly&#39;s isle(island) 接space虽然长了点，更契合一点，本来就是个人的空间，.space也便宜，10年188RMB\n按阿里云的规则来，该实名实名，提交信息就提交信息\n\n设置\n先要注册个账号 https://dash.cloudflare.com/\n添加自己购买的域名即可\n到阿里云的域名管理页面设置域名的 dns 服务器：这里的 dns 地址都是cloudflare给的，一共两个，填两个框\n等阿里云dns的更新，我这里大概等了1刻钟左右，还挺快的\n到添加好的域名里面进行配置：（我这里已经配置过了，没有太多截图，具体可以参考 https://siriusq.top/github-pages-%E5%90%AF%E7%94%A8-cloudflare-%E5%8A%A0%E9%80%9F%E5%8F%8A-https.html）\nA 类 IP 地址用 nslookup、dig 命令就好：eg. nslookup kinly.github.io\nCNAME 是固定的样式：eg. www + kinly.github.io\n\n\n域名指定地址配置好的样子：\ngit 站点对应仓库的配置：\ngit 本身更新域名的速度还是很快的，只是注意 cloudflare 的域名解析先只用 dns （不带tls）的方式，git这边设置好 enforce https 在切换成带 tls 的就好，具体前面的引用博文里面有说明\nhexo g -d 命令遇到 git 配置的 custom domain 被覆盖的问题，参考网上的解决办法在 source 目录下新建了 CNAME 文件，写入 domain klysisle.space\n\n效果：超出预期\n加速的域名：\n老的域名：\n\n另外\n之前尝试用过 cloudflare 的 1.1.1.1 dns 地址，但是实际效果不好，应该是墙的关系，也可能是姿势不对？\n海外白嫖：\naws 海外 ecs，一个账号一年期，部署vps使用，ip被封了可以换机器\ngithub 站点\ncloudflare 加速\ncloudflare turnstile：还不知道怎么嵌入到 hexo\nproton vpn：这个不好用\n\n\n\n","categories":["部署"],"tags":["知识备忘","部署"]},{"title":"螺旋矩阵:由内向外,游戏掉落问题","url":"/archives/7a93055.html","content":"2025-05-14 更新\n老代码是很早之前从一篇blog里抄来做改动的，很惭愧没有找到blog地址补在文档上\n新的部分基于AI生成以下是一篇关于“用 C++20 编写螺旋矩阵生成器”的博客文章，面向有一定 C++ 基础的开发者：\n\n\n编译期构建螺旋矩阵路径：用 C++20 实现坐标映射在某些游戏开发或图形处理场景中，我们经常需要以螺旋方式遍历一个二维矩阵，常见于地图填充、探索算法或邻域扩展。在本文中，我将用现代 C++20 技术实现一个编译期生成螺旋路径的工具，并支持运行期通过偏移顺序依次访问矩阵所有点。\n问题定义目标是构造一个螺旋矩阵偏移列表，满足：\n\n编译期生成固定大小的 (dx, dy) 坐标偏移数组。\n运行期只需传入任意起点 (x, y)，即可遍历整个螺旋路径。\n路径以 (0, 0) 为中心开始，顺时针向外扩展。\n\n\n实现思路实现分两部分：\n\n编译期生成路径：使用 constexpr 和 std::array 构建偏移数组；\n运行期应用偏移：传入起始点，加上偏移依次访问每个位置。\n\n\n螺旋路径规则遍历方向依次为：右 → 上 → 左 → 下。每走两轮，步长加一：\nStep length: 1  → 1 → 2 → 2 → 3 → 3 → ...Directions : →  ↑ → ← ↓ ← ↑ → ...\n\n举例：\n(0,0)→ (1,0)↑ (1,1)← (0,1) → (-1,1)↓ (-1,0) → (-1,-1)→ (0,-1) → (1,-1)↑ (1,0) → (1,1) ...\n\n\nC++20 代码实现#include &lt;array&gt;#include &lt;utility&gt;#include &lt;iostream&gt;constexpr std::pair&lt;int, int&gt; directions[] = &#123;    &#123;1, 0&#125;,   // → right    &#123;0, 1&#125;,   // ↑ up    &#123;-1, 0&#125;,  // ← left    &#123;0, -1&#125;   // ↓ down&#125;;template &lt;size_t N&gt;constexpr auto generate_spiral_offsets() &#123;    std::array&lt;std::pair&lt;int, int&gt;, N&gt; offsets&#123;&#125;;    int x = 0, y = 0;    size_t idx = 0;    int step = 1;    offsets[idx++] = &#123;x, y&#125;; // 起点    while (idx &lt; N) &#123;        for (int dir = 0; dir &lt; 4; ++dir) &#123;            int dx = directions[dir].first;            int dy = directions[dir].second;            int len = (dir / 2 + 1) * step;            for (int i = 0; i &lt; len &amp;&amp; idx &lt; N; ++i) &#123;                x += dx;                y += dy;                offsets[idx++] = &#123;x, y&#125;;            &#125;            if (dir % 2 == 1) ++step; // 每两轮增长一次        &#125;    &#125;    return offsets;&#125;constexpr size_t count = 25;constexpr auto spiral_offsets = generate_spiral_offsets&lt;count&gt;();\n\n\n应用：遍历矩阵运行时，我们只需加上起点 (origin_x, origin_y) 即可：\nvoid print_spiral_from(int origin_x, int origin_y) &#123;    for (auto [dx, dy] : spiral_offsets) &#123;        int x = origin_x + dx;        int y = origin_y + dy;        std::cout &lt;&lt; &quot;(&quot; &lt;&lt; x &lt;&lt; &quot;,&quot; &lt;&lt; y &lt;&lt; &quot;) &quot;;    &#125;    std::cout &lt;&lt; &#x27;\\n&#x27;;&#125;\n\n\n\n\n\n旧：问题\n游戏内怪物死亡掉落一般要求是以死亡点为圆心向周围扩散找到可用点刷新场景道具\n画图可以看到这是一个螺旋矩阵问题\n以某个点为中心点，周围的坐标都是其相对坐标\n要求由内向外，矩阵样式如下代码注释\n使用静态变量提前初始化好矩阵，之后遍历矩阵的相对坐标就可以\n传送目标点等可用点搜索也可以用这个array\n\n代码/*42\t43\t44\t45\t46\t47\t4841\t20\t21\t22\t23\t24\t2540\t19\t6\t7\t8\t9\t2639\t18\t5\t0\t1\t10\t2738\t17\t4\t3\t2\t11\t2837\t16\t15\t14\t13\t12\t2936\t35\t34\t33\t32\t31\t30 */ // 坐标点struct cell &#123;    unsigned x = 0;    unsigned y = 0;&#125;;static constexpr int __helix_radius = 3;static constexpr int __helix_size = (__helix_radius * 2 + 1) * (__helix_radius * 2 + 1);static cell __cell_helix[__helix_size];static int _helix(int x, int y) &#123;    int t = std::max(std::abs(x), std::abs(y));    int u = t + t;    int v = u - 1;    v = v * v + u;    if( x == -t )        v += u + t - y;    else if( y == -t )        v += 3 * u + x - t;    else if( y == t )        v += t - x;    else        v += y - t;    return v - 1;&#125;static bool _init_helix() &#123;    for(int y = -1 * __helix_radius; y &lt;= __helix_radius; ++y) &#123;        for(int x = -1 * __helix_radius; x &lt;= __helix_radius; ++x) &#123;            cell&amp; cpt = __cell_helix[_helix(x, y)];            cpt.x = x;            cpt.y = y;        &#125;    &#125;    return true;&#125;static bool __call_init_helix = _init_helix();","categories":["知识积累"],"tags":["游戏","模块"]},{"title":"服务端-9宫格场景","url":"/archives/4311cbf8.html","content":"前言\n场景同步在游戏里已经有很成熟的处理方式，9宫格、十字链、灯塔、4叉树、8叉树….\n一般分为这些方面：\n地图制作\n区域划分\n地图管理\n对象管理\n视野同步\n碰撞检测\n\n\n对于服务端来说压力主要在视野同步、碰撞检测，一个涉及数据广播，一个涉及数据检查\n前段时间重构了一个2DMMO游戏的场景相关内容，使用的9宫格方式做视野管理，只是2D碰撞检测就只使用了bits标记方式，没有引入4叉树、8叉树这种\n记录一下备忘\n\n名词\ncell 可站立的最小单位，一般也是场景对象的(x, y)坐标：下图涂黄、绿的小格子\narea 9宫格的一个单位，x, y 标记表示横纵各占用多少个 cell：下图黄、绿标记的块\neyesight 视野区域半径(3*3的9宫格，这里就是 1, 1)：下图蓝色、红色框示意的块，其中蓝色是客户端屏幕视野，红色是服务端管理视野，一般服务端是比客户端大的，也就是服务端先于客户端将数据同步到客户端，这样在玩家视野切换的时候表现更流畅\nflag 配置来的静态属性(阻挡点、安全区、自由攻击….)、运行中的动态属性(栅栏、场景事件….)\nworldpoint 一些大世界游戏会用到的概念，更小粒度的坐标点，比如4个worldpoint组成一个cell，也可以直接把这个概念简化为 cell，配合 4叉树 处理碰撞问题\n\n\n对象、格子管理\n场景维护所在场景的对象（场景对象）\n\n场景对象持有所在地图 uuid，cell 信息\n\n视野同步是以 area 为单位的，碰撞检测以 cell 为单位，那么对象挂在 cell、area 哪里更合适呢？\n\n两者发生的频率上视野同步更高：例如场景对象每次有动作(移动、坐下)都需要做视野同步，但是坐下这个动作不需要做碰撞检测\n假设对象挂在 area 上，视野同步只需要遍历9个 area 就好\n碰撞检测只是对单个格子占用信息的检查，需要的数据只是格子的占用标记 flag\n结论：场景对象挂在 area 结构上，cell 对象生增加 flag 标记就好\n\n  using entity_handles = std::unordered_set&lt;entity_handle&gt;;std::vector&lt;entity_handles&gt; _area_entitys;  // 视野格子对象列表\n  // 格子标记，做细节一点，但是匿名联合体、结构体都不是个好的习惯struct cell_flag &#123;    union &#123;        int _flag = 0;        struct &#123;            bool _barrier : 1;         // 占用阻挡（如果非下面的特有占用，标记这个通用值）            bool _player_barrier : 1;  // 特有：玩家占用（如果占用的是玩家，标记这个值）            bool _monster_barrier : 1; // 特有：怪物占用（如果占用的是怪物，标记这个值）            bool _item_barrier : 1;    // 特有：道具占用（如果占用的是道具，标记这个值）            bool _block : 1;           // 物理阻挡        &#125;;    &#125;;    cell_flag() = default;    bool is_block() const &#123;        return _block;    &#125;&#125;;struct barrier_mark &#123;    const bool is_mark = false;  // 标记判断是否占用格子    // test 值和 cell_flag 一一对应    union &#123;        int flag = 0;        struct &#123;            bool test_barrier : 1;    // 是否检查其他占用            bool test_player : 1;     // 是否检查玩家类型的占用            bool test_monster : 1;    // 是否检查怪物类型的占用            bool test_item : 1;       // 是否检查道具类型的占用            bool test_block : 1;      // 是否检查物理阻挡        &#125;;    &#125;;    barrier_mark() = default;    barrier_mark(bool _0, bool _1, bool _2, bool _3, bool _4, bool _5)        : is_mark(_0)        , test_barrier(_1)        , test_player(_2)        , test_monster(_3)        , test_item(_4)        , test_block(_5) &#123;    &#125;&#125;;static const barrier_mark barrier_mark_none(false, false, false, false, false, true);  // 不占格子，检查物理阻挡（比如用于透明场景对象）static const barrier_mark barrier_mark_slack(true, true, false, false, false, true);   // 占格子，松弛的，穿人、穿怪、穿道具static const barrier_mark barrier_mark_default(true, true, true, true, false, true);   // 占格子，默认的，不穿人、不穿怪、穿道具static const barrier_mark barrier_mark_item(true, true, false, false, true, true);     // 占格子，场景道具的，穿人、穿怪、不穿道具\npoint 都是2维级别，为了简化转换成1维\nstd::vector&lt;cell_flag&gt; _cells;        // 格子\n\ncell, area 坐标系单位不一样，虽然都是 (x, y)，为了干净需要一个 cell_point, area_point\n/**    * \\brief 横纵    */struct point &#123;    uint32_t x = 0;    uint32_t y = 0;&#125;;/**    * \\brief struct cell point (world point)    */struct cell_point &#123;    uint32_t cx = 0;    uint32_t cy = 0;    bool operator == (const cell_point&amp; right) const &#123;        return this-&gt;cx == right.cx            &amp;&amp; this-&gt;cy == right.cy;    &#125;&#125;;/**    * \\brief invalid cell point    */static const cell_point invalid_cell = cell_point&#123; 0x7FFFFFFF, 0x7FFFFFFF &#125;;/**    * \\brief struct area point    */struct area_point &#123;    uint32_t ax = 0;    uint32_t ay = 0;    bool operator == (const area_point&amp; right) const &#123;        return this-&gt;ax == right.ax            &amp;&amp; this-&gt;ay == right.ay;    &#125;&#125;;/**    * \\brief invalid area point    */static const area_point invalid_area = area_point&#123; 0x7FFFFFFF, 0x7FFFFFFF &#125;;/**    * \\brief rect_point    */struct rect_point &#123;    uint32_t lx = 0;    uint32_t ly = 0;    uint32_t rx = 0;    uint32_t ry = 0;&#125;;\n\n地图基础数据\n/**    * \\brief base config    */struct base_config &#123;    cell_point cell;    // 地图格子数量    area_point area;    // 视野块占格子数量    point eyesight;     // 视野区域半径（3*3视野的话这里是 1, 1）    point area_size;    // 整张地图多少个area（加载地图后计算得到）&#125;;\n\n视野\n还是这个图，在服务端看，场景满载的同步量是: 12 * 8 * 9 &#x3D; 864 (假设一个cell只有一个对象)\n\n\n\n进出视野：假设一个对象从红色点移动到蓝色点，他的视野范围也就从左上角的 9 * area 变成了右下角的 9 * area\n\n\n\n如图红色标记了相互离开的格子，蓝色标记了相互进入的格子，换到 area 就分别是 5 * area\n\n\n\n视野列表，想要得到视野列表就需要先获得 红蓝 area，简化图，看进出视野的相对关系\n\n视图认为对象从 (0, 0) 移动到 (2, 2) 坐标点\n\n\n上图已经用颜色标记了点和点相对的关系：\n\n(-1, -1) &lt;-&gt; (3, 3) = (0, 0) - ( 1,  1) &lt;-&gt; (2, 2) + ( 1,  1)(-1,  0) &lt;-&gt; (3, 2) = (0, 0) - ( 1,  0) &lt;-&gt; (2, 2) + ( 1,  0)(-1,  1) &lt;-&gt; (3, 1) = (0, 0) - ( 1, -1) &lt;-&gt; (2, 2) + ( 1, -1)( 0, -1) &lt;-&gt; (2, 3) = (0, 0) - ( 0,  1) &lt;-&gt; (2, 2) + ( 0,  1)( 0,  0) &lt;-&gt; (2, 2) = (0, 0) - ( 0,  0) &lt;-&gt; (2, 2) + ( 0,  0)( 0,  1) &lt;-&gt; (2, 1) = (0, 0) - ( 0, -1) &lt;-&gt; (2, 2) + ( 0, -1)( 1, -1) &lt;-&gt; (1, 3) = (0, 0) - (-1,  1) &lt;-&gt; (2, 2) + (-1,  1)( 1,  0) &lt;-&gt; (1, 2) = (0, 0) - (-1,  0) &lt;-&gt; (2, 2) + (-1,  0)( 1,  1) &lt;-&gt; (1, 1) = (0, 0) - (-1, -1) &lt;-&gt; (2, 2) + (-1, -1)from_point - (x, y) = to_point + (x, y)\n\n\n这可能是全文最有价值的一段代码：（注意下面的拷贝是必要的，如果是list可以换成splice；因为会有原（临近）坐标force传送的情况，比如原地复活；如果客户端支持，可以标记force为false，否则会因为使用对称方式导致（视野内）对象先进入视野后离开视野的情况；根据需要选择合适的方式修改这种情况）// 镜像关系for (int32_t y = -_config.eyesight.y; y &lt;= _config.eyesight.y; ++y) &#123;    for (int32_t x = -_config.eyesight.x; x &lt;= _config.eyesight.x; ++x) &#123;        // 两个方向偏移后新点和目标点距离小于半径，用两圆相交的方式看待        if (!force            &amp;&amp; std::abs(static_cast&lt;int32_t&gt;(from.ax) + x - static_cast&lt;int32_t&gt;(to.ax)) &lt;= _config.eyesight.x            &amp;&amp; std::abs(static_cast&lt;int32_t&gt;(from.ay) + y - static_cast&lt;int32_t&gt;(to.ay)) &lt;= _config.eyesight.y) &#123;            continue;        &#125;        if (ok_from) &#123;            auto leas = entitys(area_point&#123; from.ax + x, from.ay + y &#125;, nullptr);            std::copy(leas.begin(), leas.end(), std::back_inserter(leaves));        &#125;        if (ok_to) &#123;            auto ents = entitys(area_point&#123; to.ax - x, to.ay + y &#125;, nullptr);            std::copy(ents.begin(), ents.end(), std::back_inserter(enters));        &#125;    &#125;&#125;\n\n25宫格\n考虑这个问题是因为9宫格的范围毕竟太大了，想减少遍历的消耗\n也想找到一种方式可以在对象多的场景优化一些性能\n而且在服务端视野比客户端大的前提下，服务端其实是有优化空间的\n如上格子满载的情况下，9格视野最多需要处理 12 * 8 * 5 (exit) + 12 * 8 * 5 (enter) &#x3D; 960\n5 * 5 宫格 area:(7, 5), 满载同步量: 7 * 5 * 25 &#x3D; 875，格子范围并不影响客户端同步效果\n\n\n\n从红格子跳到另一个红格子：满载需要处理的同步量: 7 * 5 * 9 (exit) + 7 * 5 * 9 (enter) &#x3D; 630，相比960的数据量，少了1&#x2F;3\n\n\n\n简单压测的结果\n\n\n思考\n缩小 area 尺寸带来的问题:\n最关键是同步变得频繁了；沿X轴单方向走，9宫格走12cell离开area，25宫格走7cell\n\n\n为什么还考虑用这个方案：\n同步频率提高了 40%，同步量减少了 30%，并且同步量是在非满载的情况下，收益是更差的，但是如果技能的命中范围是在 7 * 5 内的，对战斗目标的筛选是提高了很多的\n进出视野会引发事件，单线程模型下，更少的进出视野可以减少1个逻辑周期程序的处理量\n当前地图场景的设计，视野单位占格子数量和视野区域半径两个数值是配置项，可以每张地图都不同\n\n\n\n样例代码https://github.com/kinly/anything/blob/main/game_map.h\n","categories":["知识积累"],"tags":["游戏","模块","场景同步"]},{"title":"图结构：拓扑排序","url":"/archives/6132c487.html","content":"pre\n可排序拓扑图：有相无环图\n网上资料很多，结构也比较明确：\nhttps://zhuanlan.zhihu.com/p/339709006\nhttps://oi-wiki.org/graph/topo/\n\n\n是在想找到一种预设寻路算法关键点，减轻寻路算法对服务端压力是看到的一种结构\n这个结构比较简单，可以用在游戏的任务模块里面，把任务串成一个有向无环图，然后根据这个图进行拓扑排序，把任务串起来\n\n拓扑排序\n看了网上不少代码，不过在明确这个结构可以用在任务模块的情况下，需要的接口大体如下：\n（从配置表读取后）把任务添加到拓扑结构里\n指定某个（些）任务依赖的前置任务是什么\n源码基本参考：https://github.com/graphitemaster/dep_sort/tree/master\n修改为自己的写法习惯\n\n代码实现\nhttps://github.com/kinly/anything/blob/main/dep_sort.h\n\n#pragma once#include &lt;unordered_map&gt;#include &lt;unordered_set&gt;#include &lt;vector&gt;/// dep topological sortnamespace easy::utils &#123;template &lt;class tt&gt; class dep_sort &#123;public:  struct relation;  using relation_type = relation;  struct result;  using result_type = result;  using value_type = tt;  using map_type = std::unordered_map&lt;value_type, relation_type&gt;;public:  struct relation &#123;    std::size_t dependencies;    std::unordered_set&lt;value_type&gt; dependents;  &#125;;  struct result &#123;    std::vector&lt;value_type&gt; sorted;    std::vector&lt;value_type&gt; non_sorted;    bool has_cycles() const &#123; return non_sorted.empty() == false; &#125;  &#125;;private:  map_type _values;public:  bool has_node(const value_type&amp; node) &#123;    return _values.contains(node);  &#125;  void clear() &#123; _values.clear(); &#125;  bool add_node(const value_type &amp;node) &#123;    auto res = _values.insert(&#123;node, &#123;&#125;&#125;);    return res.second;  &#125;  bool add_node(value_type &amp;&amp;node) &#123;    auto res = _values.insert(&#123;std::move(node), &#123;&#125;&#125;);    return res.second;  &#125;  bool has_dependency(const value_type &amp;node, const value_type &amp;dependency) &#123;    if (!has_node(node))      return false;    const auto &amp;value = _values.at(node);    return value.dependents.find(dependency) != value.dependents.end();  &#125;  bool add_dependency(const value_type &amp;node, value_type &amp;&amp;dependency) &#123;    if (node == dependency)      return false;    auto res_value = _values.insert(&#123;std::move(dependency), &#123;&#125;&#125;);    auto &amp;dependents = res_value.first-&gt;second.dependents;    if (dependents.find(node) == dependents.end()) &#123;      dependents.insert(node);      _values[node].dependencies += 1;      return true;    &#125;    return false;  &#125;  bool add_dependency(const value_type &amp;node, const value_type &amp;dependency) &#123;    if (node == dependency)      return false;    auto res_value = _values.insert(&#123;dependency, &#123;&#125;&#125;);    auto &amp;dependents = res_value.first-&gt;second.dependents;    if (dependents.find(node) == dependents.end()) &#123;      dependents.insert(node);      _values[node].dependencies += 1;      return true;    &#125;    return false;  &#125;  template &lt;template &lt;typename, typename...&gt; class container_tt, typename... container_tt_params&gt;  bool add_dependencies(      const value_type &amp;node,      const container_tt&lt;value_type, container_tt_params...&gt; &amp;dependencies) &#123;    for (const auto &amp;one : dependencies) &#123;      if (!add_dependency(node, one))        return false;    &#125;    return true;  &#125;  result_type sort() const &#123;    auto copyed = *this;    result_type res;    for (const auto &amp;[node, relations] : copyed._values) &#123;      if (relations.dependencies == 0) &#123;        res.sorted.push_back(node);      &#125;    &#125;    for (std::size_t index = 0; index &lt; res.sorted.size(); ++index) &#123;      for (const auto &amp;one : copyed._values[res.sorted.at(index)].dependents) &#123;        if (--copyed._values[one].dependencies == 0) &#123;          res.sorted.push_back(one);        &#125;      &#125;    &#125;    for (const auto &amp;[node, relations] : copyed._values) &#123;      if (relations.dependencies != 0) &#123;        res.non_sorted.push_back(node);      &#125;    &#125;    return res;  &#125;&#125;;&#125;;\n\n\n图示：\n\n\n实现过程中关注到的点：\ntemplate any container: container_params 是必须的\nhttps://stackoverflow.com/questions/7728478/c-template-class-function-with-arbitrary-container-type-how-to-define-it\n\ntemplate &lt;template &lt;typename...&gt; class container_tt, typename... container_params&gt;void test_any_container(const container_tt&lt;std::string, container_params...&gt; &amp;cc) &#123;  for (const auto&amp; one : cc) &#123;    std::cout &lt;&lt; one &lt;&lt; std::endl;  &#125;&#125;\n\n\ncheck is container: https://stackoverflow.com/questions/12042824/how-to-write-a-type-trait-is-container-or-is-vector\n\ntemplate&lt;typename T, typename _ = void&gt;struct is_container : std::false_type &#123;&#125;;template&lt;typename... Ts&gt;struct is_container_helper &#123;&#125;;template&lt;typename T&gt;struct is_container&lt;        T,        std::conditional_t&lt;            false,            is_container_helper&lt;                typename T::value_type,                typename T::size_type,                typename T::allocator_type,                typename T::iterator,                typename T::const_iterator,                decltype(std::declval&lt;T&gt;().size()),                decltype(std::declval&lt;T&gt;().begin()),                decltype(std::declval&lt;T&gt;().end()),                decltype(std::declval&lt;T&gt;().cbegin()),                decltype(std::declval&lt;T&gt;().cend())                &gt;,            void            &gt;        &gt; : public std::true_type &#123;&#125;;\n\n\nemplace 并不能完全替代 insert&#x2F;push 等操作：c++20 之前 emplace 不能进行初始化的聚合，比如 const char* -&gt; std::string，或者构造一个结构体\n\n","categories":["知识积累"],"tags":["游戏","模块"]},{"title":"C++ std::move & lambda & std::function & virtual","url":"/archives/3e184a88.html","content":"近期代码里一些疑惑点\nstd::move&#x2F;std::forward 并不会将原对象置为空\n\nvoid function(std::string&amp;&amp; remark) &#123;  ...&#125;void function_source(std::string&amp;&amp; source) &#123;  for (auto &amp; e : v) &#123;    function(std::forward&lt;std::string&gt;(source));  &#125;&#125;\n\n如上，循环里使用 std::forward，在function 不会做 std::move 动作的情况下，这个写法是可行的\n\n\n当然还是不建议这么写，因为 remark 是可以被修改的…调用方不应留这样的隐患，还是用 const std::string&amp; 更好\n\n\nstd::move 对于 std::function&#x2F;lambda 的不同表现\n\nvoid function(std::function&lt;void()&gt;&amp;&amp; oper) &#123;&#125;void function_source() &#123;  auto source = []() &#123;    ...  &#125;;  function(std::move(source));  function(std::move(source));&#125;\n\n如上，对source 进行两次 std::move，会得到两个不同的std::function 对象，而不会得到一个空对象\n\n对上面的问题做了一些测试struct helper_st &#123;  int i = 0;  helper_st() = default;  helper_st(helper_st &amp;&amp;) &#123;    std::cout &lt;&lt; &quot;struct move&quot; &lt;&lt; std::endl;    i = 100;  &#125;  helper_st(const helper_st &amp;) &#123;    std::cout &lt;&lt; &quot;struct copy&quot; &lt;&lt; std::endl;    i += 1;  &#125;&#125;;void string_move_test(std::string &amp;&amp;str) &#123;  str.append(&quot;X&quot;);  std::cout &lt;&lt; str &lt;&lt; std::endl;&#125;void function_move_test(std::function&lt;void()&gt; &amp;&amp;func) &#123;  func();  std::cout &lt;&lt; typeid(func).name() &lt;&lt; &quot; x &quot; &lt;&lt; std::addressof(func) &lt;&lt; std::endl;&#125;void function_move_test(const std::function&lt;void()&gt; &amp;func) &#123;  func();  std::cout &lt;&lt; typeid(func).name() &lt;&lt; &quot;y&quot; &lt;&lt; std::endl;&#125;void function_move_test_2(std::function&lt;void()&gt; &amp;&amp;func) &#123;  function_move_test(std::forward&lt;std::function&lt;void()&gt;&gt;(func));  function_move_test(std::forward&lt;std::function&lt;void()&gt;&gt;(func));  std::function&lt;void()&gt; move_func(std::move(func));  std::cout &lt;&lt; (func ? &quot;not nullptr\\n&quot; : &quot;nullptr\\n&quot;);    // nullptr&#125;int main(int argc, char *argv[]) &#123;  // about string  // https://stackoverflow.com/questions/65426585/stdmovestdstring-not-making-passed-argument-to-empty-state  &#123;    std::string source(&quot;string&quot;);    std::cout &lt;&lt; std::boolalpha;    std::cout &lt;&lt; source.empty() &lt;&lt; std::endl; // false    std::string target(std::move(source));    std::cout &lt;&lt; source.empty() &lt;&lt; std::endl; // true    std::cout &lt;&lt; target.empty() &lt;&lt; std::endl; // false  &#125;  &#123;    std::string source = &quot;abc&quot;;    string_move_test(std::forward&lt;std::string&gt;(source));  // abcX    string_move_test(std::forward&lt;std::string&gt;(source));  // abcXX    string_move_test(std::move(source));                  // abcXXX    string_move_test(std::forward&lt;std::string&gt;(source));  // abcXXXX    std::cout &lt;&lt; source &lt;&lt; std::endl;                     // abcXXXX  &#125;  // about std::function &amp; lambda  // https://stackoverflow.com/questions/13680587/move-semantic-with-stdfunction  // https://sf-zhou.github.io/programming/lambda_implicit_conversion_bug.html  &#123;    auto ff = []() &#123;&#125;;    std::function&lt;void()&gt; ff_v = []() &#123;&#125;;    std::function&lt;void()&gt; fff&#123;std::move(ff)&#125;;    std::function&lt;void()&gt; fff_v&#123;std::move(ff_v)&#125;;    std::cout &lt;&lt; (ff ? &quot;not nullptr\\n&quot; : &quot;nullptr\\n&quot;);     // not nullptr    std::cout &lt;&lt; (ff_v ? &quot;not nullptr\\n&quot; : &quot;nullptr\\n&quot;);   // nullptr    std::cout &lt;&lt; typeid(ff).name() &lt;&lt; &quot;\\n&quot;;                // class `int __cdecl main(int,char * __ptr64 * __ptr64 const)&#x27;::`5&#x27;::&lt;lambda_1&gt;    std::cout &lt;&lt; typeid(fff_v).name() &lt;&lt; &quot;\\n&quot;;             // class std::function&lt;void __cdecl(void)&gt;  &#125;  &#123;    helper_st hst;    auto func = [&amp;hst]() &#123;      hst.i += 1;      static int xx = 1;      xx += 1;      std::cout &lt;&lt; &quot;abc:&quot; &lt;&lt; hst.i &lt;&lt; &quot;\\t&quot; &lt;&lt; xx &lt;&lt; &quot;\\t&quot;;    &#125;;    function_move_test_2(std::forward&lt;std::function&lt;void()&gt;&gt;(func));   // abc:1   2       class std::function&lt;void __cdecl(void)&gt; x 000000BC55DFCCA0                                                                       // abc:2   3       class std::function&lt;void __cdecl(void)&gt; x 000000BC55DFCCA0    function_move_test(std::forward&lt;std::function&lt;void()&gt;&gt;(func));     // abc:3   4       class std::function&lt;void __cdecl(void)&gt; x 000000BC55DFCD00    function_move_test(std::move(func));                               // abc:4   5       class std::function&lt;void __cdecl(void)&gt; x 000000BC55DFCD60    function_move_test(std::forward&lt;std::function&lt;void()&gt;&gt;(func));     // abc:5   6       class std::function&lt;void __cdecl(void)&gt; x 000000BC55DFCDC0    func();                                                            // abc:6   7    std::cout &lt;&lt; std::endl;  &#125;  // virtual function with default argument  // https://www.sandordargo.com/blog/2021/01/27/virtual-functions-with-default-arguments  &#123;    struct st_basic &#123;      virtual void v_function(int default_value = 0) &#123;        std::cout &lt;&lt; &quot;st_basic: &quot; &lt;&lt; default_value &lt;&lt; &#x27;\\n&#x27;;      &#125;    &#125;;    struct st_child : public st_basic &#123;      virtual void v_function(int default_value = 1) override &#123;        std::cout &lt;&lt; &quot;st_child: &quot; &lt;&lt; default_value &lt;&lt; &#x27;\\n&#x27;;      &#125;    &#125;;    std::shared_ptr&lt;st_basic&gt; sptr = std::make_shared&lt;st_child&gt;();    sptr-&gt;v_function();                                                  // st_child: 0  &#125;  return 0;&#125;\n\n总结\nstd::move 相当于强制将对象转换为 rvalue，这个右值是可以被修改的，传给其他函数时，只有这个函数对右值做了修改，才会对原对象产生影响，之前受 std::string 等有默认右值构造函数的影响，以为 std::move 会置空原对象是不对的….例如：string_move_test 函数参数是右值类型，实现是修改参数而非置空，就会得到如上输出结构\n\nstd::forward 同理\n\nstd::function&#x2F;lambda 是两个东西，lambda -&gt; std::function 会进行隐式转换，所以 std::move 会得到不同的对象，而不会置空原对象\n\n在测试 helper_st hst; 引用到 lambda 表达式的情况看到是相同对象，也就是 lambda -&gt; std::function 只构造了新的函数指针，这里 hst 相当于 std::ref(hst)；这也是符合理解的\n\n然后想到 virtual function 的情况，用了一种不常见的方式，给虚函数加带默认值的参数….可以看到结果是使用了基类的函数地址 + 对象类型（父类）的参数默认值；\n\n参数在编译期就确定了，而虚函数地址是运行期确定的，所以会得到这样的结果；\n\n避免歧义，虚函数不要带默认值参数\n\n引申：如果换成CRTP呢？那么都是编译期行为了，这个函数原本是参数是什么默认值就会有什么输出，所以不会出现上面的歧义\n\n\nmove &amp; rvo\n测试是以前做的了，前面有同事看到我做优化时候把他们写的 return std::move(...); 改成了 return ...;； 就翻了下之前测试的东西补发出来\n编译器优化，在编译期将右值转换为左值，以减少不必要的拷贝\n之前也是习惯写成 return std::move(string_value); 但是被编译期警告了，应该改成 return string_value;\n具体参考：https://en.cppreference.com/w/cpp/language/copy_elision\n或者搜索 RVO、 NRVO、 copy elision\n测试结果和说明都标记在图片里了：\n\n","categories":["代码"],"tags":["C++"]},{"title":"近期优化备忘","url":"/archives/f9da676.html","content":"pre\nMMO游戏服务器，主语言C++11，辅助语言Lua\n优化点：\n运行时 cpu 占用\n启动速度\n\n\n总结改动：除了 lua 版本的变更其他都是很简单的改动项；实际给一个已经上线项目做优化时改动点并不多，都是很小的细节，一段逻辑除非命中的特别多并且有明显的性能问题才会被单扣出来整理逻辑着看\n引用、拷贝语法造成的差异\n遍历没有用引用方式\n返回值不是引用的或者拿值类型接收了引用类型的返回值\n\n\n容器栈、指针（lazy construct）的差异\n连续容器（std::vector）reserve 的影响\nRVO&#x2F;NRVO 的优化\n循环的优化\n更现代的内存分配器\n\n\n这些就都是些代码的习惯….而且刚来的时候就写过[优化Tips]的文章；然而一年过去了该有的问题还都有，注释也还不加….只是能跑的代码\n不注意细节的C++肯定是比Java还慢的（Java里除了基础类型全是引用）\n\nlua 5.3.X 版本 table 遍历问题直接看结论：\nlua 5.3.X 版本中 hashint (64bit) 的实现有问题，5.4.X 版本修改问题，速度提升很多\nvia: https://www.cnblogs.com/coding-my-life/p/16990992.html\n\npre\n压测发现 lua malloc 占用比较高\n\n裸的程序考虑载入 tcmalloc 试试\n\n然后看到占用较高的是\n+ 26.50%  25.29% XXXX XXXX [.] luaH_next+ 13.47%  12.18% XXXX XXXX [.] luaV_equalobj\n\n查资料知道:\n\nluaH_next 是遍历 hash table 的\nluaV_equalobj 是比较两个对象是否相等\n\n\n起初是怀疑lua代码实现上有太多 for one pairs(table) do 这种，但是程序载入的 lua 量太大了，排查遍历热点太困难了\n\n机器上装了lua相关的东西，就想先试试多大的量会引起性能热点\ntest_table = &#123;&#125;for i = 1, 200000 do  test_table[i] = iendfor one in pairs(test_table) doend\n实际测试下来，20W的量级时间消耗也几乎可以忽略（20W是实际业务上最大的一块对象，全服怪物对象，实际没有接口可以拿到全服怪物对象列表）\n\n又怀疑是 lua 有循环套循环的情况，一样陷入僵局，代码量很大想排查这个太麻烦了\n\n转到 luaV_equalobj 的热点问题上\n\n如上查到相关问题，修改测试代码 test_table[i] = i -&gt; test_table[i &lt;&lt; 32] = i\n\n复现问题，替换lua版本重新测试\n\nluaH_next 热点仍在\nluaV_equalobj 已经消失\n\n\n\nstd::set 构造问题pre\n前面压测 500 人在线已经基本稳定，被要求先处理启动问题\n\n先用 timer_cost 分段打印启动耗时class timer_cost &#123;private:  std::chrono::time_point&lt;std::chrono::high_resolution_clock&gt; _last;public:  timer_cost() : _last(std::chrono::high_resolution_clock::now()) &#123;&#125;  void print(std::string &amp;&amp;msg, bool reset = true) &#123;    auto end = std::chrono::high_resolution_clock::now();    auto dur =        std::chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(end - _last);    std::cout &lt;&lt; msg &lt;&lt; &quot; : &quot; &lt;&lt; dur.count() &lt;&lt; &quot; ns&quot; &lt;&lt; std::endl;    if (reset) &#123;      _last = std::chrono::high_resolution_clock::now();    &#125;  &#125;&#125;;\n地图实例化时基于配置数据拷贝时间耗时很大\n因为地图很大 1000 * 1000 很常见，而最初阻挡信息是标记在一个 cell 上的，也就是每张地图都拷贝了 大小 &#x3D; 1000 * 1000 cell 的容器\n\n怀疑是 vector 拷贝写法问题，压测了几种写法差异\n#include &lt;vector&gt;#include &lt;cstring&gt;static const int64_t N = 1000000;static const int64_t M = N - 1;static const std::vector&lt;int64_t&gt; vec = []()&#123;  std::vector&lt;int64_t&gt; vec;  vec.resize(N);  for (int i = 0; i &lt; N; i++) &#123;      vec[i] = i;  &#125;  return vec;&#125;();void func1(benchmark::State&amp; state) &#123;  for (auto _ : state) &#123;    std::vector&lt;int64_t&gt; dst;    dst.reserve(M);    std::copy(vec.begin(), vec.begin() + M, dst.begin());    benchmark::DoNotOptimize(dst);  &#125;&#125;BENCHMARK(func1);void func2(benchmark::State&amp; state) &#123;  for (auto _ : state) &#123;    std::vector&lt;int64_t&gt; dst;    dst.resize(M);    memcpy(&amp;dst[0], &amp;vec[0], M * sizeof(int64_t));    benchmark::DoNotOptimize(dst);  &#125;&#125;BENCHMARK(func2);void func3(benchmark::State&amp; state) &#123;  for (auto _ : state) &#123;    std::vector&lt;int64_t&gt; dst(vec);    dst.reserve(M);    benchmark::DoNotOptimize(dst);  &#125;&#125;BENCHMARK(func3);void func4(benchmark::State&amp; state) &#123;  for (auto _ : state) &#123;    std::vector&lt;int64_t&gt; dst(vec.begin(), vec.end());    benchmark::DoNotOptimize(dst);  &#125;&#125;BENCHMARK(func4);void func5(benchmark::State&amp; state) &#123;  for (auto _ : state) &#123;    std::vector&lt;int64_t&gt; dst(M);    std::copy(vec.begin(), vec.begin() + M, dst.begin());    benchmark::DoNotOptimize(dst);  &#125;&#125;BENCHMARK(func5);\n\n\n程序也用了正确的方式\n\n加中断挂 perf 工具\n\n\nstd::getchar();\n\n\n看到耗时点是 cell 结构里一个 std::unique_ptr&lt;std::set&lt;uint64_t&gt;&gt; 的数据成员….容器成本很高\n这个在从源数据做拷贝的时候是不需要拷贝的，注释掉之后性能提升\n\nstd::future wait\nhttps://stackoverflow.com/questions/10890242/get-the-status-of-a-stdfuture?rq=4\n\nhttps://wandbox.org/permlink/Z1arsDE7eHW9JrqJ\n\n实际测试 c++11 版本 没有设置的 future: f.wait_until(chrono::system_clock::time_point::min()); 快近300倍；MSVC平台并不明显\n\n这里遗留了一个问题，异步任务完成后的同步信号；\n\n例如使用 std::async，返回 std::future，如果持有这个返回值 wait_for/wait_until，用来等待的线程仍然是阻塞的\n前面做测试是丢了一个容器到线程任务里，完成任务存入容器，主线程消费容器内容，但是这个容器是需要加锁的\n最好的方式是协程的写法，无奈公司技术比较老\n\n\n\n内存分配器 TODO\n测试中发现msvc&#x2F;gcc下内存实际占用差异很大（windows 7GB，linux 3.5GB）\n\n代码没有注意过内存对齐的问题，基础类型、容器、对象都是随意放的，这些改起来量太大了\nstruct x &#123;  int _int;  float _float;&#125;;struct xx : public x &#123;  std::vector&lt;int&gt; _vector_int&#125;sizeof(x) // msvc: 8, gcc: 8sizeof(xx) // msvc: 40, gcc: 32\n\n测试过程中也发现 msvc 的内存分配速度相比更慢（gcc下用了tcmalloc）\n\nmsvc 取 gperftools 里的 tcmalloc_minimal 做了替换，反而拖慢了速度，内存占用更小了（约 4GB），但是当前速度更重要\n\ntcmalloc windows: https://github.com/gperftools/gperftools/blob/master/README_windows.txt\n\nmimalloc 微软开发的内存分配器，发现性能也没有更好\n\nmimalloc windows: https://github.com/microsoft/mimalloc\n\n\n","categories":["备忘"],"tags":["C++","日记"]},{"title":"优化Tips","url":"/archives/c40e739.html","content":"Optimizing Tips某次给内部同事的分享前提：先编写正确的代码，再优化\n先完成需求，实现业务内容，先让程序跑起来\n可能在做单元测试的过程中就可以看出哪个函数被频繁调用了，哪个逻辑做多了遍历或者搜索\n然后分析以发现瓶颈（热点），并消除瓶颈（热点）\n这样得到的成效往往是最直接和明确的\n优化的顺序：要么先消除最大的那个热点，要么先消除一眼就可以改掉的那个热点\n通常到最后是需要靠算法上的优化消除那个遗留下来的最麻烦的点，做这件事情的时候如果拿不准，就先多做粒度比较小的压测，找到适合的方式\n\n优化核心：\n缓存命中、复用\nL 级缓存的命中\n复用避免拷贝\n\n\n原子单位\n避免时间片跳出\n\n\n汇编指令重排\n重排指令\n跳转、压栈、出栈的优化\n\n\nIO异步\n与其他设备级（网卡、磁盘等）交互的异步化\n\n\n\n循环调用：for each (auto&amp; one : range(1, 100)) &#123;  caller();&#125;\n\ncaller() &#123;  for each (auto&amp; one : range(1, 100)) &#123;  &#125;&#125;\n\n\n↓↓↓\n\n函数调用需要两次跳转，还会有堆栈内存操作（参数&#x2F;返回值&#x2F;临时变量压栈出栈）\n\n优先使用迭代循环（相对递归来说），由于函数调用的栈空间是在出函数体才释放的，递归层级太深会导致栈溢出\n\n可以使用（短的）内联函数消除函数跳转问题\n\n循环内避免动态分配内存（new&#x2F;malloc）对于所有内存模型ptmalloc&#x2F;tcmalloc&#x2F;jmalloc这个动作很可能是要加锁的，循环本身是个cpu密集的行为，想象每次循环都被lock一下会怎么样？\n\n可跳出的循环，尽量提早跳出，break&#x2F;return\n\n\n遍历：int array[__line][__row] = &#123;&#123;...&#125;, &#123;...&#125; ...&#125;;\n\nfor (unsigned i : __line) &#123;  for (unsigned j : __row) &#123;    array[i][j];  &#125;&#125;\n\nfor (unsigned j : __row) &#123;  for (unsigned i : __line) &#123;    array[i][j];  &#125;&#125;\n\n\n↓↓↓\n数组的空间是连续的，也就是内存是连续的，顺序的访问内存和乱序（随机、跳转）访问内存性能差别很大\narray[i][j] 和 array[i][j+1] 相邻\narray[i][j] 和 array[i+1][j] 很远\n\nconst std::vector&lt;...&gt;&amp; get_all() const &#123;  return _all;&#125;const auto&amp; all = get_all();   // 这里也是需要 const &amp; 取返回值的for (const auto&amp; one : all) &#123;  // 这里也是需要 const &amp; 取迭代内容的  if (!checker(one)) continue;  ...&#125;\n\nconst std::vector&lt;...&gt;&amp; get_all_filter(std::function&lt;bool(...)&gt;&amp;&amp; checker) const &#123;  static std::vector&lt;...&gt; result;  result.clear();  for (const auto&amp; one : all) &#123;    if (checker(one))      result.push_back(one);  &#125;  return result;&#125;const auto&amp; all = get_all_filter()for (const auto&amp; one : all) &#123;  ...&#125;\n\n\n↓↓↓\n试想为什么有些程序会定义 attr 的宏来限制对数据成员的操作只有 get&#x2F;set\n\n判断：\n如果不是要检查每种条件，把if… else if… else…换成switch语句，编译器对swich更容易做优化，特别是switch常量那种\nif 首先判断经常发生的情况\n\nif (men) &#123;  ...&#125; else if (women) &#123;  ...&#125; else &#123; // other?  ...&#125;\n\n提前退出：\n循环&#x2F;遍历&#x2F;迭代很多时候都是可以提前退出的，很多逻辑在纸上写（画）和代码写是两个思路\n\n尽量少的参数数量：\n简单类型的参数，如果数量足够少，尺寸足够小，会被压到寄存器里面，特别是外层有循环迭代的情况，寄存器访问比内存访问快的多\n如果是仅函数内部使用的参数，使用std::move()，\n如果是其他参数，使用 const xx&amp; (不可被改变), xx&amp; (可被改变)\n\n尽量少的局部变量：\n（同参数解释）\n局部变量如果是在一个空间内使用的 {}, 在空间内声明，比如 if { int a &#x3D; 0; }\n局部变量一样，声明必带初始化（不要相信编译器对常规变量的默认初始化）\n\n尽量简单的返回值：（std::move语义）尽量使用引用传递参数&#x2F;返回值：（对于成员变量）\n作为参数，想不到有什么场景是需要以值传递的…\n返回值需要关注是否在函数退出会被释放（栈空间），如果是可以用 static修饰\nstl clear 语义比 construct 语义快很多\nswap 语义一般是用新对象覆盖，不同的方式开销不一样，再讨论…\n如果知道容器需要的容量，提前 reserve，特别是 vector这种容器，所以新标准有了 array\n\n容器\n定长容器虽然有限制，但是对内存更友好;如果是可以预估数量级的数据，优先使用定长容器或者reserve(https://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html)\nstd::unordered_map 相比 std::map时间复杂度更低，但是是在较大的数据量上；较小的数据量，较复杂的key（长std::string）带来的hash消耗会导致std::unordered_map不如std::map更快\n同理 std::unordered_set std::set\n嵌套的容器在语义和理解上都更不友好，添加 make_key 方法 -&gt;std::string, std::tuple, user-define struct\n如果 make_key 需要hash，尽量用主流的hash算法，注意碰撞和算法本身的消耗\n一般情况 user-define struct 都可以被 std::tuple替代，虽然缺少了struct明确的语义，但是std::tuple的可展开性更容易写通用的hash函数\nsee:https://www.boost.org/doc/libs/1_35_0/doc/html/boost/hash_combine_id241013.html\n\n轻量化调用链路： （这只是一个更清楚的感受）call_a(...);call_b(...);call_c(...);\n\nfunction call_b(...) &#123;  call_c(...);&#125;function call_a(...) &#123;  call_b(...);&#125;call_a(...);\n\n虚函数：\n虚函数比普通函数调用的代价高很多… 这个是必要的么？ 参考 CRTP\n虚函数相比普通函数调用的代价从cpu crycle 来看并没有高多少；只是多了一次虚表查询，但是这个查询的代价可以被认为是固定的（虚函数表指针（vptr）则存放在类对象最前面的位置，即对象内存布局的最前面）\n但虚函数的问题是：\n虚函数被滥用了，看到很多同学做设计时把继承于基类对象的所有方法都定义为虚函数（为了使用时只用基类类型就可以），这会导致虚函数表的膨胀，增加内存消耗，增加内存访问的消耗\n虚函数不能像普通函数一样在编译期被优化 （inline&#x2F;constexpr）\n\n\n\n// crtp 不是灵丹妙药，模板的引入导致引入了更多类型；这只是反virtual的的宣誓。（当然他的性能确实更好）// The Curiously Recurring Template Pattern (CRTP)template &lt;class T&gt;class Base &#123;  // methods within Base can use template to access members of Derived&#125;;class Derived : public Base&lt;Derived&gt; &#123;  // ...&#125;;\n\n\nsee:https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern\n\n明确类型：\n数据处理上尽量明确类型，避免 cast\n不同数据类型所需要的空间是不一样的，甚至缓存他们的寄存器都不一样(int&#x2F;float)\n每次cast都相当于要检查寄存器空间，甚至切换寄存器\n\n\nsee: https://zh.wikipedia.org/wiki/%E5%AF%84%E5%AD%98%E5%99%A8\n\n构造函数：\n新标准有了默认初始化方式\n额外需要初始化的尽量写在初始化列表区，而不是构造的函数体\n不要相信默认构造函数\n加上右值构造，可能今后这个才更常被调用到\n\nclass abc &#123;  private:    int _a = 0;  // 1.    int _b;    int _c;  public:    explicit abc()      : _b(1), _c(2) &#123;  // 2.       // _a = 0; _b = 1; _c = 2; // 3.    &#125;&#125;;\n\n初始化：\n对象&#x2F;结构的声明直接做初始化\nabc abc_(1);\nabc abc_; abc_ &#x3D; …\n想要再编译器检查这个写法：explicit\nstl 的初始化，参考 std::initializer_list\n\n\n\n析构函数：\n构造析构是继承 override上基类和派生类命名不同的函数（其实他们的函数一个是没有函数名，一个是~）\n派生类析构后会调用基类的析构，但是如果基类没有虚析构，指向基类的对象就认为需要释放的只是他自己（虚表找不到析构）\n感谢编译器在基类virtual修饰的函数上默认派生类是可以不写 virtualoverride 的，但也造成了不清不楚的问题\n如果就是不想要虚析构，用 final 修饰你的结构\n\n数据运算\n数据运算尽量避免三元运算符\na = a + 1; // 如果可以，用 += 替换a += 1;    // -=, *=, /= 同理a = bool_ ? x : y;  // 三元运算符会产生额外的变量\n\n\n上面乍一看只是简单数据类型，一些新的编译器会做优化，但是如果a的类型是一个struct… 比如坐标点(x, y, z)\n+&#x3D; 相比 + 可以减少一次临时对象的分配\n同理 ++a, a++\n\n\nsee: https://en.wikipedia.org/wiki/Expression_templates\n\n\n数据类型：\n数据在内存里操作的最小单位是4字节(int)，int8, int16,如果涉及计算，会被用4字节空间计算，然后再转化成对应类型；所以才有代码用8, 16 类型只做常量声明\n\nrename:\n一定有必要 rename 数据类型么？如果需要，语言层面 using更好看（相比类外的 typedef，甚至 #define）\n\nclass string_view &#123;public:  using value_type = char;  using pointer = char*;  using const_pointer = const char*;&#125;;\n\nauto delete:\n如果 std::shared_ptr&lt;&gt; 不是所有人都接受的新内容（被遗忘的std::weak_ptr&lt;&gt;）\n\nstd::unique_ptr&lt;&gt;一定可以让你的代码更干净，毕竟更多的情况不是内存申请出来就可以继续使用的\nstd::unique_ptr&lt;abc&gt; abc_(new abc());if (!abc_-&gt;testOK(...) || !testOK(abc_)) &#123;  ...  // delete abc;&#125;\n\ntemplate&lt;typename _Ty&gt;std::shared_ptr&lt;_Ty&gt; make_shared_array(size_t size) &#123;  return std::shared_ptr&lt;_Ty&gt;(new _Ty[size], std::default_delete&lt;_Ty[]&gt;());&#125;template&lt;typename _Ty, class... Args&gt;inline typename std::enable_if&lt;!std::is_array&lt;_Ty&gt;::value, std::unique_ptr&lt;_Ty&gt;&gt;::type make_unique(Args&amp;&amp;... args) &#123;  return std::unique_ptr&lt;_Ty&gt;(new _Ty(std::forward&lt;Args&gt;(args)...));&#125;template&lt;typename _Ty&gt;inline typename std::enable_if&lt;std::is_array&lt;_Ty&gt;::value &amp;&amp; std::extent&lt;_Ty&gt;::value == 0, std::unique_ptr&lt;_Ty&gt;&gt;::typemake_unique(size_t size) &#123;  using _reTy = typename std::remove::extent&lt;_Ty&gt;::type;  return std::unique_ptr&lt;_Ty&gt;(new _reTy[size]());&#125;\n\n讨论：\nC++的引用类型是一种选择；而其他语言 java&#x2F;c#引用是唯一的选择（不要争执span，毕竟是会在编译期被提醒的），为什么？\n多态有静多态, 动多态；为什么？\ntypedef 初衷应该是为了明确语义，隐藏模板的侵入；不要让他污染了你的程序\nauto 并不能解析出 &amp; ，只是 auto x &#x3D;  -&gt; const type_x&amp; {…};是一个拷贝\n在纸上画结构，标记逻辑跳出点（纸上的逻辑比程序更清楚）\n在纸上列出已有的内容，和想求得的结果（纸上的算法优化比程序更直接）\n\n….- 避免繁复的设计。（架构设计是横向的，内容（实现）设计是纵向的，期望最终得到的是一个近似正方形）- 清理无用代码，除非很简单并且很可能被用到- 先想好怎么测试再开始- 关注方法论。\n\n附录：系统的各种延时：\n\n\n事件\n延迟\n相对事件比例\n\n\n\n1个CPU周期\n0.3 ns\n1 s\n\n\nL1 缓存访问\n0.9 ns\n3 s\n\n\nL2 缓存访问\n2.8 ns\n9 s\n\n\nL3 缓存访问\n12.9 ns\n43 s\n\n\n主存访问(从CPU访问DRAM)\n120 ns\n6 分\n\n\n固态硬盘I&#x2F;O(闪存)\n50-150 us\n2-6 天\n\n\n旋转磁盘I&#x2F;O\n1-10 ms\n1-12 月\n\n\n互联网：从旧金山到纽约\n40 ms\n4 年\n\n\n互联网：从旧金山到英国\n81 ms\n8 年\n\n\n互联网：从旧金山到澳大利亚\n183 ms\n19 年\n\n\nTCP 包重传\n1-3 s\n105-317 年\n\n\nOS 虚拟化系统重启\n4 s\n423 年\n\n\nSCSI 命令超时\n30 s\n3 千年\n\n\n硬件虚拟化系统重启\n40 s\n4 千年\n\n\n物理系统重启\n5 m\n32 千年\n\n\n物理距离-&gt;网速基准值推算公式：\n光速：299792458 m&#x2F;s -&gt; 300000 km&#x2F;s\n光纤是经物理介质的，理论值会比光经空气慢；一般简化用 200000 km&#x2F;s为参考\neg. 新加坡 - 美弗吉尼亚 物理距离: 15000 km；单程时间：15000 &#x2F; 200000* 1000 &#x3D; 75 ms；RTT（ping）约 150 ms\n\n术语：\nIOPS:每秒发生的输入&#x2F;输出操作的次数，是数据传说的一个对量方法。对于磁盘的读写，IOPS指的是每秒读和写的次数。\n吞吐量:评价工作执行的速率，尤其是在数据传输方面，这个属于用于描述数据传输速度（字节&#x2F;秒或者比特&#x2F;秒）。再某些情况下（如数据库），吞吐量指的是操作的速度（每秒操作数或每秒业务数）\n相应时间:一次操作完成的时间。包括用于等待和服务的时间，也包括用来返回结果的时间。\n延时:延时是描述操作里用来等待服务的时间。再某些情况下，它可以指的是整个操作时间，等同于响应时间。\n使用率:对于服务所请求的资源，使用率描述再所给定的时间区间内资源的繁忙程度。对于存储资源来说，使用率指的就是所消耗的存储容量（例如，内存使用率）。\n饱和度: 指的是某一资源无法满足服务的排队工作量。\n瓶颈:在系统性能里，瓶颈指的是限制系统性能的那个资源。分辨和移除系统瓶颈是系统性能的一项重要工作。\n工作负载:系统的输入或者是对系统所时间的负载叫做工作负载。对于数据库来说，工作负载就是客户端发出的数据库请求和命令。\n缓存:用于复制或者缓冲一定量数据的高速存储区域，目的是为了避免对较慢的存储层级的直接访问，从而提高性能。出于经济考虑，缓存区的容量要比更慢以及的存储容量要小。\n\n目标\n延时：低应用响应时间\n吞吐量：高应用程序操作率或者数据传输率\n资源使用率：对于给定应用程序工作负载，高效的使用资源\n\n大O标记法\n\n\n标记法\n举例\n\n\n\nO(1)\n布尔判断\n\n\nO(logn)\n顺序队列的二分搜索\n\n\nO(n)\n链表的线性搜索\n\n\nO(nlogn)\n快速排序（一般情况）\n\n\nO(n^2)\n冒泡排序（一般情况）\n\n\nO(2^n)\n分解质因数；指数增长\n\n\nO(n!)\n旅行商人问题的穷举法\n\n\n参考\n\nhttp://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/\n\n","categories":["知识备忘"],"tags":["C++"]},{"title":"C++ std::function & lambda 性能损失","url":"/archives/b61fb416.html","content":"pre\n习惯 std::function 作为参数参与函数过滤、操作等，起初怀疑 std::function 性能应该是比 inline function 低\n查到相关资料：https://stackoverflow.com/questions/42856707/can-be-stdfunction-inlined-or-should-i-use-different-approach\n\n以下是基于上述问题做的测试，结果：\n\n\nstd::function 相当于一次 virtual function 的调用成本\n\n\n\n如果可能，auto arg / template 是接近原始调用的\n\n\n\n否则：lambda 是一个更好的选择\n\n\n\n代码static const unsigned N = 10;struct loop3_lambda &#123;  static void impl() &#123;    double sum = 0.0;    const auto fn = [](double a, double b, double c) &#123;      const auto subFn = [](double x, double y) &#123; return x / (y + 1); &#125;;      return sin(a) + log(subFn(b, c));    &#125;;    for (unsigned i = 1; i &lt;= N; ++i) &#123;      for (unsigned j = 1; j &lt;= N; ++j) &#123;        for (unsigned k = 1; k &lt;= N; ++k) &#123;          sum += fn(i, j, k);        &#125;      &#125;    &#125;  &#125;&#125;;struct loop3_function &#123;  static void impl() &#123;    double sum = 0.0;    const std::function&lt;double(double, double, double)&gt; fn = [](double a, double b, double c) &#123;      const auto subFn = [](double x, double y) &#123; return x / (y + 1); &#125;;      return sin(a) + log(subFn(b, c));    &#125;;    for (unsigned i = 1; i &lt;= N; ++i) &#123;      for (unsigned j = 1; j &lt;= N; ++j) &#123;        for (unsigned k = 1; k &lt;= N; ++k) &#123;          sum += fn(i, j, k);        &#125;      &#125;    &#125;  &#125;&#125;;struct loop3_template &#123;  template &lt;class func_tt, class... args_tt&gt; static void impl(func_tt&amp;&amp; func, args_tt&amp;&amp; ... args) &#123;    double sum = 0.0;    for (unsigned i = 1; i &lt;= N; ++i) &#123;      for (unsigned j = 1; j &lt;= N; ++j) &#123;        for (unsigned k = 1; k &lt;= N; ++k) &#123;          sum += func(i, j, k);        &#125;      &#125;    &#125;  &#125;&#125;;struct loop3_function_arg &#123;  static void impl(std::function&lt;double(double, double, double)&gt;&amp;&amp; func) &#123;    double sum = 0.0;    for (unsigned i = 1; i &lt;= N; ++i) &#123;      for (unsigned j = 1; j &lt;= N; ++j) &#123;        for (unsigned k = 1; k &lt;= N; ++k) &#123;          sum += func(i, j, k);        &#125;      &#125;    &#125;  &#125;&#125;;struct loop3_function_2_lambda &#123;  static void impl(std::function&lt;double(double, double, double)&gt; &amp;&amp;func) &#123;    double sum = 0.0;    const auto lambda_call = [func](double a, double b, double c) &#123;      return func(a, b, c);    &#125;;    for (unsigned i = 1; i &lt;= N; ++i) &#123;      for (unsigned j = 1; j &lt;= N; ++j) &#123;        for (unsigned k = 1; k &lt;= N; ++k) &#123;          sum += lambda_call(i, j, k);        &#125;      &#125;    &#125;  &#125;&#125;;struct loop3_auto &#123;  static void impl(auto &amp;&amp;func) &#123;    double sum = 0.0;    for (unsigned i = 1; i &lt;= N; ++i) &#123;      for (unsigned j = 1; j &lt;= N; ++j) &#123;        for (unsigned k = 1; k &lt;= N; ++k) &#123;          sum += func(i, j, k);        &#125;      &#125;    &#125;  &#125;&#125;;struct loop3_raw &#123;  static void impl() &#123;    double sum = 0.0;    for (unsigned i = 1; i &lt;= N; ++i) &#123;      for (unsigned j = 1; j &lt;= N; ++j) &#123;        for (unsigned k = 1; k &lt;= N; ++k) &#123;          sum += sin((double)i) + log((double)j / (k + 1));        &#125;      &#125;    &#125;  &#125;&#125;;static void loop3_lambda_test(benchmark::State &amp;state) &#123;  for (auto _ : state) &#123;    loop3_lambda::impl();  &#125;&#125;static void loop3_function_test(benchmark::State &amp;state) &#123;  for (auto _ : state) &#123;    loop3_function::impl();  &#125;&#125;static void loop3_template_test(benchmark::State &amp;state) &#123;  for (auto _ : state) &#123;    loop3_template::impl([](double a, double b, double c) &#123;      const auto subFn = [](double x, double y) &#123; return x / (y + 1); &#125;;      return sin(a) + log(subFn(b, c));    &#125;);  &#125;&#125;static void loop3_function_arg_test(benchmark::State &amp;state) &#123;  for (auto _ : state) &#123;    loop3_function_arg::impl([](double a, double b, double c) &#123;      const auto subFn = [](double x, double y) &#123; return x / (y + 1); &#125;;      return sin(a) + log(subFn(b, c));    &#125;);  &#125;&#125;static void loop3_function_2_lambda_test(benchmark::State &amp;state) &#123;  for (auto _ : state) &#123;    loop3_function_2_lambda::impl([](double a, double b, double c) &#123;      const auto subFn = [](double x, double y) &#123; return x / (y + 1); &#125;;      return sin(a) + log(subFn(b, c));    &#125;);  &#125;&#125;static void loop3_auto_test(benchmark::State &amp;state) &#123;  for (auto _ : state) &#123;    loop3_auto::impl([](double a, double b, double c) &#123;      const auto subFn = [](double x, double y) &#123; return x / (y + 1); &#125;;      return sin(a) + log(subFn(b, c));    &#125;);  &#125;&#125;static void loop3_raw_test(benchmark::State &amp;state) &#123;  for (auto _ : state) &#123;    loop3_raw::impl();  &#125;&#125;BENCHMARK(loop3_lambda_test);BENCHMARK(loop3_function_test);BENCHMARK(loop3_template_test);BENCHMARK(loop3_function_arg_test);BENCHMARK(loop3_function_2_lambda_test);BENCHMARK(loop3_auto_test);BENCHMARK(loop3_raw_test);","categories":["代码"],"tags":["C++"]},{"title":"草稿: 35岁游戏服务端开发","url":"/archives/ae45068e.html","content":"pre\n关于35岁失业，去年找工作时实际感受到这个问题\n临近35岁，有觉得我要求薪资太高的，也可能有觉得我已经熬不住加班的，当然更主要是技能点还不够强\n记录一些所见和想法\n\n1. 这个行业失败率很高\n互联网是个变化很快的行业，特别是游戏\n玩家对游戏的依赖程度是远小于微信、微博、知乎这类有新鲜新奇资讯的产品\n\n2. 技术迭代的速度+知识获取的便捷\n用10年前的知识体系、思维方式，去学习、理解新的东西很多时候是行不通或者很难的\n而这些知识或者理解这些内容所需要的思维结构是新一代上学时候就学习、接受到的内容\n这已经不是一个纯基础学科，更多的东西是依赖现有技术、框架的组合、组装，大家不用太关心底层的内容，大部分时间也遇不到底层的问题\n一个老程序如果不是一直紧跟技术的迭代，学习理解的速度比年轻的同学更慢\n举个例子上次和朋友聊天听到他家10岁上小学的小朋友已经在参加计算机相关考证了，而我上大学是从打字开始学习的\n\n3. 硬件成本更低，语言、编译器更先进\n即使不是更优方案也能跑起来\n新的语言更简单，学习成本也更低，商业期待更快的产出\n对比《超级马里奥》一个只有几十KB的游戏（好像是32+8？），当前的游戏随便就上G\n服务端也是，之前受32bits系统、带宽限制，内存、字节流上的优化都很精细\n\n4. 我们不期待在游戏里见到更多人了，玩游戏这件事情逐渐更像是一个自娱自乐的避风港\n喜欢竞技类的有moba、吃鸡\n其他时候更喜欢《塞尔达》、《原神》这种独处放松的环境\n这导致游戏服务端的比重降低\n\n5. 性格更固定，自我追求更明确，改变？\n有了家庭生活成本的压力在精力被分散\n年轻的时候都觉得身体有用不完的力气，年纪越大越觉得精力会因为没有年轻时的体格变得更差，\n部分中国管理者是一个奴役主的心态，结了婚的好欺负、有房贷的好欺负，压迫着卷加班卷绩效；好像追求美好生活变成了束缚自己的锁链\n\n6. 10年工作经验的价值：\n设计、架构上快速熟悉、理解的能力\n对风险、瓶颈点的预判、把握\n业务熟悉度在理解需求上的优势\n\n7. 觉得刚毕业或者只有1-2年工作经验的同学花大量时间在熟悉现有架构、编程习惯上\n之前学习的过程可能更像是在很宽的桌子上搭积木，而工作把他们框在一个窄盒子里；\n\n8. 还有就是对业务需求的理解上\n这个点我觉得有待提高的是这个行业整体产品、策划的设计表述能力（如果不是你就照这个样子抄的场景）\n\n9. 35+的开发者守着10年前的技术不做更新\n或想稳定自己的位置，或没有学习的欲望和精力，或因为古老项目不想平添风险；恶性循环，被淘汰\n关注技术革新，也不说跟上技术革新了，可是要关注这些东西，敢于尝试应用，不是从0-1的创造而是应用，技术变化是向着更简单、高效、优解的，关注并应用可以让我们更轻松\n锻炼身体，保持身体机能\n\n","categories":["职场"],"tags":["记录","职场"]},{"title":"草稿: c++ defer 实现","url":"/archives/629ebde7.html","content":"一个最简单的 defer 实现\n主要是测试了 template function args 的闭包传输\n其中 mutable 是关键，不然编译都是forward类型的报错\n另外 std::invoke 是低开销的\n\nclass defer : std::shared_ptr&lt;defer&gt; &#123;public:  template &lt;class function_tt, class... args_tt&gt;  explicit defer(function_tt &amp;&amp;func, args_tt &amp;&amp;...args)      : std::shared_ptr&lt;defer&gt;(            nullptr, [func = std::forward&lt;function_tt&gt;(func),                      ...args = std::forward&lt;args_tt&gt;(args)](defer *) mutable &#123;              std::invoke(std::forward&lt;function_tt&gt;(func), std::forward&lt;args_tt&gt;(args)...);            &#125;) &#123;&#125;&#125;;int main(int argc, char *argv[]) &#123;  &#123;    int x = 1;    &#123;      defer def(          [&amp;](int, int) &#123;        std::cout &lt;&lt; x &lt;&lt; &quot;\\n&quot;;        x = 10;      &#125;, 1, 2);      // defer def([](int &amp;xy) &#123; std::cout &lt;&lt; xy &lt;&lt; &quot;\\n&quot;; &#125;, std::ref(x));    &#125;    std::cout &lt;&lt; x &lt;&lt; std::endl;  &#125;&#125;\n\n\n结果：110\n\n","categories":["代码"],"tags":["C++"]},{"title":"零碎的：nlohmann json build error: LNK2019","url":"/archives/a113327a.html","content":"描述\nnlohmann 本身是 header-only 的方式，A 引入版本 3.11, B 引入版本 3.10；可能会导致 同时引入 A, B 的工程 C 出现混用版本的不兼容问题；\nnlohmann 把 namespace 做成了带版本号的方式\n\n// player.hclass player : public std::enable_shared_from_this&lt;player&gt; &#123;public:  using uuid = std::uint64_t;  static constexpr uuid invalid_uuid = -1;public:  player(uuid id) : _uuid(id) &#123;&#125;  ~player() = default;  static std::shared_ptr&lt;sz::player&gt; create_player(player::uuid id,                                        const nlohmann::json &amp;json_data);&#125;;// player.cpp#includestd::shared_ptr&lt;sz::player&gt;player::create_player(player::uuid id, const nlohmann::json &amp;json_data) &#123;  ...&#125;\nSeverity\tCode\tDescription\tProject\tFile\tLine\tSuppression StateError\tLNK2019\tunresolved external symbol &quot;public: static class std::shared_ptr&lt;class sz::player&gt; __cdecl sz::player::create_player(unsigned __int64,class nlohmann::json_abi_v3_11_2::basic_json&lt;class std::map,class std::vector,class std::basic_string&lt;char,struct std::char_traits&lt;char&gt;,class std::allocator&lt;char&gt; &gt;,bool,__int64,unsigned __int64,double,class std::allocator,struct nlohmann::json_abi_v3_11_2::adl_serializer,class std::vector&lt;unsigned char,class std::allocator&lt;unsigned char&gt; &gt;,void&gt; const &amp;)&quot; (?create_player@player@sz@@SA?AV?$shared_ptr@Vplayer@sz@@@std@@_KAEBV?$basic_json@Vmap@std@@Vvector@2@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@2@_N_J_KNVallocator@2@Uadl_serializer@json_abi_v3_11_2@nlohmann@@V?$vector@EV?$allocator@E@std@@@2@X@json_abi_v3_11_2@nlohmann@@@Z) referenced in function &quot;public: static class std::shared_ptr&lt;class sz::battle::room&gt; __cdecl sz::battle::room::create(class std::basic_string_view&lt;char,struct std::char_traits&lt;char&gt; &gt;,class std::basic_string_view&lt;char,struct std::char_traits&lt;char&gt; &gt;)&quot; (?create@room@battle@sz@@SA?AV?$shared_ptr@Vroom@battle@sz@@@std@@V?$basic_string_view@DU?$char_traits@D@std@@@5@0@Z)\tgame-service\tD:\\sz_service\\game-service\\game-service\\battle.obj\t1\n\n解决办法\n统一版本。\n例如当前项目引入了 behaviortree_cpp 4.6.1 (json 版本3.11.3)\n自己单独引入了 nlohmann&#x2F;json (json 版本3.11.2)\n把自己引入的json也替换成 3.11.3 版本\n\n\n当然如果可以只用一处json最好，但是这样会涉及改动引入第三方库的文件，具体使用哪种方式统一版本根据具体情况选择\n\n参考资料\nhttps://github.com/luxonis/depthai-core/issues/630\nhttps://json.nlohmann.me/features/namespace/#structure\n\n","categories":["代码"],"tags":["C++"]},{"title":"时间轮定时器：step by step","url":"/archives/4ab88357.html","content":"pre\n原来写过一篇相关内容，后头一看实在太简要了，有些东西自己都不记得为啥这么写了\n现在重新写一篇，详细一点 step by step\n\n定时器\n游戏里定时器简直是不可或缺的东西，比如技能冷却、怪物刷新、玩家心跳等等\n定时器一般分为两类：单次定时器和周期定时器\n单次定时器：定时器到时间后，执行一次回调函数，然后销毁\n周期定时器：定时器到时间后，执行一次回调函数，然后重新计时\n\n\n游戏里定时器的精度一般要求在毫秒(1-500ms)级别\n常见游戏类型已经精度控制：\nFPS、赛车实时游戏：精度要求高，一般要求在1-5ms级别\nMMO游戏：精度要求一般，一般要求在200ms级别，怪物傻一点在400-500ms\nARPG游戏：精度要求比MMO高，一般要求在50ms级别？\n\n\n定时器的通用需求：\n排序的\n没有空间限制的\n最大可能保持精度\n对CPU、内存没有太大压力\n\n\n上述要求看好像排序的容器就可以满足需求（set, priority_queue），也有不少介绍定时器的是用最小堆这样的容器实现的，但是这种排序容器在插入的时候有时间复杂度\n想做到O(1)的插入时间复杂度，首先需要用到数组，假设定义一个3600长度的数组，每个下标代表1s的刻度，那这个数组最多容纳3600秒范围内的定时器，超过这个时间的就塞不进去了\n\n时间轮-定时器\n在我理解，时间轮核心内容是轮子的复用\n\n标准时间\n日常表述：(秒级)\n\n\n\n钟表表示：\n\n\n\n程序表述：\n程序用时间戳(timestamp)表示时间，这里我们依然只用秒级\n有了上面钟表表示的方式，这里的程序表示需要被分片到钟表上：把时间戳切成一个个数字（这里为了更直观用的是 % 10 的方式）（如下图）\n\n\n\n\n\n上面相差的时间：2秒，49秒在程序里差异的数字分别是：（红框、橙框）\n\n\n\n差值用程序的写法：-- 49秒....(04031 + 49) / 10 / 10 / 10 / 10 % 10 = 0 没有变更(4031 + 49) / 10 / 10 / 10 % 10 = 4 没有变更(031 + 49) / 10 / 10 % 10 = 0 没有变更(31 + 49) / 10 % 10 = 8(1 + 49) % 10 = 0\n\n\n\n好像时间轮已经快出来了，这就是根据差值，把一个新的定时任务插入到时间轮的写法了：\n\n// cpp: xx 插入到时间轮clock cc(current_ts);clock cn(next_ts);if (cn._0 != cc._0) &#123;    wheel[cn._0].add(xx);&#125; else if (cn._1 != cc._1) &#123;    wheel[cn._1].add(xx);&#125; else if (cn._2 != cc._2) &#123;    wheel[cn._2].add(xx);&#125; else if (cn._3 != cc._3) &#123;    wheel[cn._3].add(xx);&#125; else &#123;  // 这里怎么办？？  // 我想只支持到 2100 年，也就是这里不会是超过32位的时间  // 也就只有 current_ts == next_ts 才会出现这种情况  // 那么也放到 最里面的轮子里就好&#125;\n\n\n其实写到这里看起来时间轮这个定时器已经写好了\n\n","categories":["代码"],"tags":["C++"]},{"title":"快速笔记:std::shared_ptr<void>","url":"/archives/8937f8a7.html","content":"linkhttps://stackoverflow.com/questions/5913396/why-do-stdshared-ptrvoid-work\ndescription\nshared_ptr 构造时保留了析构函数指针\n\n理论上子类析构可以没有 virtual 关键字，但是不建议\n\n因为C语言的习惯，还是觉得 std::shared_ptr&lt;void&gt; 不应是个好的选择\n\nstd::unique_ptr&lt;void&gt; 并不能做到 std::shared_ptr&lt;void&gt; 相同的效果，这是因为默认删除器(std::default_delete&lt;T&gt;)是针对完全类型的\ntemplate&lt;typename T&gt;struct default_delete &#123;  void operator()(T* ptr) const &#123;    delete ptr;  &#125;&#125;;\n\nstd::unique_ptr&lt;void&gt; ptr(new int(42)); // 错误！// error: invalid application of ‘delete’ to incomplete type ‘void’// 使用 lambda 表达式定义删除器auto deleter = [](void* ptr) &#123;  std::cout &lt;&lt; &quot;Custom lambda deleter called for pointer: &quot; &lt;&lt; ptr &lt;&lt; std::endl;  free(ptr); // 使用 free 释放内存&#125;;// 创建 std::unique_ptr&lt;void&gt;，使用 lambda 删除器std::unique_ptr&lt;void, decltype(deleter)&gt; ptr(malloc(100), deleter);\n\ncode#include &lt;memory&gt;#include &lt;iostream&gt;#include &lt;vector&gt;class test &#123;public:  test() &#123;    std::cout &lt;&lt; &quot;Test created&quot; &lt;&lt; std::endl;  &#125;  virtual ~test() &#123;    std::cout &lt;&lt; &quot;Test destroyed&quot; &lt;&lt; std::endl;  &#125;&#125;;class sub_test : public test &#123;public:  sub_test() &#123;    std::cout &lt;&lt; &quot;sub_test created&quot; &lt;&lt; std::endl;  &#125;  virtual ~sub_test() &#123;    std::cout &lt;&lt; &quot;sub_test destroyed&quot; &lt;&lt; std::endl;  &#125;&#125;;int main() &#123;  std::cout &lt;&lt; &quot;At begin of main.\\ncreating std::vector&lt;std::shared_ptr&lt;void&gt;&gt;&quot;            &lt;&lt; std::endl;  std::vector&lt;std::shared_ptr&lt;void&gt;&gt; v;  &#123;    std::cout &lt;&lt; &quot;Creating test&quot; &lt;&lt; std::endl;    v.push_back( std::shared_ptr&lt;test&gt;( new test() ) );    v.push_back( std::shared_ptr&lt;test&gt;( new sub_test() ) );    std::cout &lt;&lt; &quot;Leaving scope&quot; &lt;&lt; std::endl;  &#125;  std::cout &lt;&lt; &quot;-------------1&quot; &lt;&lt; std::endl;  v.pop_back();  // sub_test pop out  std::cout &lt;&lt; &quot;-------------2&quot; &lt;&lt; std::endl;  v.pop_back();  // test pop out  std::cout &lt;&lt; &quot;-------------3&quot; &lt;&lt; std::endl;  // std::unique_ptr&lt;void&gt;  auto test_st_deleter = [](void* ptr) &#123;    std::cout &lt;&lt; &quot;test struct deleter.&quot; &lt;&lt; std::endl;    // anything check ptr&#x27;s type    auto st_ptr = static_cast&lt;test*&gt;(ptr);    if (st_ptr) &#123;      delete st_ptr;      ptr = nullptr;      return;    &#125;    // anything else....  &#125;;  &#123;    std::cout &lt;&lt; &quot;Creating unique test&quot; &lt;&lt; std::endl;    std::unique_ptr&lt;void, decltype(test_st_deleter)&gt; u_ptr(new sub_test(), test_st_deleter);    std::cout &lt;&lt; &quot;Leaving unique scope&quot; &lt;&lt; std::endl;  &#125;  std::cout &lt;&lt; &quot;Leaving main&quot; &lt;&lt; std::endl;  return 0;&#125;// outputAt begin of main.creating std::vector&lt;std::shared_ptr&lt;void&gt;&gt;Creating testTest createdTest createdsub_test createdLeaving scope-------------1sub_test destroyedTest destroyed-------------2Test destroyed-------------3Creating unique testTest createdsub_test createdLeaving unique scopetest struct deleter.sub_test destroyedTest destroyedLeaving main","categories":["快速笔记"],"tags":["快速笔记","c++"]},{"title":"快速笔记:前置声明作为 map/unordered_map value 编译报错","url":"/archives/e121c7ba.html","content":"前置声明作为 unordered_map value 的编译报错：\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=92770\n\nhttps://gcc.godbolt.org/z/1nE5W9eh1\n\n\n#include &lt;map&gt;#include &lt;unordered_map&gt;#include &lt;memory&gt;struct st;class cx &#123;  std::map&lt;int, st&gt; maps;//   std::unordered_map&lt;int, st&gt; umaps;   // 这种在gcc 12.1 之前都不可以  std::unordered_map&lt;int, std::unique_ptr&lt;st&gt;&gt; umap_ptrs;&#125;;int main() &#123;    return 0;&#125;","categories":["快速笔记"],"tags":["快速笔记","c++"]},{"title":"游戏排行榜快速实现","url":"/archives/df49bf4d.html","content":"pre\n之前的排行榜实现为 std::vector&lt;rank_info&gt; + std::unordered_map&lt;player_id, rank_index&gt;\n问题1：每次更新排行榜需要全量排序，因为容器存储了具体角色的排名\n问题2：全量排序后需要全量存储\n没有引发灾难性的问题是因为排行榜最大尺寸只有100\n\n\n取舍：是否需要存储具体玩家所在排行榜的具体位置？\n当前游戏更多的操作是查看排行榜榜单，榜单数据无论是反序列化或者遍历拼ui的动作上都可以获得我具体的排名\n需要指定玩家具体排名数据是可以遍历榜单，时间复杂度O(N) 相比全量排序O(N^2)还是小的\n遍历的方式还可以优化（todo）\n\n\n\n快速重构\n最简单的方式 std::set\nset::iterator 是稳定的，只有erase动作有影响 https://en.cppreference.com/w/cpp/container#Iterator_invalidation#pragma once#include &lt;map&gt;#include &lt;string&gt;#include &lt;unordered_map&gt;#include &lt;unordered_set&gt;namespace rank &#123;class container_interface &#123; public:  virtual ~container_interface() = default;  // todo:  // virtual std::string serialize() = 0;  // virtual std::string unserialize() = 0;&#125;;template &lt;std::size_t count_vv, class sort_key_tt, class element_tt,          class element_key_tt, class compare_tt = std::less&lt;sort_key_tt&gt; &gt;class container : public container_interface &#123;  using sort_data =      std::map&lt;sort_key_tt, std::pair&lt;element_key_tt, element_tt&gt;, compare_tt&gt;;  using sort_data_iterator = typename sort_data::iterator; private:  const std::size_t _count = count_vv;  sort_data _data;  std::unordered_map&lt;element_key_tt, sort_data_iterator&gt; _elements;  std::unordered_set&lt;element_key_tt&gt; _dirty_elements; public:  container() = default;  container(compare_tt&amp;&amp; compare_call) : _data(compare_call) &#123;&#125;  ~container() override = default;  [[maybe_unused]] bool insert(const sort_key_tt&amp; skey, const element_tt&amp; ev, const element_key_tt&amp; ekey) &#123;    remove(ekey);    if (auto [data_it, res] = _data.emplace(skey, std::make_pair(ekey, ev));        res) &#123;      if (auto [ele_it, res] = _elements.emplace(ekey, data_it); res) &#123;        _dirty_elements.emplace(ekey);      &#125;    &#125;    while (_data.size() &gt; _count) &#123;      auto last_data_it = std::prev(_data.end());      remove(last_data_it-&gt;second.first);    &#125;    return exist(ekey);  &#125;  [[maybe_unused]] bool remove(const element_key_tt&amp; ekey) &#123;    if (const auto it = _elements.find(ekey); it != _elements.end()) &#123;      _dirty_elements.emplace(ekey);      _data.erase(it-&gt;second);      _elements.erase(it);      return true;    &#125;    return false;  &#125;  bool exist(const element_key_tt&amp; ekey) const &#123;    return _elements.contains(ekey);  &#125;&#125;;&#125;; // namespace rank\n测试代码namespace rank_test &#123;struct sort_key &#123;  uint32_t level = 0;  uint32_t exp = 0;  uint64_t ts = 0;  uint64_t auto_increment = 0;&#125;;using element_key = uint64_t;struct element_value &#123;  std::string name;&#125;;&#125;;  // namespace rank_testtemplate &lt;&gt;struct std::less&lt;rank_test::sort_key&gt; &#123;  bool operator()(const rank_test::sort_key&amp; left,                  const rank_test::sort_key&amp; right) const &#123;    return left.level &lt; right.level ||           (left.level == right.level &amp;&amp; left.exp &lt; right.exp) ||           (left.level == right.level &amp;&amp; left.exp == right.exp &amp;&amp;            left.ts &lt; right.ts) ||           (left.level == right.level &amp;&amp; left.exp == right.exp &amp;&amp;            left.ts == right.ts &amp;&amp; left.auto_increment &lt; right.auto_increment);  &#125;&#125;;template &lt;&gt;struct std::greater&lt;rank_test::sort_key&gt; &#123;  bool operator()(const rank_test::sort_key&amp; left,                  const rank_test::sort_key&amp; right) const &#123;    return left.level &gt; right.level ||           (left.level == right.level &amp;&amp; left.exp &gt; right.exp) ||           (left.level == right.level &amp;&amp; left.exp == right.exp &amp;&amp;            left.ts &gt; right.ts) ||           (left.level == right.level &amp;&amp; left.exp == right.exp &amp;&amp;            left.ts == right.ts &amp;&amp; left.auto_increment &gt; right.auto_increment);  &#125;&#125;;rank::container&lt;10, rank_test::sort_key, rank_test::element_value,                rank_test::element_key&gt;    rc;rank::container&lt;10, rank_test::sort_key, rank_test::element_value,                rank_test::element_key, std::greater&lt;rank_test::sort_key&gt;&gt;    rcg;for (int i = 0; i &lt; 100; ++i) &#123;  rank_test::sort_key sk&#123;1, 1, 1, i&#125;;  rank_test::element_value ev&#123;&quot;name_&quot; + std::to_string(i)&#125;;  rc.insert(sk, ev, i);  rcg.insert(sk, ev, i);&#125;\n\n至此都很美好，一个标准可用的排序容器\n新需求：lua 需要决定用哪些属性排序，并指定具体属性的顺序\n第一反应是：假设用 level, exp 双属性排序，想要得到 等级相同，经验大的排前面的样子，可以: level &lt;&lt; 32 | exp 得到一个新值作为 sort_key\n然而这种方式…策划不懂（或者只是觉得算着麻烦…）\n策划提出了想要的样子: 构建排行榜时给定 table[“level”] &#x3D; 升序&#x2F;降序; table[“exp”] &#x3D; 升序&#x2F;降序\n还是要实现….\n一个排序规则数据而已，但是容器本身只有 sort_key 的类型，排序是需要 operator &lt; 函数处理的…\n并且这里实现的 container 想作为一个单纯的容器使用，并不想引入外部特殊规则….只能想办法把数据引入到 compare_tt 里\n数据可以作为lambda的闭包： operator &lt; 使用lambda\nhttps://stackoverflow.com/questions/72673837/c11-how-to-use-lambda-as-type-parameter-where-it-requires-a-functor-type-l\n于是就有了：container(compare_tt&amp;&amp; compare_call) : _data(compare_call) &#123;&#125;\n\nnamespace lua_rank_test &#123;struct sort_key &#123;  std::unordered_map&lt;std::string, int64_t&gt; keys;&#125;;&#125;;  // namespace lua_rank_teststd::vector&lt;std::pair&lt;std::string, bool&gt;&gt; compares&#123;&#123;&quot;level&quot;, true&#125;,                                                   &#123;&quot;exp&quot;, true&#125;&#125;;auto lua_comp = [compares](const lua_rank_test::sort_key&amp; left,                           const lua_rank_test::sort_key&amp; right) &#123;  for (const auto&amp; one : compares) &#123;    auto lv = left.keys.at(one.first);    auto rv = right.keys.at(one.first);    if (lv == rv)      continue;    if (one.second)  // sort down      return lv &gt; rv;    return lv &lt; rv;  &#125;  return false;&#125;;rank::container&lt;10, rank_test::sort_key, rank_test::element_value,                rank_test::element_key, decltype(lua_comp)&gt;    rcl(lua_comp);\n\n明显有性能问题，但是先能跑吧\n\nset comparator exceptionvoid test_set() &#123;\tstruct info &#123;\t\tuint32_t id = 0;\t\tuint32_t seq = 0;\t\tuint32_t count = 0;\t\tbool operator &lt; (const info&amp; src) const &#123;\t\t\treturn count &lt;= src.count || seq &lt;= src.seq;\t\t&#125;\t&#125;;\tstd::set&lt;info&gt; set_info;\tset_info.emplace(info&#123;1, 1, 1&#125;);\tset_info.emplace(info&#123;1, 1, 1&#125;);&#125;// msvc环境：运行这段代码在第二个emplace处会抛出异常 invalid comparator// linux g++ 环境：暂时未发现问题// msvc 严格要求 1. 比较运算符不能因为插入顺序产生歧义 2. 相等的比较必须返回 false// 举例：先插入 &#123;1, 2, 1&#125;;// https://hankin2015.github.io/2017/12/08/20171208SetBug/// 准确的 operator &lt;bool operator &lt; (const info&amp; src) const &#123;\treturn count &lt; src.count\t\t|| (count == src.count &amp;&amp; seq &lt; src.seq)                       // 如果不希望 seq 参与比较可不要\t\t|| (count == src.count &amp;&amp; seq == src.seq &amp;&amp; id &lt; src.id)       // 如果不希望 seq &amp; id 参与比较可不要\t\t;&#125;","categories":["快速笔记"],"tags":["模块","快速笔记","c++"]},{"title":"websockify deploy: tcp to websocket","url":"/archives/6bc8d688.html","content":"需求\n原TCP服务，需要支持websocket协议\n\n方案\n中间层 websocket to tcp bridge&#x2F;proxy\n代理选型：websockify (协议代理)\n（可选）入口选型：nginx (入口，TLS卸载)\n\n环境准备\n（可选）linux 服务器\npython 3.6+\nwebsockify: https://github.com/novnc/websockify v0.12.0\n（可选）nginx: yum install nginx\n\n部署\n（可选）安装nginx\n\n（可选）配置nginx，反向代理到websockify\n\n安装websockify\n\n下载websockifygit clone https://github.com/novnc/websockify.gitcd websockifygit checkout v0.12.0\n启动websockify# 测试方式./run -v --traffic 20803 127.0.0.1:20802# 生产方式./run -D 20803 127.0.0.1:20802\n\n\n\n测试\n启动一个 tcp 服务端:\nnc -k -l 20802\n\npostman 发送请求:\n\n不走nginxws://xxx:xxx:xxx:xx:20803\n走nginx+tlswss://xxx:xxx:xxx:xx:443/?ip=xxx:xxx:xxx:xx&amp;port=20803\n\n\n\n备注：websockify 仅支持 binary 数据传输，具体参考 https://github.com/novnc/websockify/issues/365\n\n\n","categories":["部署"],"tags":["部署","快速笔记"]},{"title":"内存泄漏相关","url":"/archives/8f000135.html","content":"pre\n一个古老的windows项目查内存泄漏相关问题\n\nvld windows 安装\n下载：vld-2.5.1-setup.exe\n实测 vs2019、vs2022 均可用，注意载入的 lib 是 win32&#x2F;win64 就好\n默认目录：C:\\Program Files (x86)\\Visual Leak Detector\n\nproject 载入：\nc&#x2F;c++ -&gt; general -&gt; additional include directories: C:\\Program Files (x86)\\Visual Leak Detector\\include\nc&#x2F;c++ -&gt; general -&gt; debug information format: Program Database(/Zi)\nlinker -&gt; input -&gt; additional dependencies: C:\\Program Files (x86)\\Visual Leak Detector\\lib\\Win64\\vld.lib\nlinker -&gt; Debugging -&gt; generate debug info: (/Debug: Full)\n注意：如果是在 vs 运行状态下安装 vld，需要重启 vs；否则工程运行会报错找不到 vld.dll 类似的问题\n\n代码修改：\nmain 函数所在 cpp 文件最上面添加 #include &lt;vld.h&gt;\n如果是使用 stdafx.h 的项目，在 stdafx.h 里最前面添加\n重定向 stdout 到文件，以便查看最后的输出\n手动开启 vld，这样方便非debug模式显式的关闭 vld// main 函数开始的地方：freopen(&quot;vld-output.txt&quot;, &quot;w&quot;, stdout);// 显式开启vldVLDEnable();// main 函数结束的地方fflush(stdout);\n\nlinux 环境还是 libasan&#x2F;tcmalloc 更好用libasan\n物料：gcc 版本自带（高版本）\nmakefile 示例： (注意CXXFLAGS, LINKFLAGS都需要带这个参数)ASANFLAGS := -fsanitize=leak -fsanitize=address -fno-omit-frame-pointer -fno-optimize-sibling-callsCXXFLAGS += $(ASANFLAGS)LINKFLAGS += $(ASANFLAGS)\n\ntcmalloc\n物料：google gpreftools 工具包\n\nmakefile 示例: (注意: 加到最后)\nLINKFLAGS += -ltcmalloc\n\ntips: 线程数量超过12左右启动会慢\n\n方式1: 直接开, 结束进程后会给出解析heap文件的指令\n# 开启env HEAPCHECK=normal ./memory-leak-test# 结果pprof ./memory-leak-test &quot;/tmp/memory-leak-test.23613._main_-end.heap&quot; --stack --inuse_objects --lines --heapcheck --edgefraction=1e-10 --nodefraction=1e-10 --text &gt; tcmalloc-mlt.output.txt\n\n方式2: 查运行时泄漏\n\n分配内存，占用内存参数都设置的很大，避免自己打heap\n设置了信号量12打印一次\n有两个文件了可以对比分析# 启动env HEAPCHECK=normal HEAPPROFILE=./mlt.prof HEAP_PROFILE_ALLOCATION_INTERVAL=107374182400 HEAP_PROFILE_INUSE_INTERVAL=1073741824000 HEAPPROFILESIGNAL=12 ./memory-leak-test# 结果pprof --text --stack memory-leak-test mlt.prof.0002.heap --base=mlt.prof.0001.heap &gt; tcmalloc-mlt.output.txt\n\n\n\n一些常见的内存泄漏问题：(AI 辅助生成)// ---------------- tips ----------------void memoryLeakExample() &#123;    int* p = new int(10);  // 动态分配内存    // 忘记释放内存，导致内存泄漏&#125;// ---------------- tips ----------------void memoryLeakWithException() &#123;    int* p = new int(10);  // 动态分配内存    throw std::runtime_error(&quot;Something went wrong!&quot;);  // 抛出异常    delete p;  // 由于异常，delete 不会被执行，造成内存泄漏&#125;// ---------------- tips ----------------void memoryLeakWithMultipleAllocations() &#123;    int* p = new int(10);  // 分配内存    p = new int(20);  // 再次分配内存，但没有释放之前的内存，造成泄漏    delete p;  // 仅释放了最后分配的内存&#125;// ---------------- tips ----------------void memoryLeakInContainer() &#123;    std::vector&lt;int*&gt; v;    v.push_back(new int(10));  // 向容器中添加动态分配的内存    // 忘记释放容器中的内存，导致内存泄漏&#125;// ---------------- tips ----------------void memoryLeakWithMallocAndDelete() &#123;    int* p = (int*)malloc(sizeof(int));  // 使用 malloc 分配内存    delete p;  // 错误，应该使用 free 而不是 delete&#125;// ---------------- tips ----------------void memoryLeakWithArray() &#123;    int* arr = new int[5];  // 使用 new[] 分配数组    // 错误：使用 delete 释放数组    delete arr;  // 错误，应该使用 delete[] 而不是 delete&#125;// ---------------- tips ----------------struct MyStruct &#123;    int id;    std::vector&lt;int&gt; values;&#125;;void memoryLeakWithMemset() &#123;    MyStruct s;    s.id = 10;    s.values = &#123;1, 2, 3&#125;;    std::cout &lt;&lt; &quot;Before memset: id = &quot; &lt;&lt; s.id &lt;&lt; &quot;, values.size() = &quot; &lt;&lt; s.values.size() &lt;&lt; std::endl;    // 错误：使用 memset 重置结构体，可能导致内存泄漏或未定义行为    memset(&amp;s, 0, sizeof(s));    MyStruct s2;    // 错误：使用 memcpy 复制结构体，直接拷贝 STL 容器会破坏其内部状态    memcpy(&amp;s2, &amp;s1, sizeof(MyStruct));    std::cout &lt;&lt; &quot;After memset: id = &quot; &lt;&lt; s.id &lt;&lt; &quot;, values.size() = &quot; &lt;&lt; s.values.size() &lt;&lt; std::endl;&#125;// ---------------- tips ----------------void memoryLeakWithSharedPtr() &#123;    std::shared_ptr&lt;MyStruct&gt; s1 = std::make_shared&lt;MyStruct&gt;();    s1-&gt;p = std::make_shared&lt;int&gt;(10);    // 错误：如果没有正确管理 shared_ptr，可能会发生循环引用，导致内存泄漏    std::shared_ptr&lt;MyStruct&gt; s2 = s1;    // shared_ptr 循环引用，无法释放内存&#125;// ---------------- tips ----------------void memoryLeakWithKVReplace() &#123;    std::map&lt;int, int*&gt; test_map;    test_map[1] = new int(1);    test_map[1] = new int(2);  // 替换了之前key=1的value，导致上一行内存泄漏&#125;// ---------------- tips ----------------void test() &#123;    std::vector&lt;int&gt; vec;    for(int i = 0; i &lt; 100000000000000; ++i) &#123;        vec.push_back(i);  // 错误逻辑导致的内存膨胀（内存泄漏都查完，内存还是暴涨，往这个方向查）    &#125;&#125;","categories":["快速笔记"],"tags":["快速笔记","c++"]},{"title":"AI: windows-dllexport-dllimport","url":"/archives/e0b61275.html","content":"在 C++ 中，__declspec(dllexport) 和 __declspec(dllimport) 是用于标记 动态链接库（DLL） 中符号导出和导入的关键字。它们是 Microsoft 编译器（如 Visual Studio）专有的修饰符，用于控制符号在动态链接库中的可见性。\n以下是详细介绍：\n\n1. __declspec(dllexport)__declspec(dllexport) 告诉编译器将函数或变量导出（Export）到动态链接库（DLL），以便其他模块（如可执行文件或其他 DLL）可以使用这些符号。\n使用场景\n当您创建一个动态链接库（DLL）时，需要使用 __declspec(dllexport) 导出希望公开的函数、变量或类。\n\n示例导出函数// MyLibrary.h__declspec(dllexport) void myFunction();\n\n// MyLibrary.cpp#include &quot;MyLibrary.h&quot;__declspec(dllexport) void myFunction() &#123;    // 函数实现&#125;\n\n导出变量// MyLibrary.h__declspec(dllexport) int myGlobalVar;\n\n// MyLibrary.cpp#include &quot;MyLibrary.h&quot;__declspec(dllexport) int myGlobalVar = 42;\n\n导出类// MyLibrary.hclass __declspec(dllexport) MyClass &#123;public:    void myMethod();&#125;;\n\n// MyLibrary.cpp#include &quot;MyLibrary.h&quot;void MyClass::myMethod() &#123;    // 函数实现&#125;\n\n\n2. __declspec(dllimport)__declspec(dllimport) 告诉编译器从动态链接库（DLL）中导入（Import）符号，以便在当前模块中使用。\n使用场景\n当您使用一个动态链接库（DLL）中的函数、变量或类时，需要使用 __declspec(dllimport) 来声明这些符号。\n\n示例假设您已经创建了一个动态链接库，并导出了一个函数或变量：\n导入函数// MyLibrary.h__declspec(dllimport) void myFunction();\n\n// main.cpp#include &quot;MyLibrary.h&quot;int main() &#123;    myFunction(); // 调用来自 DLL 的函数    return 0;&#125;\n\n导入变量// MyLibrary.h__declspec(dllimport) int myGlobalVar;\n\n// main.cpp#include &quot;MyLibrary.h&quot;int main() &#123;    int value = myGlobalVar; // 使用来自 DLL 的全局变量    return 0;&#125;\n\n导入类// MyLibrary.hclass __declspec(dllimport) MyClass &#123;public:    void myMethod();&#125;;\n\n// main.cpp#include &quot;MyLibrary.h&quot;int main() &#123;    MyClass obj;    obj.myMethod(); // 调用来自 DLL 的方法    return 0;&#125;\n\n\n3. 动态切换 __declspec(dllexport) 和 __declspec(dllimport)在同一个头文件中，通常需要根据编译目标（DLL 还是客户端）动态切换 __declspec(dllexport) 和 __declspec(dllimport)。\n实现方法通过定义预处理器宏来控制导出和导入。例如：\n// MyLibrary.h#ifdef MYLIBRARY_EXPORTS#define MYLIBRARY_API __declspec(dllexport) // 编译 DLL 时使用#else#define MYLIBRARY_API __declspec(dllimport) // 使用 DLL 时使用#endifMYLIBRARY_API void myFunction();\n\n在编译 DLL 时定义 MYLIBRARY_EXPORTS，而在使用 DLL 时不定义 MYLIBRARY_EXPORTS。\n编译动态库（DLL）在生成 DLL 时，通过编译器选项定义 MYLIBRARY_EXPORTS：\ncl /D MYLIBRARY_EXPORTS MyLibrary.cpp /LD\n\n使用动态库在使用 DLL 的项目中，不需要定义 MYLIBRARY_EXPORTS，编译器会自动将其视为 __declspec(dllimport)。\n\n4. 注意事项4.1 不使用 __declspec 的情况\n如果不使用 __declspec(dllexport) 导出符号，编译器不会将符号公开到 DLL 导出表中，外部模块无法直接访问它们。\n如果不使用 __declspec(dllimport) 导入符号，编译器会假定符号是静态链接的，但可能会导致运行时错误。\n\n4.2 使用 DEF 文件导出符号除了使用 __declspec(dllexport)，还可以通过模块定义文件（.def 文件）导出符号。这在需要大量导出符号时更加方便：\n示例 DEF 文件：\nLIBRARY MyLibraryEXPORTS    myFunction    myGlobalVar\n\n生成 DLL：\ncl MyLibrary.cpp /LD /DEF:MyLibrary.def\n\n4.3 导出 C 函数（避免 C++ 名字修饰）如果导出的函数是用 C++ 编写的，默认情况下会启用名字修饰（name mangling）。为了避免名字修饰，可以使用 extern &quot;C&quot;：\nextern &quot;C&quot; __declspec(dllexport) void myFunction();\n\n\n5. 总结\n**__declspec(dllexport)**：用于将符号导出到 DLL，供其他模块使用。\n**__declspec(dllimport)**：用于从 DLL 导入符号到当前模块。\n动态切换导出&#x2F;导入：使用预处理器宏（如 MYLIBRARY_API）动态控制。\nDEF 文件：在需要导出大量符号时可以替代 __declspec(dllexport)。\n\n如有具体问题或代码场景需要分析，可以进一步探讨！ 😊\n","categories":["代码"],"tags":["C++"]},{"title":"折腾：std::format placeholder","url":"/archives/ff186d23.html","content":"编译期：std::format placeholder\n最终代码：https://github.com/kinly/easy_logger/blob/main/include/auto_format_rules.h\n\n背景与目标现代 C++ 提供了 std::format，比传统的 std::stringstream 更安全、高效，也避免了手动拼接。但对于旧代码或者希望“自动推导格式串”的开发者来说，迁移成本高。\n我有一个常用的辅助函数 inner_string(...)，基于 stringstream 构建字符串拼接，现在我希望用 std::format 替代它，并自动推导 &#123;&#125; 占位符的数量与格式。\n目标是：\n\n保留调用方式不变（如 inner_string(1.23, &quot;abc&quot;, 42)）\n自动生成合适的 format_string 结构\n对于 float&#x2F;double 自动加 &#123;:.2f&#125; 之类的精度\n支持 tuple 等复合类型拆解\n最好在编译期完成这些逻辑\n\n\n旧代码方式回顾：stream 拼接我们之前常用 stringstream 实现类似 print 效果：\nstd::stringstream ss;ss &lt;&lt; 123 &lt;&lt; &quot;abc&quot; &lt;&lt; 1.9 &lt;&lt; &#x27;\\n&#x27;;\n\n封装过后是这样的：\ntemplate&lt;typename _Func, typename..._Args&gt;static void _inner_unpak(_Func fun, const _Args&amp;... args) &#123;    (void)std::initializer_list&lt;int&gt;&#123;        [&amp;](const auto&amp; arg) &#123;            fun(arg);            return 0;        &#125;(args)...    &#125;;&#125;template&lt;typename..._Args&gt;inline static void _inner_format(std::ostream&amp; stream, const _Args&amp;... args) &#123;    _inner_unpak([&amp;](const auto&amp; arg) &#123;        stream &lt;&lt; arg;    &#125;, args...);&#125;template&lt;typename... _Args&gt;inline static std::string inner_string(const _Args&amp;... args) &#123;    std::stringstream ss;    _inner_format(ss, args...);    return ss.str();&#125;\n\n这其实已经是很泛化的流拼接工具了，和 std::format 的格式感知能力相比较，缺点是：\n\n不支持精度控制\n输出不统一\n类型错误编译期无法发现\n\n\n起点尝试：运行时构造 format string为了接近 std::format 的风格，第一步尝试是：根据参数个数生成一串 &#123;&#125; 占位符。\ntemplate&lt;typename... Args&gt;std::string format_string(const Args&amp;... args) &#123;  std::size_t arg_count = sizeof...(args);  std::string placeholders;  for (std::size_t i = 0; i &lt; arg_count; ++i) &#123;      placeholders += &quot;&#123;&#125;&quot;;      if (i &lt; arg_count - 1) placeholders += &#x27; &#x27;;  &#125;  return std::vformat(placeholders, std::make_format_args(args...));&#125;\n\n但是存在几个问题：\n\n每次都运行时构造格式字符串，效率低\n无法针对类型生成特定格式（如 float 想输出 &#123;:.2f&#125;）\n不支持结构体 &#x2F; tuple 等更复杂类型\n\n\n编译期自动推导格式字符串：终极方案我设计了一个完全在编译期推导格式串的系统，基于：\n\nconsteval 编译期函数\nconcepts 判断是否是 tuple\n模板参数展开\nstd::array&lt;char&gt; 拼接字符串\nC++20 string_view 缓存格式串\n\n类型到格式映射机制template &lt;typename T&gt;struct type_format &#123; static constexpr const char* value = &quot;&#123;&#125;&quot;; &#125;;template &lt;&gt; struct type_format&lt;float&gt; &#123; static constexpr const char* value = &quot;&#123;:.2f&#125;&quot;; &#125;;template &lt;&gt; struct type_format&lt;double&gt; &#123; static constexpr const char* value = &quot;&#123;:.2f&#125;&quot;; &#125;;\n\n判断是否 tuple 类型template &lt;typename T&gt;concept is_tuple_like = requires &#123; typename std::tuple_size&lt;T&gt;::type; &#125;;\n\n递归收集格式template &lt;typename T, typename Collector&gt;consteval void collect_type_formats(Collector collector) &#123;  if constexpr (is_tuple_like&lt;T&gt;) &#123;    [&amp;]&lt;std::size_t... Is&gt;(std::index_sequence&lt;Is...&gt;) &#123;      (collect_type_formats&lt;std::tuple_element_t&lt;Is, T&gt;&gt;(collector), ...);    &#125;(std::make_index_sequence&lt;std::tuple_size_v&lt;T&gt;&gt;&#123;&#125;);  &#125; else &#123;    collector(type_format&lt;std::decay_t&lt;T&gt;&gt;::value);  &#125;&#125;\n\n拼接格式串（含分隔符）template &lt;std::size_t Count, char Sep = &#x27; &#x27;&gt;consteval auto make_format_string(const std::array&lt;const char*, Count&gt;&amp; formats, std::size_t used) &#123;  std::array&lt;char, AUTO_FORMAT_LOGGER_MAX_ARGS * 16&gt; buf&#123;&#125;;  std::size_t pos = 0;  for (std::size_t i = 0; i &lt; used; ++i) &#123;    const char* f = formats[i];    while (*f) buf[pos++] = *f++;    if (i &lt; used - 1) buf[pos++] = Sep;  &#125;  std::array&lt;char, AUTO_FORMAT_LOGGER_MAX_ARGS * 16&gt; result&#123;&#125;;  std::copy_n(buf.begin(), pos, result.begin());  return std::pair&#123;result, pos&#125;;&#125;\n\n外部统一封装接口template &lt;typename... Args&gt;struct type_format_string_placeholders &#123;  static constexpr auto fmt = make_type_format_string_ct&lt;Args...&gt;();  static constexpr auto sv = std::string_view&#123;fmt.first.data(), fmt.second&#125;;&#125;;\n\n\n使用示例constexpr auto fmt = auto_format_rules::detail::make_type_format_string_ct&lt;float, int, float&gt;();std::string_view sv(fmt.first.data(), fmt.second);float a = 1.2345f, c = 3.14f;int b = 42;std::string result = std::vformat(sv, std::make_format_args(a, b, c));// 输出: 1.23 42 3.14\n\n也支持 tuple 嵌套：\nusing tup = std::tuple&lt;int, float, std::tuple&lt;double&gt;&gt;;constexpr auto sv = auto_format_rules::detail::type_format_string_placeholders&lt;tup&gt;::sv;\n\n\n编译期优势对比\n\n\n方法\n编译期\n类型感知\n精度控制\n性能开销\n\n\n\n手动写格式串\n❌\n❌\n❌\n最低\n\n\n运行时拼接 &#123;&#125;\n❌\n❌\n❌\n中\n\n\n本文方案：类型推导 + 缓存\n✅\n✅\n✅\n最优\n\n\n\n后续扩展想法\n&#123;name&#125; 风格格式串支持（需配合索引与映射）\n自动为 struct 提供格式（结合 C++23 reflexpr）\n支持单位后缀拼接（如 KB、ms）\n编译期格式串验证与调试输出\n\n\n总结这个系统完全基于编译期的 constexpr + 模板机制实现，支持自动生成符合类型的格式字符串，并为日志、调试、格式输出等提供了更高的性能与更好的类型安全。\n欢迎留言交流优化建议或 fork 后自定义扩展。\n","categories":["C++"],"tags":["C++"]},{"title":"快速笔记:域名中使用下划线的限制","url":"/archives/63e4b7b2.html","content":"域名中使用下划线的限制背景根据 RFC 952 和 RFC 1123 的规范：\n\n域名中不允许使用下划线 _ 作为有效字符。\n尽管某些工具和系统在非严格模式下可能允许下划线，但它并不符合标准规范，因此可能导致解析或访问问题。\n\n问题\nNginx 报错或无法匹配在 server_name 配置中使用带下划线的域名时，可能会报错：\n\nnginx: [emerg] invalid server name\n\n或者即使配置成功，访问时也无法匹配正确的 server_name。\n\n浏览器或客户端不支持很多浏览器和 DNS 客户端会拒绝解析包含下划线的域名，导致用户无法访问相关服务。\n\n\n解决方案1. 使用有效的域名字符建议将下划线 _ 替换为连字符 -，这是标准域名允许的字符。例如：\n\n将 dev_xxx.klysisle.space 替换为 dev-xxx.klysisle.space。\n\nNginx 配置示例：\nserver &#123; listen 80; server_name dev-xxx.klysisle.space; location /login/ &#123;     proxy_pass http://127.0.0.1:8180; &#125;&#125;\n\n2. 修改现有系统配置如果现有系统中已经大量使用了带下划线的域名，可以考虑以下几种方法：\n\n**DNS 记录别名 (CNAME)**：为带下划线的域名创建一个不带下划线的别名。例如，将 dev_xxx.klysisle.space 的 CNAME 记录指向 dev-xxx.klysisle.space。\n重定向：在 Web 服务器中配置重定向，将访问带下划线域名的请求重定向到不带下划线的域名。例如，在 Nginx 中可以使用 return 301 指令进行重定向。\n\nNginx 重定向示例：\nserver &#123; listen 80; server_name dev_xxx.klysisle.space; location / &#123;     return 301 http://dev-xxx.klysisle.space$request_uri; &#125;&#125;\n\n总结使用下划线作为域名的一部分虽然在某些情况下可能工作，但并不符合标准规范，可能会导致各种兼容性问题。为了确保域名的广泛兼容性和稳定性，建议始终使用标准允许的字符，如连字符 -。通过替换下划线或配置重定向，可以有效解决相关问题，确保服务的正常访问。\n","categories":["运维"],"tags":["运维"]},{"title":"apollo config C++(20) client","url":"/archives/38b805bc.html","content":"apollo config C++(20) client\n源码：https://github.com/kinly/apollo_config-cli\n\napollo or nacos\n两个最小化部署简单试用了一下\n最终选择 apollo 主要有是：\n权限隔离：修改、提交的权限可以隔离开，实际应用中这点还挺重要的（nacos可能也有类似功能，暂时没有使用到）\n页面配置方式更简洁\n灰度的支持\n之前用过更熟悉\n\n\n\nclient 实现\n核心功能\n\n配置拉取与缓存\n线程安全配置访问\nHTTP 长轮询（long poll）监听变更\n多命名空间隔离管理\nIP 感知路由支持(灰度)\n\n\n其他\n\n熔断器（circuit breaker）\ncallback thread pool TODO: 线程池已经实现，但是总觉得这里放一个线程池有点重，期望是做成切片的方式，由外部决定 callback 怎么处理，但是又会涉及另一个问题如果外部是阻塞的，那么代码里的那个锁会很长。\n而且这里涉及一次数据拷贝，暂时还没太想好怎么做才最好 （trigger_callbacks 函数调用 cb(key, value); 的地方）\n\n\n过程中的问题记录\n\napollo 服务端 status &#x3D; 304 时没有 body，cpp-httplib 不设置 response function 的情况下会取不到 304 这个 status code，考虑了下还是需要就加上了\napollo 的返回 header 里没有 content-length …. 不太友好 response_body 的 reserve 没有意义了（还是保留在这里了，之后看下 apollo 实现看能不能改掉）\ncpp-httplib 里的 encode_url 结果对 apollo 是不够的，所以有了这个函数：strict_url_encode\napollo 有更新再拉取的时候也是全量的，一度考虑做个比较器，比较后只 callback 增量给应用方….（暂时还没有实现，namespace_data 结构里保留了 notification_id、messages 信息，应该可以用这两个信息先对比下再看是否要遍历区分这个namespace里是否有更新）\nprocess_config_response 的实现是直接替换了整个 namespace_data, 主要是省事，后面 process_notifications 会再把 notificationId, messages 信息更新掉，再次 fetch_config 时没有变更也会只得到 304 的 status code\n\n\n\n依赖要求\nC++20 编译器\ncpp-httplib (v0.12.1+)\nnlohmann&#x2F;json (v3.11.2+)\n\n基础使用void apollo_test() &#123;  using namespace apollo::client;  // 创建客户端  auto client = apollo_client::create(&quot;http://localhost:8080&quot;, &quot;cats&quot;, &quot;dev&quot;, &quot;192.168.100.1&quot;);  // 注册回调  client-&gt;register_callback(&quot;application&quot;, &quot;login.port&quot;, [](std::string_view key, std::string_view value) &#123;    std::cout &lt;&lt; &quot;application login.port updated to: &quot; &lt;&lt; value &lt;&lt; &quot;\\n&quot;;  &#125;);  client-&gt;register_callback(&quot;application&quot;, &quot;game.port&quot;, [](std::string_view key, std::string_view value) &#123;    std::cout &lt;&lt; &quot;application game.port changed to: &quot; &lt;&lt; value &lt;&lt; &quot;\\n&quot;;  &#125;);  // 添加命名空间  client-&gt;add_namespace(&quot;application&quot;);  client-&gt;add_namespace(&quot;cats.tables&quot;);  // 启动客户端  client-&gt;start();  // 主循环  while (true) &#123;    // if (auto val = client.get_value(&quot;database&quot;, &quot;timeout&quot;)) &#123;    //   std::cout &lt;&lt; &quot;Current timeout: &quot; &lt;&lt; *val &lt;&lt; &quot;\\n&quot;;    // &#125;    std::this_thread::sleep_for(std::chrono::seconds(5));  &#125;&#125;\n\n其他update message\n2025-04-08 把 nlohmann json 替换成了 simdjson。最开始理解错误了 simdjson 的 iterate_many 接口，以为是增量解析的；issue 里看到了一些关于增量解析的讨论，期望后续有相关实现\nhttps://github.com/simdjson/simdjson/issues/128\nhttps://github.com/simdjson/simdjson/issues/1356\nhttps://github.com/simdjson/simdjson/issues/1135\n\n\n\n熔断器\n这个熔断器比较简单，失败超过一定次数就以幂值延长等待时间\n\nutil::circuit_breaker::config cb_cfg&#123;  .max_failures_before_cooldown = 10,  .get_delay = util::circuit_breaker::config::create_exponential_backoff(500, 1.5),  .cooldown_duration = std::chrono::seconds(45)&#125;;client-&gt;set_breaker_config(cb_cfg); // 自定义熔断策略\n\n线程池\n相比传统线程池，增加了按照 hash_key 固定任务到某个线程\n主要也是想给游戏服务端的存储DB使用，玩家ID作为 hash_key，这样单个玩家的数据库操作是在一个线程有序执行的\n（也可能是这个线程池设计如此的关系，觉得直接用在 apollo client 里有点重度\n\nutil::thread_pool pool(8);pool.submit(&quot;user_123&quot;, []&#123;    // 保证相同路由键的任务顺序执行&#125;);\n\nTODO:\ncallback 的线程问题，最简单的方式是丢到 std::async 里，目前是在网络线程同步调用的，后面根据实际使用修改\napollo fetch 到的内容是完整的，也就是整个 namespace 下的东西都会被 fetch 下来，这个最终到底是封装到 client 里合适还是丢到外面处理合适暂时还不确定\n如果遇到配置依赖：shop 配置检查 item 配置里是否有对应的 item_id，那么遇到 shop 配置更新回调先于 item 配置更新传递到外部，应该如何处理\n\n","categories":["C++"],"tags":["C++","apollo config","配置中心"]},{"title":"快速笔记：inline namespace","url":"/archives/fa403e19.html","content":"\n\n有 AI 了记博客（还是从AI搬过来的笔记）好像没什么必要了….\n\n\ninline namespace 是一个 C++11 引入的非常实用的工具，适合做：\n📦 库版本控制 &#x2F; ABI 隔离\n🔌 插件或模块系统的版本兼容\n⚙️ 对外接口稳定，对内灵活演进\n\n下面我们用一个简单例子来一步步讲清楚怎么用 👇\n\n✅ 1. 最基本用法namespace mylib &#123;inline namespace v1 &#123;    void hello() &#123;        std::cout &lt;&lt; &quot;Hello from v1\\n&quot;;    &#125;&#125;&#125;\n\n你可以这样使用：\nmylib::hello();       // ✅ 直接访问，等价于 mylib::v1::hello()mylib::v1::hello();   // ✅ 显式写出版本\n\n\n✅ 2. 加入多个版本 —— 新版本可以共存namespace mylib &#123;inline namespace v2 &#123;    void hello() &#123;        std::cout &lt;&lt; &quot;Hello from v2\\n&quot;;    &#125;&#125;// v1 不是 inline，保留兼容性但不默认使用namespace v1 &#123;    void hello() &#123;        std::cout &lt;&lt; &quot;Hello from v1\\n&quot;;    &#125;&#125;&#125;\n\n此时：\nmylib::hello();       // 🔸 使用的是 v2 版本（因为是 inline）mylib::v1::hello();   // ✅ 指定使用旧版本mylib::v2::hello();   // ✅ 显式访问当前版本\n\n\n✅ 3. inline namespace 的实际用途比如你写了一个游戏 AI 库 ai::, 你可以这样组织：\nnamespace ai &#123;inline namespace v2025_04 &#123;    struct Behavior &#123;        void tick() const &#123;            std::cout &lt;&lt; &quot;tick v2025_04\\n&quot;;        &#125;    &#125;;&#125;// 旧版本留着，但用户默认看不到namespace v2023_12 &#123;    struct Behavior &#123;        void tick() const &#123;            std::cout &lt;&lt; &quot;tick v2023_12\\n&quot;;        &#125;    &#125;;&#125;&#125;\n\n使用者默认写：\nai::Behavior b;b.tick();  // ✅ 输出 tick v2025_04\n\n旧代码还能写：\nai::v2023_12::Behavior old_b;old_b.tick(); // ✅ 输出 tick v2023_12\n\n\n🧠 实践建议\n\n\n目的\n怎么做\n\n\n\n维护 ABI\n给实现放进 inline namespace，防止链接冲突\n\n\n版本演进\n用多个 namespace vxxxx_xx 组织新旧代码\n\n\n使用方便\n只把最新版本声明为 inline，用户直接用 ai::Xxx\n\n\n\n🎁 Bonus：和 #define 或 constexpr 配合版本判断你还可以配合常量使用版本：\nnamespace ai &#123;inline namespace v2025_04 &#123;    constexpr int version = 202504;&#125;&#125;\n\n然后在代码里：\n#if ai::version &gt;= 202500    // 使用新接口#endif\n\n\n","categories":["快速笔记"],"tags":["快速笔记","c++"]},{"title":"random helper：范围、权重随机算法","url":"/archives/eba4529e.html","content":"inlay::random\nhttps://github.com/kinly/random_helper.git\n\n一个高性能、线程安全的 C++ 随机数工具库，支持线程局部随机引擎、通用区间采样函数 range，以及三种不同策略的权重采样器（Alias、Expansion、Binary）。\n特性 Features\n💡 线程局部随机引擎封装：thread_rng()\n🎲 通用区间采样函数：range(min, max)\n📦 三种权重采样器：\nweight_faster_alias: O(1) 采样，适合频繁调用\nweight_faster_expansion: 极致快速采样，适合小权重集合\nweight_faster_binary: 适合通用场景，支持整数&#x2F;浮点权重\n\n\n\n示例 Example#include &quot;random.hpp&quot;#include &lt;iostream&gt;int main() &#123;  std::vector&lt;int&gt; values&#123;1, 2, 3, 4&#125;;  std::vector&lt;double&gt; weights&#123;0.1, 0.2, 0.3, 0.4&#125;;  inlay::random::weight_faster_alias&lt;int&gt; sampler(      values.begin(), values.end(),      weights.begin(), weights.end()  );  for (int i = 0; i &lt; 10; ++i) &#123;    std::cout &lt;&lt; sampler() &lt;&lt; &quot; &quot;;  &#125;&#125;\n\n性能比较 Benchmark\n\n\n方法\n初始化复杂度\n采样复杂度\n适用场景说明\n\n\n\nAlias\nO(n)\nO(1)\n高频采样、浮点权重\n\n\nExpansion\nO(n × w)\nO(1)\n小权重集合、最快采样\n\n\nBinary\nO(n)\nO(log n)\n通用、整数权重优先\n\n\n编译要求\nC++20 及以上（仅少量语法）\n无第三方依赖（仅 STL）\n\nTODO\n 添加更多采样策略支持\n 支持分布策略插件式扩展\n\n信息备忘\n\n引擎（Engine）：像是一台骰子机，不停地吐出“基础随机数”。\n\n\n\n\n分布（Distribution）：是一个数学过滤器，告诉你“这些随机数应该分布成什么样子”。\n\n\n\n如何选择随机引擎\n\n\n\n\n应用场景\n推荐引擎\n原因\n\n\n\n游戏中的非关键随机行为\ndefault_random_engine 或 minstd_rand\n快速，易于使用\n\n\n科学模拟\nmt19937 或 ranlux48\n高质量随机数\n\n\n加密相关\n❌ 不使用这些引擎\n请使用 std::random_device + 专业加密库\n\n\n教学 &#x2F; 学习\nminstd_rand, knuth_b\n简单，容易理解\n\n\n嵌入式系统\nminstd_rand0\n小内存，占用低\n\n\n跨平台一致性要求\n明确指定 mt19937 并使用固定种子\n保证可重现性\n\n\n\n常见分布种类及用途\n\n\n\n\n分布名称\n类名\n描述\n典型用途\n\n\n\n均匀整数分布\nstd::uniform_int_distribution\n等概率生成某范围内的整数\n抽奖、骰子、游戏事件\n\n\n均匀实数分布\nstd::uniform_real_distribution\n生成实数范围内等概率值\n物理模拟、归一化值\n\n\n伯努利分布\nstd::bernoulli_distribution\n成功概率 p 的二项分布（0 或 1）\n掷硬币、概率判断\n\n\n二项分布\nstd::binomial_distribution\nn 次试验中成功次数\n离散事件成功次数模拟\n\n\n几何分布\nstd::geometric_distribution\n成功一次前失败的次数\n等待第一次成功的模型\n\n\n泊松分布\nstd::poisson_distribution\n单位时间内事件发生次数\n网络包、电话中心模拟\n\n\n正态分布（高斯）\nstd::normal_distribution\n钟形曲线\n噪声、误差模拟、机器学习初始化\n\n\n对数正态分布\nstd::lognormal_distribution\n变量对数正态分布\n股票收益、金融模型\n\n\n指数分布\nstd::exponential_distribution\n时间间隔模拟\n排队、寿命建模\n\n\ngamma 分布\nstd::gamma_distribution\n广义泊松时间间隔\n生物模型、贝叶斯方法\n\n\nWeibull 分布\nstd::weibull_distribution\n产品寿命分析\n工业可靠性\n\n\nextreme value 分布\nstd::extreme_value_distribution\n极端事件概率\n风速、洪水预测\n\n\n","categories":["C++"],"tags":["c++"]},{"title":"在使用 Cursor 半个月后，我总结了这些使用心得","url":"/archives/c3812e38.html","content":"\n最近半个月，我尝试用 Cursor + Claude 作为日常 C++ 开发的主要助手。期间踩了不少坑，也摸索出了一些相对靠谱的用法。本文简单记录一下我的使用体验、配置规则、Prompt 编写建议，以及它的优点和局限，供你参考。\n\n\nCursor 是什么？Cursor 是一个基于 Claude（还有其他大模型）的代码编辑器插件。它能帮你补全、重构、分析代码，还能直接执行一些复杂的修改任务——听起来就像是个“AI 搭档”。\n但说实话，目前它离“完全替你开发”还有相当的距离。尤其在中大型项目中，使用 Cursor 容易陷入「build → ask → fix → repeat」的循环，AI 也会在其中频繁“降智”。如果你自己不能快速定位问题，效率反而可能被拖慢。\n所以我的建议是：\n\n把它当成助手，不是替代品。\n\n你还是要保持对项目的掌控，Cursor 是锦上添花，不是雪中送炭。\n\n特别注意在借助 Agent 重构结构时需及时备份，很多时候 AI 容易用力过猛\n\n\n\n使用前的准备：规则配置很关键项目结构建议（以 C++ 为例）为了让 Cursor 更好理解项目上下文，同时方便后期维护，我建议提前规范项目结构，比如：\n## 项目目录结构1. **模块化组织**：   - 每个模块一个文件夹，以模块名命名；   - 同一模块的 `.hpp` 和 `.cpp` 文件放在一起。2. **特殊目录**：   - `util/`：通用工具代码；   - `3rd/`：第三方依赖；   - `cmake/`：CMake 配置，子结构如下：     - `build.cmake`：构建相关；     - `develop.cmake`：开发相关；     - `3rd.xxxx.cmake`：第三方依赖；     - 所有第三方库建议通过 Git Submodule，而不是 `find_package`。````---### 命名规范建议统一的命名风格能显著提升 AI 理解代码的能力。下面是我实践中的一套：```markdown## 命名规则（C++）1. 使用 snake_case 命名法；2. 所有变量、函数、类型名统一小写加下划线；3. 类成员变量以下划线 `_` 开头；4. 模板参数以 `_tt`（类型）或 `_vv`（值）结尾，必要时可简写为 `tt`。\n\n\n.clang-format 配置（建议添加到规则文档）Cursor 对格式也有一定敏感度，一个稳定的格式化配置可以减少 AI 的错误改写：\nLanguage: CppBasedOnStyle: GoogleIndentWidth: 2TabWidth: 2ContinuationIndentWidth: 2UseTab: NeverAlignAfterOpenBracket: DontAlignAllowAllParametersOfDeclarationOnNextLine: falseAllowShortBlocksOnASingleLine: falseAllowShortCaseLabelsOnASingleLine: falseAllowShortFunctionsOnASingleLine: EmptyAllowShortIfStatementsOnASingleLine: falseAllowShortLoopsOnASingleLine: falseColumnLimit: 120FixNamespaceComments: trueShortNamespaceLines: 0\n\n\nPrompt 怎么写更有效？这是重点。如果你希望 AI 给出可用代码、结构、建议，一定要把需求说清楚，而且提供完整上下文。\n比如下面这个 Prompt：\n我正在使用 C++ 和 [Seastar](https://github.com/scylladb/seastar) 框架开发一个高性能服务端网关，要求同时支持 HTTP、TCP、UDP 三种协议，并尽可能支持 WebSocket。目标是实现一个适用于游戏或微服务系统的高并发异步网关，具备以下特性：1. 使用 Seastar 的 `sharded` 模型按 CPU 分片运行；2. HTTP 模块用于提供 RESTful 接口；3. TCP 模块用于长连接服务，支持 session 管理；4. UDP 模块用于无连接消息传输；5. WebSocket（如有实现建议，欢迎提供），通过 HTTP 升级连接；6. 所有模块需异步非阻塞，使用 Seastar 的 `future` 模型；7. 框架应线程安全、易于扩展，便于后续添加协议（如 QUIC/NATS 等）；8. 也需要客户端，方便服务器访问外部内容。请帮我：- 提供一个项目骨架和可运行的项目示例；- 对模块如何组织（HTTP/TCP/UDP/WebSocket）提供结构建议；- 推荐 Seastar 中合适的组件；- 如果 WebSocket 没有内建支持，请指出如何手动实现；- 补充开发过程中需要注意的性能或异步陷阱；- 依赖 asio no-boost 生成相同接口的代码，并且给出对比压测的代码，我后期需要对比压测 asio &amp; seastar；- 使用不同数据长度作为压测样例。\n\n小贴士：\n\n不要只问“帮我写一个 XXX”；\n提供清晰背景、目标、技术栈；\n最好分点描述需求，避免一次性丢一个巨型段落；\n可以先让 AI 草拟，再自己逐步 refine。\n\n\nCursor 使用功能简表\n\n\n功能\n用法说明\n适合场景\n\n\n\nask\n直接提问或让 AI 解释某段代码\n快速查询、代码含义分析、生成示例\n\n\nagent\n执行更复杂的修改或重构\n多文件重构、批量命名更改、自动注释\n\n\nmanual\n无 AI 介入，仅记录操作历史\n基本用不到，可忽略\n\n\n\n使用总结 &amp; 建议\nCursor 是个好工具，但它不会替你写完项目。它像一个能说会动、偶尔犯迷糊的实习生——能帮上忙，但你得会指挥它。\n\n几点使用建议：\n\n一定要写好项目规则（包括 clang-format、命名规范等）；\nPrompt 一定要完整清晰；\n不要相信 AI 给出的东西是“能跑”的，尤其涉及编译或跨模块逻辑时；\n手动改过的代码注意备份，Cursor 有时候会“自作主张”还原掉。\n\n最后：继续学习、保持代码的主控权，才是最高效率的合作方式。\n\n\n如果你也在用 Cursor，欢迎留言分享你的使用体验！\n\n","categories":["AI 编程助手"],"tags":["AI 编程助手","Cursor","Claude","编码效率"]}]